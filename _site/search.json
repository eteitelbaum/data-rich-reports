[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Microsoft 365\n🔗 on GW IT’s Microsoft 365 Page\n\n\nTableau\n🔗 on Tableau Trial\n\n\nLecture Recordings\n🔗 on Blackboard\n\n\nProf T’s Zoom Office\n🔗 on Zoom\n\n\nOffice Hours Appointments\n🔗 on Calendly"
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Support",
    "section": "",
    "text": "Writing Center GW’s Writing Center cultivates confident writers in the University community by facilitating collaborative, critical, and inclusive conversations at all stages of the writing process. Working alongside peer mentors, writers develop strategies to write independently in academic and public settings. Appointments can be booked online here.\nAcademic Commons Academic Commons provides tutoring and other academic support resources to students in many courses. Students can schedule virtual one-on-one appointments or attend virtual drop-in sessions. Students may schedule an appointment, review the tutoring schedule, access other academic support resources, or obtain assistance here."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Support",
    "section": "",
    "text": "Writing Center GW’s Writing Center cultivates confident writers in the University community by facilitating collaborative, critical, and inclusive conversations at all stages of the writing process. Working alongside peer mentors, writers develop strategies to write independently in academic and public settings. Appointments can be booked online here.\nAcademic Commons Academic Commons provides tutoring and other academic support resources to students in many courses. Students can schedule virtual one-on-one appointments or attend virtual drop-in sessions. Students may schedule an appointment, review the tutoring schedule, access other academic support resources, or obtain assistance here."
  },
  {
    "objectID": "course-support.html#support-for-students-outside-the-classroom",
    "href": "course-support.html#support-for-students-outside-the-classroom",
    "title": "Support",
    "section": "Support for students outside the classroom",
    "text": "Support for students outside the classroom\nDisability Support Services (DSS) 202-994-8250 Any student who may need an accommodation based on the potential impact of a disability should contact Disability Support Services to establish eligibility and to coordinate reasonable accommodations.\nCounseling and Psychological Services 202-994-5300 GW’s Colonial Health Center offers counseling and psychological services, supporting mental health and personal development by collaborating directly with students to overcome challenges and difficulties that may interfere with academic, emotional, and personal success.\nGW aims to create a community that cares for each other.The CARE Team fosters this goal by creating a pathway through which students who may need additional support can be identified and referred to the most appropriate services. Through the CARE Team, students are given the support they need to persist and succeed at GW and beyond.\nSafety and Security:\n\nIn an emergency: call GWPD 202-994-6111 or 911.\nFor situation-specific actions: review the Emergency Response Handbook\nStay informed: safety.gwu.edu/stay-informed"
  },
  {
    "objectID": "exercises/exercise-1.2.html",
    "href": "exercises/exercise-1.2.html",
    "title": "Exercise 1.2",
    "section": "",
    "text": "Loading webR..."
  },
  {
    "objectID": "exercises/exercise-1.2.html#code",
    "href": "exercises/exercise-1.2.html#code",
    "title": "Exercise 1.2",
    "section": "",
    "text": "Loading webR..."
  },
  {
    "objectID": "exercises/exercise-1.2.html#questions",
    "href": "exercises/exercise-1.2.html#questions",
    "title": "Exercise 1.2",
    "section": "Questions",
    "text": "Questions\n\nTry summarizing the data with a different function for one or more of the variables.\n\n\nWhat is the median value of polyarchy for The West?\nWhat is the max value of gdp_pc for Eastern Europe?\nWhat is the standard deviation of flfp for Africa?\nWhat is the interquartile range of women_rep for the Middle East?\n\n\nNow try grouping by country instead of region.\n\n\nWhat is the median value of polyarchy for Sweden?\nWhat is the max value of gdp_pc New Zealand?\nWhat is the standard deviation of flfp for Spain?\nWhat is the interquartile range of women_rep for Germany?\n\n\nSort countries in descending order based on the mean value of gdp_pc (instead of the median value of polyarchy). Which country ranks first based on this sorting?\nNow try sorting countries in ascending order based on the median value of women_rep (hint: delete “desc” from the arrange() call). Which country ranks at the “top” of the list?"
  },
  {
    "objectID": "exercises/zzz.html",
    "href": "exercises/zzz.html",
    "title": "Additional Dependencies",
    "section": "",
    "text": "/exercises/webr-serviceworker.js\n/exercises/webr-worker.js"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This page displays an outline of the topics, content, and assignments for the term. Each module starts on a Monday. There are no assignments due on Sundays.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModule\nDate\nSkills\nPackages\nFunctions\nReadings\nReference\nVideos\nAssignments\n\n\n\n\n1.1\nMay 22\nRead data into R\nreadr, dplyr\nread_csv(), glimpse()\n\n📖\n🖥️🖥️\n\n\n\n\nMay 23\nReshape data\ntidyr\npivot_longer()\n\n📖\n🖥️\n\n\n\n\nMay 24\nClean data\ndplyr\nmutate(), mutate_at(), substring()\n📖\n\n🖥️🖥️\n📘\n\n\n1.2\nMay 25\nDownload data from an API\nwbstats, vdemdata, dplyr, janitor\nwb_data(), vdem, select_(), filter(), case_match(), round_to_fraction()\n\n\n🖥️🖥️\n\n\n\n\nMay 26\nMerge data frames\ncountrycode, dplyr , readr\ncountrycode(), left_join(), write_csv()\n\n📖\n🖥️🖥️\n\n\n\n\nMay 27\nGroup, summarize and arrange\ndplyr\ngroup_by(), summarize(), arrange()\n\n📖\n🖥️\n📘🧮\n\n\n2.1\nMay 29\nBar charts & histograms\nggplot2\nggplot(), geom_col(), geom_histogram(), aes(), labs()\n\n📖📖\n🖥️🖥️\n\n\n\n\nMay 30\nLine charts\nggplot2\ngeom_line()\n\n\n🖥️\n\n\n\n\nMay 31\nScatter plots\nggplot2, scales\ngeom_point(), geom_smooth(), scale_x_log10(), label_number(), geom_text()\n📖\n📖\n🖥️\n📘\n\n\n2.2\nJun 1\nColor schemes\ntidyr, colorBlindess, dplyr, viridis, RColorBrewer\ndrop_na(), cvdPlot(), scale_fill_manual(), scale_fill_viridis_d(), scale_fill_brewer(), scale_color_manual(), scale_color_viridis_d(), scale_color_brewer\n\n📖\n🖥️\n\n\n\n\nJun 2\nThemes & annotations\nggplot2\ntheme_dark(), theme_minimal(), annotate(), geom_hline(), geom_vline()\n\n📖\n🖥️🖥️\n\n\n\n\nJun 3\nInteractivity\nplotly\nggplotly(), layout()\n\n\n🖥️\n📘 🧮\n\n\n3.1\nJun 5\nChoropleth maps\nrnaturalearth, ggplot2, ggthemes\nne_countries(), geom_sf(), theme_map()\n\n\n🖥️\n\n\n\n\nJun 6\nMap data\nggplot2, viridis\ntheme(), scale_fill_viridis_c()\n\n\n🖥️\n\n\n\n\nJun 7\nMake a map function\n\neval(), parse(), function(), source()\n📖\n\n🖥️\n📘\n\n\n3.2\nJun 8\nUpload UCDP data\nstates, sf\nsfind(), st_as_sf()\n\n\n🖥️\n\n\n\n\nJun 9\nMake a leaflet map\nleaflet\nleaflet(), addTiles(), addMarkers(), setView()\n\n\n🖥️\n\n\n\n\nJun 10\nCustomize your map\nleaflet, htmltools\nawesomeIcons(), addAwesomeMarkers(), addProviderTiles(), sprintf(), lapply(), HTML\n\n\n🖥️\n📘 🧮\n\n\n4.1\nJun 12\nExploring tabular data\ntidycensus, dplyr, stringr, kableExtra\ncensus_api_key(), load_variables(), get_acs(), rename(), rename_with, str_remove(), kable(), slice_max(), slice_min(), slice_sample(), bind_rows()\n\n\n🖥️🖥️\n\n\n\n\nJun 13\nMake a gt table\ngt\ngt(), tab_header(), cols_label(), fmt_currency(), tab_source_note(), cols_width(), opt_table_font(), cols_align(), tab_options(), gtsave()\n\n\n🖥️\n\n\n\n\nJun 14\nConfidence intervals\nggplot2\ngeom_errorbar()\n📖\n\n🖥️\n📘\n\n\n4.2\nJun 15\nDisplay regression tables\npeacesciencer, broom, dplyr\ncreate_stateyears(), add_ucdp_acd(), add_democracy(), add_creg_fractionalization(), add_sdp_gdp(), add_rugged_terrain(), tidy(), mutate_if(), glm(), binomial()\n\n\n🖥️\n\n\n\n\nJun 16\nMake regression tables\nmodelsummary\nlist(), modelsummary()\n\n\n🖥️\n✍️\n\n\n\nJun 17\nCoefficient plots\nmodelsummary\nmodelplot(), rev()\n\n\n🖥️\n📘 🧮\n\n\n5.1\nJun 19\nScatter plot app setup\ndplyr\nsummarize_all()\n\n\n🖥️\n\n\n\n\nJun 20\nBuilding the UI\nshiny\nfluidPage(), titlePanel(), sidebarLayout(), sidebarPanel(), selectInput(), mainPanel(), plotOutput()\n\n\n🖥️\n\n\n\n\nJun 21\nBuilding the server\nshiny\nrenderPlot(), shinyApp()\n📖\n\n🖥️\n📘\n\n\n5.2\nJun 22\nLine chart app setup\nfredr\nfredr_set_key() , as.Date() , Sys.Date() ,\n\n\n🖥️\n\n\n\n\nJun 23\nBuilding the UI\nshiny\ncolumn(), wellPanel(), helpText(), sliderInput()\n\n\n🖥️\n✍️\n\n\n\nJun 24\nBuilding the server\nshiny, fredr\nreactive(), fredr(), fred_indicator()\n\n\n🖥️\n📘 🧮\n\n\n6.1\nJun 26\nTBD\n\n\n\n\n🖥️\n\n\n\n\nJun 27\nTBD\n\n\n\n\n\n\n\n\n\nJun 28\nTBD\n\n\n\n\n\n\n\n\n6.2\nJun 29\nTBD\n\n\n\n\n🖥️\n\n\n\n\nJun 30\nTBD\n\n\n\n\n\n\n\n\n\nJul 1\nTBD\n\n\n\n\n\n✍️"
  },
  {
    "objectID": "instructor.html",
    "href": "instructor.html",
    "title": "Instructor",
    "section": "",
    "text": "Emmanuel Teitelbaum is an associate professor of political science and international affairs at the The George Washington University His research and writing explore how class conflict and compromise intersect with democracy and development. He also has a strong interest in labor standards and understanding how labor unions, nonprofit organizations, consumers and corporations can help to promote them.\nAt GW, Professor Teitelbaum teaches courses on comparative politics, comparative political economy and South Asia. He is on faculty in the Department of Political Science and the Elliott School of International Affairs and am affiliated with the Sigur Center for Asian Studies as well as the Institute for International Economic Policy."
  },
  {
    "objectID": "instructor.html#office-hours",
    "href": "instructor.html#office-hours",
    "title": "Instructor",
    "section": "Office hours",
    "text": "Office hours\nProfessor Teitelbaum’s office hours are on Tuesdays and Thursdays from 4:00 p.m. to 5:00 p.m. Please sign up for a slot (or two) on his Calendly page. He is available for consultation virtually on Zoom or in his office at 411 Monroe Hall (2115 G. ST NW)."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "modules/getting-started.html",
    "href": "modules/getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "All of our work for this course will be done in the R language and we will be working with R in RStudio. RStudio is an integrated development environment (IDE) develop by a company named Posit. Please be sure to download and install the most recent versions of R and R Studio from Posit’s website.\nIt is a good idea to periodically update R and RStudio. RStudio will prompt you when it is time to update and you can follow the same process of downloading and installing from the Posit website that we just did here. For R, there are a number of ways to do it, but the easiest is to use packages like installr for Windows and updateR for Mac. Here is a good blog post that walks you through the steps of how to update R using these packages. I usually update R once a semester.\nWe are going to be using a number of R packages throughout the course. One essential set of packages are those that comprise the Tidyverse, but especially readr, dplyr, ggplot2 and tidyr. You can install the entire Tidyverse collection of packages by typing install.packages(\"tidyverse\") in your console. We will talk about these packages in detail as we go through the course, but have a look at this basic description now to gain some basic familiarity.\nAnother thing that you really want to do is to make sure that you have the native pipe operator (|&gt;) enabled. In RStudio, go to Tools&gt;Global Options, then go to Code and select “Use native pipe operator.”\nWhile you are here, you can also go to Appearance to select a different editor theme or to Pane Layout to change how the four panes in R Studio are organized. Next, familiarize yourself with how to expand and minimize the four windows. The most important window that I want to highlight here is the source window. This is where we are going to be working most of the time in this course. And if I tell you to send your source code, I mean to send the file that you are working on in this window. This could be a Quarto document, an R script or an app.R file for a Shiny app.\nThe next window is the Console and there we also see tabs for Terminal and Background Jobs. The console is where you can run R code one line at a time. The terminal is relevant for more advanced users and we will make some use of it when we talk about publishing Quarto documents. Background Jobs is going to be helpful when we want troubleshoot a Quarto document that is not rendering properly.\nFrom there, the next pane we want to explore is Environment, History, etc. Environment tells us what files are currently available to us. The other important tab here is Git which will be where we push things to GitHub. You will be using this a lot in the course.\nFinally, we see a pane with Files, Plots, Packages etc. Files tells us what files are in our project folder and enables us to copy, and delete files associated with our project. Plots is a window for viewing our visualizations. And Packages shows us what packages are available and loaded into our environment.\nBefore you move on to the next section, take some time to familiarize yourself with the various user-friendly buttons and shortcuts available to you like the drop down menu for the pane layout, a spell checker, a button for inserting a code chunk and other features that you can play around with."
  },
  {
    "objectID": "modules/getting-started.html#sec-rstudio-setup",
    "href": "modules/getting-started.html#sec-rstudio-setup",
    "title": "Getting Started",
    "section": "",
    "text": "All of our work for this course will be done in the R language and we will be working with R in RStudio. RStudio is an integrated development environment (IDE) develop by a company named Posit. Please be sure to download and install the most recent versions of R and R Studio from Posit’s website.\nIt is a good idea to periodically update R and RStudio. RStudio will prompt you when it is time to update and you can follow the same process of downloading and installing from the Posit website that we just did here. For R, there are a number of ways to do it, but the easiest is to use packages like installr for Windows and updateR for Mac. Here is a good blog post that walks you through the steps of how to update R using these packages. I usually update R once a semester.\nWe are going to be using a number of R packages throughout the course. One essential set of packages are those that comprise the Tidyverse, but especially readr, dplyr, ggplot2 and tidyr. You can install the entire Tidyverse collection of packages by typing install.packages(\"tidyverse\") in your console. We will talk about these packages in detail as we go through the course, but have a look at this basic description now to gain some basic familiarity.\nAnother thing that you really want to do is to make sure that you have the native pipe operator (|&gt;) enabled. In RStudio, go to Tools&gt;Global Options, then go to Code and select “Use native pipe operator.”\nWhile you are here, you can also go to Appearance to select a different editor theme or to Pane Layout to change how the four panes in R Studio are organized. Next, familiarize yourself with how to expand and minimize the four windows. The most important window that I want to highlight here is the source window. This is where we are going to be working most of the time in this course. And if I tell you to send your source code, I mean to send the file that you are working on in this window. This could be a Quarto document, an R script or an app.R file for a Shiny app.\nThe next window is the Console and there we also see tabs for Terminal and Background Jobs. The console is where you can run R code one line at a time. The terminal is relevant for more advanced users and we will make some use of it when we talk about publishing Quarto documents. Background Jobs is going to be helpful when we want troubleshoot a Quarto document that is not rendering properly.\nFrom there, the next pane we want to explore is Environment, History, etc. Environment tells us what files are currently available to us. The other important tab here is Git which will be where we push things to GitHub. You will be using this a lot in the course.\nFinally, we see a pane with Files, Plots, Packages etc. Files tells us what files are in our project folder and enables us to copy, and delete files associated with our project. Plots is a window for viewing our visualizations. And Packages shows us what packages are available and loaded into our environment.\nBefore you move on to the next section, take some time to familiarize yourself with the various user-friendly buttons and shortcuts available to you like the drop down menu for the pane layout, a spell checker, a button for inserting a code chunk and other features that you can play around with."
  },
  {
    "objectID": "modules/getting-started.html#quarto",
    "href": "modules/getting-started.html#quarto",
    "title": "Getting Started",
    "section": "Quarto",
    "text": "Quarto\n\nOnce you have R, R Studio and Quarto installed, you are ready to start integrating text and code with Quarto. Quarto is an open source publishing platform that enables you to integrate text with code. If you have used R Markdown before then Quarto will look familiar to you because Quarto is the next generation of R Markdown.\nRStudio comes with a version of Quarto already installed, but it can be useful to install the most recent version separately and because doing so will allow you to use Quarto with another IDE like VS Code. You can install the most recent version of Quarto by visiting this page and selecting the version for your operating system.\nNow take a little time to create a Quarto project in R Studio and make sure everything is working properly. But before you get started, create a new folder(directory) for this course on your computer somewhere. Once that is done, go to File &gt; New Project. Then select Quarto Project and name the project something like “test-project” in the Directory name field. Next, select Browse and navigate to the folder that you created for this course. Select Create Project.\nYou will notice that in your new project folder there is a file with an .Rproj extension. The .Rproj file is what tells RStudio which files are associated with the project and it obviates the need to set the working directory. It also makes it possible to share the folder with anyone who is running R and RStudio and have them run your code without having to set a working directory. This is what we refer to as a project-based workflow and we will use it for every assignment in this class.\nNow try rendering the document with the Render toggle button. By default, Quarto renders an .html file that it will open in a browser and save to your project folder.\nNext we want to try rendering a .pdf document. To do this, we have to install tinytex, a lightweight version of LaTeX. To do this, go to the Terminal and type quarto install tinytex. Now, change the format from html to pdf by inserting format: pdf in the YAML header. Then render the document again. A .pdf document should open up.\nNow take a few minutes and try changing more of the code in the YAML header. You can try changing the title, adding a subtitle (subtitle:) or changing the execution options. By default, Quarto uses the visual editor but behind the scenes it is using Markdown. Try and edit some text using the toggle buttons available in the visual editor and then switch to Source to view the underlying Markdown code. Play with the R code chunks embedded in the document or try adding new code chunks.\nYou may already have some experience writing in Markdown, which is a lightweight markup language that enables you to format plaintext files. If you have not used Markdown, or if your memory is hazy, don’t worry: it is really easy to learn. Have a look at this Markdown cheat sheet and try to familiarize yourself with its basic syntax. Finally, take some time to get familiar with the Guide and Reference sections of the Quarto website. Then take a look at the gallery so that you can get an idea of the kinds of things you can produce with Quarto."
  },
  {
    "objectID": "modules/getting-started.html#github",
    "href": "modules/getting-started.html#github",
    "title": "Getting Started",
    "section": "GitHub",
    "text": "GitHub\n\nGitHub is a platform for hosting version control repositories. In this course we will learn to use GitHub to store, manage and collaborate on code.\nOne central concept you want to be familiar with is a repository or “repo” for short. Repos are essentially folders where code can be stored and then accessed and changed by multiple users. All of the assignments for this course will be managed in repos.\nGitHub repos are managed using a version control system named Git. Git allows developers to make and track changes to the code stored in the repo. Git also enables users to create branches to work on the code without affecting the main codebase and then merge those changes back into the main branch when they are ready.\nThe first thing you are going to want to do is to register a GitHub account. From there, you want to install Git and initiate Git using the usethis package.\nNext, you need to generate a personal access token (PAT) and set your credentials with the gitcreds package.\nNow, you can create a GitHub repo and clone it to your computer in RStudio. There a number of ways to clone a repo, but the recommended method for this course involves creating a new project in RStudio and selecting “Version Control” for the method (instead of “New Directory” as we did before). From there, select “Git”, copy the URL from the green “Code” tab in the GitHub repo, and paste it into “Repository URL” field. Next, select the directory where you want the repository to be created and click “create project.”"
  },
  {
    "objectID": "modules/getting-started.html#github-classroom",
    "href": "modules/getting-started.html#github-classroom",
    "title": "Getting Started",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\n\n\nGive a brief overview of GitHub Classroom and how to use it.\nPerhaps have students download a mock assignment to illustrate how it works."
  },
  {
    "objectID": "modules/module-1.1.html",
    "href": "modules/module-1.1.html",
    "title": "Module 1.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall R, R Studio and the Tidyverse collection of packages if you have not done so already (see getting started)\nInstall the janitor package (install.packages(\"janitor\"))\nHave a look at the documentation for readr, dplyr, tidyr and janitor\n\nFamiliarize yourself with the readr, dplyr and tidyr cheatsheets\nCreate a new directory/folder in your project folder called “data” where you can store .csv files\nStart a new quarto project called “modules” and generate a quarto document named “module-1.1.qmd” inside of it so that you can code along with me"
  },
  {
    "objectID": "modules/module-1.1.html#overview",
    "href": "modules/module-1.1.html#overview",
    "title": "Module 1.1",
    "section": "Overview",
    "text": "Overview\nIn this module, we are going to work with a “flat file” (.csv) that we will download from the World Bank’s Data Bank. We are going to encounter many problems with these data that we will rectify using various R packages that I will introduce along the way. The idea is to take this file in its current state and transform it into a tidy dataset where each column represents a variable, each row represents an observation, and each cell represents a single value."
  },
  {
    "objectID": "modules/module-1.1.html#downloading-world-bank-data-into-a-flat-file",
    "href": "modules/module-1.1.html#downloading-world-bank-data-into-a-flat-file",
    "title": "Module 1.1",
    "section": "Downloading World Bank data into a flat file",
    "text": "Downloading World Bank data into a flat file\n\nGo to the World Development Indicators portal at the World Bank’s Data Bank.\nUnder Countries, select the Countries tab and then select the little check mark ☑️ to select all of the countries. Be sure to select the Countries tab first, though, or you will also be downloading aggregate data for regions and groups of countries.\nNext, under Series, search for “labor force participation” and find labor force participation rates for women ages 15-64 (ILO modeled estimates). Check that series.\nNow go to Time and select the years from the last 50 years. Click Apply Changes, go to Download Options and download as a .csv file. Place the .csv file in the data directory that you created for this module. Save it as “messy_wb_data.csv” or something like that."
  },
  {
    "objectID": "modules/module-1.1.html#reading-data-from-a-flat-file",
    "href": "modules/module-1.1.html#reading-data-from-a-flat-file",
    "title": "Module 1.1",
    "section": "Reading data from a flat file",
    "text": "Reading data from a flat file\n\nNow we are going to read this messy World Bank data into R using the read_csv() function from the readr package. readr is a collection of functions that parses data from a flat file into a tibble, the modern Tidyverse version of a data frame. After we have read the data into R, we are going to have a look at it with the glimpse() function from the dplyr package.\nglimpse() shows us a list of the columns in the along with their type (e.g. character, double, etc.) and a few rows’ worth of data.\n\n\n\n\n\n\nNote\n\n\n\nWhile comma delimited files are the most common kind of flat file, readr includes functions for parsing files with a wide range of delimiters including tabs (read_tsv()), semicolons (read_csv2()) and white spaces (read_table()). There is also a Tidyverse package for reading in Excel files called readxl.\n\n\n\n# Load packages\nlibrary(readr) \nlibrary(dplyr) \n\n# Read data from csv file into an object called \"wb_data_messy\"\nwb_data_messy &lt;- read_csv(\"data/messy_wb_data.csv\")\n\n# View the data\nglimpse(wb_data_messy)\n\nRows: 222\nColumns: 54\n$ `Country Name`  &lt;chr&gt; \"Afghanistan\", \"Albania\", \"Algeria\", \"American Samoa\",…\n$ `Country Code`  &lt;chr&gt; \"AFG\", \"ALB\", \"DZA\", \"ASM\", \"AND\", \"AGO\", \"ATG\", \"ARG\"…\n$ `Series Name`   &lt;chr&gt; \"Labor force participation rate, female (% of female p…\n$ `Series Code`   &lt;chr&gt; \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI…\n$ `1972 [YR1972]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1973 [YR1973]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1974 [YR1974]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1975 [YR1975]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1976 [YR1976]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1977 [YR1977]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1978 [YR1978]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1979 [YR1979]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1980 [YR1980]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1981 [YR1981]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1982 [YR1982]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1983 [YR1983]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1984 [YR1984]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1985 [YR1985]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1986 [YR1986]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1987 [YR1987]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1988 [YR1988]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1989 [YR1989]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `1990 [YR1990]` &lt;chr&gt; \"15.83\", \"60.63\", \"12.31\", \"..\", \"..\", \"76.73\", \"..\", …\n$ `1991 [YR1991]` &lt;chr&gt; \"15.89\", \"65.54\", \"12.33\", \"..\", \"..\", \"76.69\", \"..\", …\n$ `1992 [YR1992]` &lt;chr&gt; \"15.92\", \"66.56\", \"12.37\", \"..\", \"..\", \"76.66\", \"..\", …\n$ `1993 [YR1993]` &lt;chr&gt; \"15.91\", \"65.01\", \"12.41\", \"..\", \"..\", \"76.68\", \"..\", …\n$ `1994 [YR1994]` &lt;chr&gt; \"15.88\", \"63.64\", \"12.47\", \"..\", \"..\", \"76.64\", \"..\", …\n$ `1995 [YR1995]` &lt;chr&gt; \"15.92\", \"61.59\", \"12.56\", \"..\", \"..\", \"76.57\", \"..\", …\n$ `1996 [YR1996]` &lt;chr&gt; \"15.75\", \"60.28\", \"12.64\", \"..\", \"..\", \"76.55\", \"..\", …\n$ `1997 [YR1997]` &lt;chr&gt; \"15.59\", \"61.91\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", …\n$ `1998 [YR1998]` &lt;chr&gt; \"15.47\", \"60.62\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", …\n$ `1999 [YR1999]` &lt;chr&gt; \"15.4\", \"58.87\", \"12.63\", \"..\", \"..\", \"76.51\", \"..\", \"…\n$ `2000 [YR2000]` &lt;chr&gt; \"15.35\", \"57.89\", \"12.71\", \"..\", \"..\", \"76.49\", \"..\", …\n$ `2001 [YR2001]` &lt;chr&gt; \"15.5\", \"56.71\", \"12.85\", \"..\", \"..\", \"76.48\", \"..\", \"…\n$ `2002 [YR2002]` &lt;chr&gt; \"15.7\", \"56.06\", \"13.02\", \"..\", \"..\", \"76.44\", \"..\", \"…\n$ `2003 [YR2003]` &lt;chr&gt; \"15.92\", \"55.3\", \"13.24\", \"..\", \"..\", \"76.41\", \"..\", \"…\n$ `2004 [YR2004]` &lt;chr&gt; \"16.13\", \"54.57\", \"13.5\", \"..\", \"..\", \"76.38\", \"..\", \"…\n$ `2005 [YR2005]` &lt;chr&gt; \"16.33\", \"53.88\", \"13.79\", \"..\", \"..\", \"76.36\", \"..\", …\n$ `2006 [YR2006]` &lt;chr&gt; \"16.12\", \"53.43\", \"14.12\", \"..\", \"..\", \"76.39\", \"..\", …\n$ `2007 [YR2007]` &lt;chr&gt; \"15.91\", \"53.07\", \"14.47\", \"..\", \"..\", \"76.42\", \"..\", …\n$ `2008 [YR2008]` &lt;chr&gt; \"15.74\", \"52.78\", \"14.87\", \"..\", \"..\", \"76.46\", \"..\", …\n$ `2009 [YR2009]` &lt;chr&gt; \"15.65\", \"51.57\", \"15.31\", \"..\", \"..\", \"76.53\", \"..\", …\n$ `2010 [YR2010]` &lt;chr&gt; \"15.65\", \"52.75\", \"15.49\", \"..\", \"..\", \"76.59\", \"..\", …\n$ `2011 [YR2011]` &lt;chr&gt; \"16\", \"60.59\", \"16.45\", \"..\", \"..\", \"76.67\", \"..\", \"55…\n$ `2012 [YR2012]` &lt;chr&gt; \"16.44\", \"55.1\", \"17.48\", \"..\", \"..\", \"76.73\", \"..\", \"…\n$ `2013 [YR2013]` &lt;chr&gt; \"17.42\", \"50.58\", \"18.29\", \"..\", \"..\", \"76.79\", \"..\", …\n$ `2014 [YR2014]` &lt;chr&gt; \"18.46\", \"50.18\", \"16.68\", \"..\", \"..\", \"76.83\", \"..\", …\n$ `2015 [YR2015]` &lt;chr&gt; \"19.55\", \"54.05\", \"17.5\", \"..\", \"..\", \"76.87\", \"..\", \"…\n$ `2016 [YR2016]` &lt;chr&gt; \"20.7\", \"56.4\", \"18.33\", \"..\", \"..\", \"76.9\", \"..\", \"56…\n$ `2017 [YR2017]` &lt;chr&gt; \"21.91\", \"55.54\", \"19.19\", \"..\", \"..\", \"76.91\", \"..\", …\n$ `2018 [YR2018]` &lt;chr&gt; \"22.32\", \"59.12\", \"18.95\", \"..\", \"..\", \"76.9\", \"..\", \"…\n$ `2019 [YR2019]` &lt;chr&gt; \"22.74\", \"61.46\", \"18.7\", \"..\", \"..\", \"76.88\", \"..\", \"…\n$ `2020 [YR2020]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …\n$ `2021 [YR2021]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", …"
  },
  {
    "objectID": "modules/module-1.1.html#reshaping-data",
    "href": "modules/module-1.1.html#reshaping-data",
    "title": "Module 1.1",
    "section": "Reshaping data",
    "text": "Reshaping data\n\nThere are a few things about the data here that make it messy. First, in order for the data to be tidy, we want each column to represent a variable and each row to represent an observation.\nBut here we see the reverse: the data are in wide form, meaning that each column represents a year and each row represents a country. This entails that each row represents multiple observations in that we have data for multiple years for each row.\nTo rectify this, we need to reshape the data from wide form to long form. For this, we need the pivot_longer() function from the tidyr package.\nThe pivot_longer() function takes three basic arguments:\n\n\ncols - which columns you want to pivot\n\nnames_to - the name of the column where the old column names are going to\n\nvalues_to - the name of the column where the values are going to\n\nIn our case, we want to reshape all of the year columns and have the years represented in the rows. We want the newly created column to be called “year” and the values are going to represent the data on female labor force participation we downloaded (flfp).\n\n# Load tidyr\nlibrary(tidyr)\n\n# Reshape the data\nwb_data &lt;- wb_data_messy |&gt; # take wb_data_messy, and put it in wb_data, but first...\n  pivot_longer(             # pivot the data from wide to long form\n    cols = `1972 [YR1972]`: `2021 [YR2021]`, # columns to pivot\n    names_to = \"year\", # name the first column \"year\"\n    values_to = \"flfp\" # name the second column \"flfp\"\n  ) \n\n# View the data\nglimpse(wb_data)\n\nRows: 11,100\nColumns: 6\n$ `Country Name` &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist…\n$ `Country Code` &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",…\n$ `Series Name`  &lt;chr&gt; \"Labor force participation rate, female (% of female po…\n$ `Series Code`  &lt;chr&gt; \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.…\n$ year           &lt;chr&gt; \"1972 [YR1972]\", \"1973 [YR1973]\", \"1974 [YR1974]\", \"197…\n$ flfp           &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"…\n\n\n\n\n\n\n\n\nThe Pipe Operator\n\n\n\nFor our pivot-longer() call we used R’s native pipe operator, e.g. |&gt;. Pipes tell R to do something to the object that they are attached to. In this case, we are telling R to apply pivot_longer() to wb_data. The alternative way of writing this code would be to include the data as the first argument in the function, e.g. pivot_longer(wb_data, cols = ..., names_to = ... , values_to = ...). As you will see, pipe operators enable us to string together multiple functions in a convenient way to transform our data.\n\n\n\n\n\n\n\n\nSpaces in Variable Names\n\n\n\nNotice that when we specify the years in our pivot_longer() call we encapsulate them in backticks (``). This is because the years, as they were imported from the WDI dataset, have spaces in them. Typically we want to avoid this scenario by writing our variable names in snake_case."
  },
  {
    "objectID": "modules/module-1.1.html#truncating-strings-and-changing-variable-types",
    "href": "modules/module-1.1.html#truncating-strings-and-changing-variable-types",
    "title": "Module 1.1",
    "section": "Truncating strings and changing variable types",
    "text": "Truncating strings and changing variable types\n\nNow that our data are transposed, we can start to work on some other key issues. Notice that the year is stored in the weird way in which it was imported–as a character (or string) with both the year and the year in brackets, e.g. 1972 [YR1972]. Notice that flfp is also stored as a character whereas it should be numeric.\nTo fix this, we will use the mutate() and mutate_at() functions from dplyr. mutate() is used to transform variables and to create new ones while mutate_at() allow us to transform multiple columns at once.\nFirst we call mutate() along with substring() to truncate the year variable to only include the first four characters of the string. Then we call mutate_at() along with as.numeric to transform year and flfp to numeric variables.\n\n# Fix year and flfp\nwb_data &lt;- wb_data |&gt; # replace wb_data with a modified version of the dataframe \n  mutate(year = substring(year, 1, 4)) |&gt; # truncate year (keep first four characters)\n  mutate_at(c(\"year\", \"flfp\"), as.numeric) # change year and flfp to numeric\n\n# View the data\nglimpse(wb_data)\n\nRows: 11,100\nColumns: 6\n$ `Country Name` &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist…\n$ `Country Code` &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",…\n$ `Series Name`  &lt;chr&gt; \"Labor force participation rate, female (% of female po…\n$ `Series Code`  &lt;chr&gt; \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.…\n$ year           &lt;dbl&gt; 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1…\n$ flfp           &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…"
  },
  {
    "objectID": "modules/module-1.1.html#cleaning-variable-names",
    "href": "modules/module-1.1.html#cleaning-variable-names",
    "title": "Module 1.1",
    "section": "Cleaning variable names",
    "text": "Cleaning variable names\n\nThe last thing we are going to do is to fix the variable names. Specifically, we want to remove the spaces from the remaining variables and conver them from title case to snake case. To do this, we will use the clean_names() function from the janitor package.\nAs a final step, we can export our clean data to a new .csv file with the write.csv() function from readr.\n\n# Load janitor\nlibrary(janitor)\n\n# Apply clean_names() to wb_data, store in new data frame called wb_data_clean\nwb_data_clean &lt;- wb_data |&gt;  \n  clean_names() \n\n# Write wb_data_clean to a csv file\nwrite_csv(wb_data_clean, \"data/wb_data_clean.csv\")\n\n# View the data\nglimpse(wb_data_clean)\n\nRows: 11,100\nColumns: 6\n$ country_name &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan…\n$ country_code &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"…\n$ series_name  &lt;chr&gt; \"Labor force participation rate, female (% of female popu…\n$ series_code  &lt;chr&gt; \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE…\n$ year         &lt;dbl&gt; 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 198…\n$ flfp         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  },
  {
    "objectID": "modules/module-1.2.html",
    "href": "modules/module-1.2.html",
    "title": "Module 1.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall the devtools package. Type install.packages(\"devtools\") in your console. You will need this to install the vdemdata package because it is not on the CRAN Network.\nInstall the vdemdata package from GitHub. Type devtools::install_github(\"vdeminstitute/vdemdata\") in your console.\nInstall the wbstats and countrycode packages:\n\n\npkg_list &lt;- c(\"wbstats\", \"countrycode\") # create a list of packages\ninstall.packages(pkg_list) # install the packages\n\n\nHave a look at the vignettes for wbstats and the countrycode documentation\nGenerate a quarto document named “module-1.2.qmd” in your modules project folder so that you can code along with me"
  },
  {
    "objectID": "modules/module-1.2.html#overview",
    "href": "modules/module-1.2.html#overview",
    "title": "Module 1.2",
    "section": "Overview",
    "text": "Overview\nIn this module working, we are going to be working with data from APIs instead of flat files. As we saw in the last lesson, importing and wrangling data from flat files can be a messy process. So when clean data are available for download, we want to be able to take advantage of that. Luckily there are some pretty good R packages that allow us to extract data from open source APIs. We are going to be working with two of those in this module (wbstats and vdemdata) and some others later in the course.\nAlong the way, we are going to continue to extend our data wrangling skills. We will learn some new functions in dplyr and janitor that will help us get our data into a usable form for analysis. We are also going to cover in depth some common data science workflows, including filtering observations, selecting variables, merging two data sets, summarizing data for different groups, and sorting data based on column values.\nThe end goal is to have a nice dataset with a combination of World Bank and V-Dem Institute data that we can use to illustrate the relationship between the economy, democracy and women’s empowerment."
  },
  {
    "objectID": "modules/module-1.2.html#downloading-data-from-an-api",
    "href": "modules/module-1.2.html#downloading-data-from-an-api",
    "title": "Module 1.2",
    "section": "Downloading data from an API",
    "text": "Downloading data from an API\n\nYou will no doubt remember the messy data that we downloaded from the World Bank’s website in module 1.1. Usually it is much easier to download data from an API as opposed to wrangling it from a .csv file. In this example, I want to illustrate that for you by having you download the same data that we worked with in the last module using the wbstats package.\nFirst we are going to load wbstats along with dplyr and janitor. The wb_data() function is the one we need to download the data from the World Bank’s API. wb_data() requires to main sets of arguments: a list of indicators that we want to use and the period for which we want to download data. The period can can be entered as two separate arguments (e.g. start_date and end_date). But for this exercise we will specify the number of years we want to download using mrv which stands for “most recent value.”\nIn addition to female labor force participation, let’s also grab the percentage of seats in parliament held by women. We will store that list of objects in a vector called women_emp to signify that these indicators are related to women’s empowerment. We will try to download 50 years of data for these two variables.\n\n\n\n\n\n\nNote\n\n\n\nIf you want to search World Bank data for additional indicators, you can use the wb_search() function. For example, if we wanted to find all of the indicators associated with female labor force participation, we could run:\n\nflfp_indicators &lt;- wb_search(\"female labor force\") # store the list of indicators\n\nprint(flfp_indicators, n=26) # view the indicators\n\nTry searching for some indicators related to a topic you are interested in and see what you get!\n\n\nWhile we are calling wb_data() we will go ahead and pipe some additional functions from dplyr and janitor to clean it up. First, we will use select() to eliminate the iso2c variable, which we won’t be needing. Then, we will rename date to year. Then we will use a combination of mutate and round_to_fraction() to round the data to the nearest hundredth.\nWe will pipe all of these functions together and store the resulting data frame in a new object called women_emp.\n\n# Load packages\nlibrary(wbstats) # for downloading WB data\nlibrary(dplyr) # for selecting, renaming and mutating\nlibrary(janitor) # for rounding\n\n# Store the list of indicators in an object\nindicators &lt;- c(\"flfp\" = \"SL.TLF.CACT.FE.ZS\", \"women_rep\" = \"SG.GEN.PARL.ZS\") \n\n# Download the data  \nwomen_emp &lt;- wb_data(indicators, mrv = 50) |&gt; # download data for last 50 yrs\n  select(!iso2c) |&gt; # drop the iso2c code which we won't be using\n  rename(year = date) |&gt; # rename date to year \n  mutate(\n    flfp = round_to_fraction(flfp, denominator = 100), # round to nearest 100th\n    women_rep = round_to_fraction(women_rep, denominator = 100) \n  )\n\n# View the data\nglimpse(women_emp) \n\nRows: 7,161\nColumns: 5\n$ iso3c     &lt;chr&gt; \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW…\n$ country   &lt;chr&gt; \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba…\n$ year      &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, …\n$ women_rep &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ flfp      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\nNow we have some pretty tidy World Bank data related to women’s empowerment without having to do too much work. I am sure you would agree that this is a much more straightforward process than downloading the data and then importing the data as a flat file!\nOne thing that becomes very clear here is that wb_data() did not download any data before 1990. It automatically filtered out the years for which all countries had no data. The fact there were no data before 1990 for any of the countries is easily missed when we were simply importing it from a .csv file."
  },
  {
    "objectID": "modules/module-1.2.html#filter-observations-select-and-create-new-variables",
    "href": "modules/module-1.2.html#filter-observations-select-and-create-new-variables",
    "title": "Module 1.2",
    "section": "Filter observations, select and create new variables",
    "text": "Filter observations, select and create new variables\n\nThe next thing we want to talk about is how to filter observations and to select new variables. We also delve more into the topic of how to create new variables. To illustrate these concepts, we are going to be working with the V-Dem Dataset. The V-Dem offers an R package for downloading its data called vdemdata.\nvdemdata is perfect for illustrating the filter() and select() verbs because its main function for downloading the data (vdem) does not take any arguments (it simply downloads the whole dataset). So you have to use R functions to narrow down the variables and years you want to work with.\nWhile V-Dem has wealth of indicators related to democracy, we are going to focus on the most famous one called the “polyarchy” score. We are also going to download data on per capita GDP and create some indicator variables for region that we will use later on when we summarize the data. Along with those variables, we also want to retain country_name, year and country_id for the purposes of merging these data with our World Bank data.\n\n\n\n\n\n\nNote\n\n\n\nWhile V-Dem has a variable look-up tool (find_var), it does not provide very much information on the variables that the search function returns. Therefore, if you want to use this package for your own research, I highly recommend just going to the V-Dem codebook and manually grabbing the codes for the indicators that you want to use in your analysis.\n\n\nIn addition to filtering out years and selecting variables, let’s also create a region coding to facilitate our analysis later on. We will do this by piping in a mutate() call where we use the case_match() function to change the region from a numeric variable to a string. This will come in handy when we go to visualize the data in future lessons.\nWe will store our new data as an object called democracy.\n\n# Load packages\nlibrary(vdemdata) # to download V-Dem data\n\n# Download the data\ndemocracy &lt;- vdem |&gt; # download the V-Dem dataset\n  filter(year &gt;= 1990)  |&gt; # filter out years less than 1990\n  select(                  # select (and rename) these variables\n    country = country_name,     # the name before the = sign is the new name  \n    vdem_ctry_id = country_id,  # the name after the = sign is the old name\n    year, \n    polyarchy = v2x_polyarchy, \n    gdp_pc = e_gdppc, \n    region = e_regionpol_6C\n    ) |&gt;\n  mutate(\n    region = case_match(region, # replace the values in region with country names\n                     1 ~ \"Eastern Europe\", \n                     2 ~ \"Latin America\",  \n                     3 ~ \"Middle East\",   \n                     4 ~ \"Africa\", \n                     5 ~ \"The West\", \n                     6 ~ \"Asia\")\n                    # number on the left of the ~ is the V-Dem region code\n                    # we are changing the number to the country name on the right\n                    # of the equals sign\n  )\n\n# View the data\nglimpse(democracy)\n\nRows: 5,846\nColumns: 6\n$ country      &lt;chr&gt; \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico…\n$ vdem_ctry_id &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n$ year         &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199…\n$ polyarchy    &lt;dbl&gt; 0.396, 0.418, 0.441, 0.451, 0.472, 0.489, 0.511, 0.560, 0…\n$ gdp_pc       &lt;dbl&gt; 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1…\n$ region       &lt;chr&gt; \"Latin America\", \"Latin America\", \"Latin America\", \"Latin…"
  },
  {
    "objectID": "modules/module-1.2.html#add-country-codes-to-a-data-frame",
    "href": "modules/module-1.2.html#add-country-codes-to-a-data-frame",
    "title": "Module 1.2",
    "section": "Add country codes to a data frame",
    "text": "Add country codes to a data frame\n\nOne common problem scholars face when they want to analyze country-level data is the fact that datasets use different country codes. This can make it challenging to combine datasets, thus limiting the potential scope of our analysis. Lucikly, there is a wonderful package called countrycode that can help to solve this problem.\nThe countrycode() function creates a new country code variable in our dataset that matches the country code variable of the second dataset that we are trying to merge it to. countrycode() takes three arguments: sourcevar; origin; and destination. sourcevar identifies the name of the column that you want to transform, origin is the coding system that you want to translate from, and destination is the coding system that you want to translate to.\nIn this next step of our analysis, we are going to join the World Bank and V-Dem data that we wrangled into a single dataset. To do that we need a common country code. The way we are going to do this is to create a new country code variable in the democracy dataset that matches the one in the women’s empowerment dataset.\nLet’s create a new version of our democracy dataset where we add a variable called iso3c. We will call mutate() to create the variable and wrap the countrycode() call inside of that. The sourcevar that we want to transform is the vdem_ctry_id, the origin code is “vdem”, and the destination code is “wb”.\nWe are also going to pipe in a relocate() call which simply moves the new iso3c column from the end of the data frame (where R automically drops it) so that it sits right next to vdem_ctry_cd. This is not essential but it is always good to keep our data frames looking nice and neat!.\n\n# Load countrycode\nlibrary(countrycode)\n\n# Create new iso3c variable\ndemocracy &lt;- democracy |&gt;    \n  mutate(iso3c = countrycode(sourcevar = vdem_ctry_id, # what we are converting\n        origin = \"vdem\",         # we are converting from vdem\n        destination = \"wb\"))  |&gt; # and converting to the WB iso3c code \n  relocate(iso3c, .after = vdem_ctry_id) # move iso3c \n\n# View the data\nglimpse(democracy)\n\nRows: 5,846\nColumns: 7\n$ country      &lt;chr&gt; \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico…\n$ vdem_ctry_id &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n$ iso3c        &lt;chr&gt; \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"…\n$ year         &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199…\n$ polyarchy    &lt;dbl&gt; 0.396, 0.418, 0.441, 0.451, 0.472, 0.489, 0.511, 0.560, 0…\n$ gdp_pc       &lt;dbl&gt; 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1…\n$ region       &lt;chr&gt; \"Latin America\", \"Latin America\", \"Latin America\", \"Latin…"
  },
  {
    "objectID": "modules/module-1.2.html#merge-two-datasets",
    "href": "modules/module-1.2.html#merge-two-datasets",
    "title": "Module 1.2",
    "section": "Merge two datasets",
    "text": "Merge two datasets\n\nNow that we have a common country code, we can join the two data sets. There are many different types of joins. First there is a distinction between mutating joins, which add observations from one dataset to another, and filtering joins, which filter out observations based on their presence or absence in another dataset. Here we are going to be focused on mutating joins.\nThere are four kinds of mutating joins we can do in dplyr. An inner_join() keeps only the observations that are common in both datasets that you want to merge. A full_join() does the opposite. It keeps all of the observations present in both datasets regardless of whether or not they have a match. A left_join() keeps all of the observations in dataset \\(x\\) and only the matching observations in dataset \\(y\\). A right_join() does the same thing, but instead keeps all of the observations from dataset \\(y\\) and only matching observations from dataset \\(x\\).\nWe are going to use left_join() to merge our two datasets. left_join() takes three essential arguments: \\(x\\); \\(y\\); and \\(by\\) which identifies the column that we want to join on. For this exercise, the \\(x\\) dataset is going to be the democracy dataset, the \\(y\\) dataset is the women empowerment dataset, and we want to join on both the “iso3c” and “year” columns.\nWhen dplyr does a join, it renames any duplicate columns with suffixes like .x or .y. In our data, country is a duplicate column across the democracy and women’s empowerment datasets. So dplyr renames these country.x and country.y. It doesn’t really matter which one we keep, so let’s just rename country.x to country and filter out country.y using select().\nWe can can pipe all of these functions together and store the resulting data frame in a new object called dem_women. Let’s also save these data as a .csv file for future use with write_csv(). The first argument for write_csv() is the name of the data frame or tibble that we want to save. The second argument is the path and name of the file that we want to save it to.\n\n# Load readr\nlibrary(readr)\n\n# Perform left join using common iso3c variable and year\ndem_women &lt;- left_join(democracy, women_emp, by = c(\"iso3c\", \"year\")) |&gt; \n  rename(country = country.x) |&gt; # rename country.x\n  select(!country.y)             # crop country.y\n\n# Save as .csv for future use\nwrite_csv(dem_women, \"data/dem_women.csv\")\n\n# View the data\nglimpse(dem_women)  \n\nRows: 5,667\nColumns: 9\n$ country      &lt;chr&gt; \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico…\n$ vdem_ctry_id &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n$ iso3c        &lt;chr&gt; \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"…\n$ year         &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199…\n$ polyarchy    &lt;dbl&gt; 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0…\n$ gdp_pc       &lt;dbl&gt; 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1…\n$ region       &lt;chr&gt; \"Latin America\", \"Latin America\", \"Latin America\", \"Latin…\n$ women_rep    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 14.20, 17.40, 18.20, 16.00, 1…\n$ flfp         &lt;dbl&gt; 33.94, 34.24, 35.01, 35.85, 36.38, 37.62, 37.69, 39.65, 3…"
  },
  {
    "objectID": "modules/module-1.2.html#group-summarize-and-arrange",
    "href": "modules/module-1.2.html#group-summarize-and-arrange",
    "title": "Module 1.2",
    "section": "Group, summarize and arrange",
    "text": "Group, summarize and arrange\n\nNow that we have completed all of the wrangling, let’s do something with it. A common sequence in data science is group by(), summarize() and arrange(). First, we group the data by certain value or category. Then we summarize it by applying a function like min(), max(), mean(), median() or sd(). Finally, we order the data according to column values.\nLet’s go ahead and apply our three new verbs to the dem_women data frame and store the resulting new data frame in an object called dem_summary. We will group the data by region, take the mean of each variable, and sort the data in descending order based on the regions’ polyarchy scores. Then we will print the object to view its contents. Along the way, we let’s also export the data to a .csv file for future use.\n\n\n\n\n\n\nNote\n\n\n\nTo print an object in R, we can either use the print() function or just execute the name of the object. Oftentimes it is simpler to just execute the name of the object.\n\n\n\n# group_by(), summarize() and arrange()\ndem_summary &lt;- dem_women |&gt; # save result as new object\n  group_by(region)  |&gt; # group dem_women data by region\n  summarize(           # summarize following vars (by region)\n    polyarchy = mean(polyarchy, na.rm = TRUE), # calculate mean, remove NAs\n    gdp_pc = mean(gdp_pc, na.rm = TRUE), \n    flfp = mean(flfp, na.rm = TRUE), \n    women_rep = mean(women_rep, na.rm = TRUE)\n  ) |&gt; \n  arrange(desc(polyarchy)) # arrange in descending order by polyarchy score\n\n# Save as .csv for future use\nwrite_csv(dem_summary, \"data/dem_summary.csv\")\n\n# View the data\nglimpse(dem_summary)\n\nRows: 6\nColumns: 5\n$ region    &lt;chr&gt; \"The West\", \"Latin America\", \"Eastern Europe\", \"Asia\", \"Afri…\n$ polyarchy &lt;dbl&gt; 0.8709230, 0.6371358, 0.5387451, 0.4076602, 0.3934166, 0.245…\n$ gdp_pc    &lt;dbl&gt; 37.913054, 9.610284, 12.176554, 9.746391, 4.410484, 21.134319\n$ flfp      &lt;dbl&gt; 52.99082, 48.12645, 50.45894, 50.32171, 56.69530, 26.57872\n$ women_rep &lt;dbl&gt; 28.12921, 21.32548, 17.99728, 14.45225, 17.44296, 10.21568"
  },
  {
    "objectID": "modules/module-2.1.html",
    "href": "modules/module-2.1.html",
    "title": "Module 2.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall the scales package (install.packages(\"scales\"))\nHave a look at the documentation for ggplot2\n\nFamiliarize yourself with the ggplot2 cheatseet\n\nGenerate a quarto document named “module-2.1.qmd” in youe modules project folder so that you can code along with me\n\nIf you have installed the Tidyverse, then you should already have the packages for this model, including ggplot2. You can go ahead and load ggplot2 along with readr and dplyr.\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nNote that you could also load these three packages by running library(tidyverse). However, it is good to be intentional about which packages we are loading as we are learning them."
  },
  {
    "objectID": "modules/module-2.1.html#overview",
    "href": "modules/module-2.1.html#overview",
    "title": "Module 2.1",
    "section": "Overview",
    "text": "Overview\nLast week we learned how to gather and wrangle data. This week we are going to start visualizing it with the ggplot2. We will learn how to make bar charts, histograms, line charts and scatter plots.\nAlong the way we are going to be talking about the “grammar of graphics” that ggplot2 is based on. The “gg” in ggplot stands for “grammar of graphics.” The grammar of graphics is a layered approach to constructing graphs based on a book by Leland Wilkinson.\nThe idea is that each visualization you make is going to contain cerain elements. You will start with some data. Then you will incorporate some “aesthetics” which you can think of as the dimensions of the visualization (x-axis, y-axis and color, size or shapes for additional dimensions). Next you identify a geometric obejct that you want to use such as a bar, a line or a point. From there you can customize various elements of the plot like the title and axis scales and labels."
  },
  {
    "objectID": "modules/module-2.1.html#bar-charts",
    "href": "modules/module-2.1.html#bar-charts",
    "title": "Module 2.1",
    "section": "Bar charts",
    "text": "Bar charts\n\nLet’s get started with our first visualization–a basic bar chart. Bar charts are good for comparing data across cases. Our aim here is going to be to summarize levels of democracy across different regions like we did in the last lesson, but this time we will illustrate the differences with a chart.\nWe will start by loading in the dem_summary.csv file that we made in the last lesson. Next we will do our first ggplot() call. The ggplot() function takes two arguments: data and mapping. data refers to the data frame that includes the variables we want to visualize and mapping refers to the aesthetics mappings for the visualization. The aesthetics mappings are themselves presented in a quoting function aes() that defines the x and y values of the plot along with other aesthetic values like fill, color and linetype. We will focus on x and y values here and return to these additional aesthetic values later.\nAfter our ggplot() call, we can add a series of additional functions to define our visualization following a + sign. The most important group are the geoms which will define the basic type of plot we want to make. In this case, we are calling geom_col() for our histogram and specifying that the fill color should be “steelblue.”\nFrom there we will further customize our visualization with the labs() function to provide a title, axis labels and a caption.\n\ndem_summary &lt;- read_csv(\"data/dem_summary.csv\")\n\nggplot(dem_summary, aes(x = region, y = polyarchy)) + # ggplot call\n  geom_col(fill = \"steelblue\") + # we use geom_col() for a a bar chart\n  labs(\n    x = \"Region\", \n    y = \"Avg. Polyarchy Score\", \n    title = \"Democracy by region, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )\n\n\n\n\nThis looks pretty good but frequently we would want the bars of our bar chart to be sorted in order of the values being displayed. Let’s go ahead and add the reorder() function to our aes() call so that we are reordering the bars based on descending values of the average polyarchy score.\n\nggplot(dem_summary, aes(x = reorder(region, -polyarchy), y = polyarchy)) +\n  geom_col(fill = \"steelblue\") + \n  labs(\n    x = \"Region\", \n    y = \"Avg. Polyarchy Score\", \n    title = \"Democracy by region, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )"
  },
  {
    "objectID": "modules/module-2.1.html#histograms",
    "href": "modules/module-2.1.html#histograms",
    "title": "Module 2.1",
    "section": "Histograms",
    "text": "Histograms\n\nNow let’s do another ggplot() call to make a histogram. We use histograms when we want to show how our data are distributed.\nWe’ll start by reading in the dem_women.csv file from our previous lesson. From there, we call ggplot(), specifying the polyarchy score on x-axis. But this time we change the geom to geom_histogram(). We also change the title and axis labels to reflect the fact that we are plotting the number of cases falling in each bin.\n\n\n\n\n\n\nNote\n\n\n\nNote that we leave the y-axis blank for the histogram because ggplot will automatically know to plot the number of units in each bin on the y-axis.\n\n\n\ndem_women_2015 &lt;- read_csv(\"data/dem_women.csv\") |&gt; \n  filter(year == 2015) \n\nggplot(dem_women_2015, aes(x = polyarchy)) + # only specify x for histogram\n  geom_histogram(fill = \"steelblue\") + # geom is a histogram\n  labs(\n    x = \"Polyarchy Score, 2015\", \n    y = \"Count\",\n    title = \"Distribution of democracy, 2015\", \n    caption = \"Source: V-Dem Institute\"\n    )"
  },
  {
    "objectID": "modules/module-2.1.html#line-charts",
    "href": "modules/module-2.1.html#line-charts",
    "title": "Module 2.1",
    "section": "Line charts",
    "text": "Line charts\n\nNow let’s create a line chart. Line charts are usually the best option when we want to illustrate trends in our data. For this visualization, we will try to illustrate Samuel Huntington’s waves of democracy by showing how countries representing each of the three waves. The U.S. represents the first wave, Japan the second wave starting with the allied victory in WWII, and Portugal represents the first country to transition in the third wave.\nFirst, let’s grab the relevant data using vdemdata and dplyr. We are going to be downloading the polyarchy measure for the U.S., Japan and Portugal as far back as the data are available. So first we will select country name, year and the polyarchy schore and then we will filter the data based on the three country names. We are saving these data in an object called dem_waves_ctrs.\n\nlibrary(vdemdata)\n\ndem_waves_ctrs &lt;- vdem |&gt;\n  select(\n    country = country_name,     \n    year, \n    polyarchy = v2x_polyarchy, \n  ) |&gt;\n  filter( \n    country %in% c(\"United States of America\", # select countries in this list\n                   \"Japan\", \n                   \"Portugal\")\n    )\n\nwrite_csv(dem_waves_ctrs, \"data/dem_waves_ctrs.csv\")\n\nNext, we are going to do our ggplot() call. The data will be the dem_waves_ctrs object that we just created. For the aesthetics mapping, we will put the year on the x-axis and the polyarchy score on the y-axis. We will also specify color in the aes() call so that we can color the lines by region.\nTo get a line chart, we have to specify geom_line(). Then within the geom_line() function we will set the linewidth equal to `1’ so that the lines are a bit more visible.\nFinally, we will add a labs() call as with the previous visualizations. But in addition to title, axis labels and a caption, we will also add color = \"Country\" to change the label of the legend to “Country” with a capital “C.”\n\n# in this ggplot() call, we add a third dimension for line color\nggplot(dem_waves_ctrs, aes(x = year, y = polyarchy, color = country)) +\n  geom_line(linewidth = 1) + # our geom is a line with a width of 1\n  labs(\n    x = \"Year\", \n    y = \"Polyarchy Score\", \n    title = 'Democracy in countries representing three different \"waves\"', \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\" # make title of legend to upper case\n  )"
  },
  {
    "objectID": "modules/module-2.1.html#scatter-plots",
    "href": "modules/module-2.1.html#scatter-plots",
    "title": "Module 2.1",
    "section": "Scatter plots",
    "text": "Scatter plots\n\nThe last thing we are going to do in this lesson is to create a scatter plot. We use scatter plots in order to illustrate how two variables relate to each other (or not). In this example, we are going to illustrating modernization theory, which predicts a positive relationship between wealth and democracy, while also incorporating levels of women’s representation into our analysis.\nWe are going to start with the dem_women.csv file we created in Module 1.2. We will then group the data by country and calculate the mean for each variable. Note that in the group_by() call we also include region because we will want to keep it so that we can color our points by region.\n\ndem_summary_ctry &lt;- read_csv(\"data/dem_women.csv\") |&gt;\n  group_by(country, region) |&gt; # group by country, keep region\n  summarize(\n    polyarchy = mean(polyarchy, na.rm = TRUE),\n    gdp_pc = mean(gdp_pc, na.rm = TRUE), \n    flfp = mean(flfp, na.rm = TRUE), \n    women_rep = mean(women_rep, na.rm = TRUE)\n  )\n\nNow let’s create our first scatter plot. Our ggplot() call looks similar to previous ones except for a few things. First we are calling geom_point() for our geom. But also notice that our aesthetics mapping includes four dimenstions: x, y, color and size. So here we are telling ggplot2 that we want wealth on the x-axis, the polyarchy score on the y-axis, to color the points based on region, and to vary the size of the points in relation to the level of women’s representation.\nOne last thing we want to do is to put our x-axis on a log scale and change the labels to reflect their dollar values. For the log scale, we can use the scale_x_log10() function and for the labels we can use the label_number() function from the scales package. We set the prefix to “$” and the suffix to “k” so that each number on the x-axis starts with a dollar sign and ends with “k” denoting “thousands.”\n\n\n\n\n\n\nNote\n\n\n\nWe will encounter other useful scales functions including label_dollar() and label_percent() in future lessons.\nNotice that in this example we introduce the scales package by including it as a prefix to the label_number() function, e.g. scales::label_number(prefix = \"$\", suffix = \"k\"). This allows us to use the package without having to load it, e.g. library(scales). It also has the benefit of generating a list of auto-complete suggestions for the many available functions in the scales package.\n\n\n\n# in this ggplot() call we have four dimensions\n# x, y, color, and size\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy, color = region, size = women_rep)) + \n  geom_point() + # use geom_point() for scatter plots\n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Region\",\n    size = \"Women Reps\"\n    )\n\n\n\n\nThe plot does a good job of illustrating the basic point of modernization theory in that we do see the positive correlation between wealth and democracy. But we also see that there are some outliers and that a lot of the outlier countries are concentrated in the Middle East.\nWe also see that the distribution of women’s representation is somewhat orthogonal to wealth and democracy. Most wealthy western countries have high levels of women’s representation, but so do a lot of low- and middle-income countries in Africa, Asia and Latin America.\nAdding a trend line\nWe can definitely see a relationship between wealth and democracy in the scatter plot, but how strong is it? One way to find out is to add a trend line. Let’s do this by adding another geom, geom_smooth(), and specifying a linear model with the argument method = \"lm\" We acn also set the linewidth of the trend line to 1 so that the line is more visible.\nIf we want to add a single trend while also maintaining the coloring by region, then we have to reconfigure the ggplot() call a bit. Specifically, we will want to move color = region to a separate aes() call in the geom_point() function, e.g. geom_point(aes(color = region)). If we don’t do this we will get separate trend lines for each region (try it and see!).\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy)) + \n  geom_point(aes(color = region)) + \n  geom_smooth(method = \"lm\", linewidth = 1) + \n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Region\"\n    )\n\n\n\n\nFacet wrapping\nNow let’s imagine that we really interested in drilling down into the “heterogeneous effects” of wealth on democracy by region. In other words, we want to see more clearly how wealth is related to democracy in some regions but not others. For this, we can use facet_wrap() to get a separate chart for each region rather than just shading the points by region. Inside of facet_wrap() we identify region as the variable that we want to use to separate the plots, e.g. facet_wrap(~region). Notice how we have to include a tilde (~) here.\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", linewidth = 1) + \n  facet_wrap(~ region) +\n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )\n\n\n\n\nHere we can clearly see a relationship between wealth and democracy in all of the countries except for the Middle East and Africa. We could speculate that the lack of a relationship in the Middle East could be evidence of an oil curse dynamic whereas perhaps the lack of a relationship in Africa is due to weak institutions.\nThe relationship between wealth and democracy in the West would be apparent, but it is obscured by the fact that western countries because the high wealth and polyarchy values result in extreme bunching in the northwest quadrant of the graph. To deal with this issue, we could add the scales = \"free\" argument to our plot.\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", linewidth = 1) + \n  facet_wrap(~ region, scales = \"free\") +\n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )\n\n\n\n\nBut notice there is a bit of a tradeoff here. With the scales = free option set, we now have separate axes for each of the plots. This is less of a clean look than having common x and y axes.\nLabeling points\nNow let’s try drilling down into one of the regions to get a better sense of what countries are driving the relationship. To do this, we can filter our data set for a region that we are interested in and then add country labels to the points in the scatter plot. Here we are going to filter for “Asia” and we will ad a geom_text() call to add country labels. In the geom_text() call we include arguments for size and vjust to adjust the size and vertical location of the labels relative to the points.\n\ndem_summary_ctry |&gt; \n  filter(region == \"Asia\") |&gt;\n  ggplot(aes(x = gdp_pc, y = polyarchy)) + \n    geom_point() + \n    geom_text(aes(label = country), size = 2, vjust = 2) +\n    geom_smooth(method = \"lm\", linewidth = 1) +\n    scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n      labs(\n        x= \"GDP Per Capita\", \n        y = \"Polyarchy Score\",\n        title = \"Wealth and democracy in Asia, 1990 - present\", \n        caption = \"Source: V-Dem Institute\"\n        )"
  },
  {
    "objectID": "modules/module-2.2.html",
    "href": "modules/module-2.2.html",
    "title": "Module 2.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall plotly (install.packages(\"plotly\")) and have a look at the documentation\n\nInstall colorBlindness (install.packages(\"colorBlindness\")) and read this vignette\n\nGenerate a quarto document named “module-2.2.qmd” in your “modules” project folder so that you can code along with me\nIn your quarto document, run these code chunks and familiarize yourself the data frames that they generate\nNote the use of drop_na() from the tidyr package in constructing the flfp_gdp data frame. drop_na() is a convenient function for dropping rows with missing values.\n\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(wbstats)\nlibrary(countrycode)\n\nindicators = c(flfp = \"SL.TLF.CACT.FE.ZS\", gdp_pc = \"NY.GDP.PCAP.KD\") # define indicators\n\n## Regional levels of FLFP for column chart \n\nflfp_gdp_regions &lt;- \n  wb_data(\"SL.TLF.CACT.FE.ZS\", country = \"regions_only\", mrnev = 1) |&gt; \n  rename(\n    region = country,\n    year = date,\n    flfp = SL.TLF.CACT.FE.ZS\n  ) |&gt; \n  select(region, iso3c, year, flfp)\n  \nflfp_gdp_regions\n\n# A tibble: 7 × 4\n  region                     iso3c  year  flfp\n  &lt;chr&gt;                      &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 East Asia & Pacific        EAS    2022  59.0\n2 Europe & Central Asia      ECS    2022  50.5\n3 Latin America & Caribbean  LCN    2022  51.0\n4 Middle East & North Africa MEA    2022  18.8\n5 North America              NAC    2022  56.9\n6 South Asia                 SAS    2022  25.6\n7 Sub-Saharan Africa         SSF    2022  60.9\n\n## Cross-section of data on FLFP and GDP per capita for scatter plot\n\nflfp_gdp &lt;- wb_data(indicators, end_date = 2021) |&gt; # download data for 2021\n    left_join(select(wb_countries(), c(iso3c, region)), by = \"iso3c\") |&gt;  # add regions\n    drop_na() # drop rows with missing values\n\nglimpse(flfp_gdp)\n\nRows: 174\nColumns: 7\n$ iso2c   &lt;chr&gt; \"AO\", \"AL\", \"AE\", \"AR\", \"AM\", \"AU\", \"AT\", \"AZ\", \"BI\", \"BE\", \"B…\n$ iso3c   &lt;chr&gt; \"AGO\", \"ALB\", \"ARE\", \"ARG\", \"ARM\", \"AUS\", \"AUT\", \"AZE\", \"BDI\",…\n$ country &lt;chr&gt; \"Angola\", \"Albania\", \"United Arab Emirates\", \"Argentina\", \"Arm…\n$ date    &lt;dbl&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 20…\n$ gdp_pc  &lt;dbl&gt; 2299.6406, 4830.5963, 42535.9660, 12402.4908, 4522.3191, 59341…\n$ flfp    &lt;dbl&gt; 74.464, 51.653, 52.789, 50.283, 57.779, 61.216, 55.915, 64.097…\n$ region  &lt;chr&gt; \"Sub-Saharan Africa\", \"Europe & Central Asia\", \"Middle East & …\n\n## Time series data on regional trends in FLFP for line chart\n\nflfp_ts &lt;- wb_data(\"SL.TLF.CACT.FE.ZS\", country = \"regions_only\", start_date = 1990, end_date = 2022) |&gt; \n  rename(\n    region = country,\n    year = date,\n    flfp = SL.TLF.CACT.FE.ZS\n  ) |&gt; \n  select(region, iso3c, year, flfp)\n  \nglimpse(flfp_ts)\n\nRows: 231\nColumns: 4\n$ region &lt;chr&gt; \"East Asia & Pacific\", \"East Asia & Pacific\", \"East Asia & Paci…\n$ iso3c  &lt;chr&gt; \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", …\n$ year   &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 200…\n$ flfp   &lt;dbl&gt; 66.32925, 66.12070, 66.00342, 65.68375, 65.65046, 65.50232, 65.…"
  },
  {
    "objectID": "modules/module-2.2.html#overview",
    "href": "modules/module-2.2.html#overview",
    "title": "Module 2.2",
    "section": "Overview",
    "text": "Overview\nIn this module we are going to take our visualizations from Module 2.1 and improve them. In the first part of the lesson we are going to focused on how to make your visualizations accessible to a color-blind audience. Then we will discuss how to improve the look of your visualizations with themes and to provide additional information and context with annotations. Finally, we will spend some time talking about how to make your graphs interactive so that users can explore them in a more dynamic and flexible way."
  },
  {
    "objectID": "modules/module-2.2.html#color-schemes",
    "href": "modules/module-2.2.html#color-schemes",
    "title": "Module 2.2",
    "section": "Color schemes",
    "text": "Color schemes\n\nThere are a number of different types of color blindness, but the most common type is red-green color blindness. Making your visualizations colorblind-accessible can be important for convincing certain audiences. Most notably, approximately 8% of men are affected by color blindness.\nLet’s start off by looking at the line chart that we did in the last module pertaining to Huntington’s three waves of democratization:\n\ndem_waves_ctrs &lt;- read_csv(\"data/dem_waves_ctrs.csv\")\n\ndem_waves_chart &lt;- ggplot(dem_waves_ctrs, aes(x = year, y = polyarchy, color = country)) +\n  geom_line(linewidth = 1) + \n  labs(\n    x = \"Year\", \n    y = \"Polyarchy Score\", \n    title = 'Democracy in countries representing three different \"waves\"', \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\"\n  )\n\ndem_waves_chart\n\n\n\n\nThe problem with this plot is that people with red-green color blindness will not be able to distinguish between the lines for Japan and Portungal. There are many tools that we could use to see how this is true, but here we are going to focus on the color vision deficiency (CVD) simulator from the colorBlindness package. To use it, all we have to do is load colorBlindness and call cvdPlot() on the stored plot.\n\nlibrary(colorBlindness)\n\ncvdPlot(dem_waves_chart)\n\n\n\n\nIn this output, we can see how deuteranopia and protonopia (red-green color blindness) would experience our plot. Notice how hard it is to distinguish between Japan and Portugal here. We can also see how someone with monochromatic vision would see the plot by looking at the “desaturated (BW)” plot. While monochromatic vision is very rare, we can use this plot to make adjustments for a worst-case scenario.\nSo once you determine that your color scheme is not colorblind friendly, what should you do? There are two basic solutions available to you: making your own colorblind friendly color scheme or use a package that produces colorblind-friendly schemes for you.\nCreate your own colorblind-friendly color scheme\nThe first way to make your plot more accessible is to create your own discrete scale using scale_fill_manual() or scale_color_manual() (depending on what type of plot you are trying to draw).\nLet’s try using an example color scheme from the R Cookbook to fill in the bars of a column chart. Here we will make use of the regional levels of female labor force participation data that we prepped in the prework section of this module. First we create a vector of colors called cb_palette. Then we build our bar chart and save it as an object called flfp_region. Crucially, when we perform our ggplot call, we include fill = region as a third dimension in our aes() function. This is in addition to including the region code iso3c on the x-axis. Finally, we use our palette to shade our bars using scale_fill_manual().\n\ncb_palette &lt;- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nflfp_region &lt;- ggplot(flfp_gdp_regions, aes(x = reorder(iso3c, -flfp), y = flfp, fill = region)) +\n  geom_col() + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(\n    x = \"Region\", \n    y = \"Avg. Female Labor Force Participation\", \n    title = \"Levels of female labor force participation by region\", \n    fill = \"Region\",\n    caption = \"Source: World Bank\"\n    ) \n\nflfp_region + scale_fill_manual(values = cb_palette)\n\n\n\n\nNow we can check our visualization using the cvdPlot() function from the colorBlindness package.\n\nflfp_region &lt;- flfp_region + scale_fill_manual(values = cb_palette)\n\ncvdPlot(flfp_region)\n\n\n\n\nAlthough it would still be difficult for a person with red-green color blindness to see some of the colors in the chart (like the pink of SSF or the bright green of LAC), it would still be possible for them to distinguish the colors of the bars based on what would appear to them as shades of grey.\nUse viridis\nAnother option is to use a package designed with accessibility issues in mind. One of the more popular ones is the viridis() package. To use it just load viridis and add a viridis color scheme to the plot. You have the option of choosing continuous, discrete or binned color schemes but here we use the discrete option scale_fill_viridis_d() because our regions constitute a discrete variable. You can also try different viridis color maps by inserting the various available schemes in the function. For example you can get the “plasma” map with `scale_fill_viridis_d(option = “plasma”). The default map is “viridis.”\n\nflfp_region + scale_fill_viridis_d()\n\n\n\n\nNow let’s run our bar chart with the viridis color mapping through cvdPlot:\n\nflfp_region &lt;- flfp_region + scale_fill_viridis_d()\n\ncvdPlot(flfp_region)\n\n\n\n\nThis is pretty good. In fact it looks fairly close to the original. It is even to easy to see the differences in colors when looking at the desaturated output. Of course the first column for the black and white plot is difficult to distinguish from the plot’s background, but we will learn how to change this up later in this module.\nUse ColorBrewer\nAnother package available to us is the RColorBrewer package. Technically, RColorBrewer is a separate package but its color mappings come available as part of ggplot2, so we don’t have to load RColorBrewer in order to use it with ggplot2. We can also use the color brewer palette selector tool to help select palettes that are “colorblind safe.”\nLet’s try updating our column chart with a ColorBrewer color scheme:\n\nflfp_region + scale_fill_brewer(palette = \"YlGn\") \n\n\n\n\nAnd now lets run it through the cvdPlot() function.\n\nflfp_region &lt;- flfp_region + scale_fill_brewer(palette = \"YlGn\")\n\ncvdPlot(flfp_region)\n\n\n\n\nScaling for scatter plots and line charts\nOne thing to note is that when we want to adjust the color scheme for a scatter plot or line chart, we should use “scale_color” instead of “scale_fill”, e.g. scale_color_manual(), scale_color_viridis_d(), scale_color_brewer. Let’s try a couple of examples. First, let’s add a viridis color map to a scatter plot. We will use the flfp_gdp data we prepped in the prework section to generate our scatter plot.\n\nwealth_flfp &lt;- ggplot(flfp_gdp, aes(x = gdp_pc, y = flfp)) + \n  geom_point(aes(color = region)) + # color points by region\n  geom_smooth(method = \"loess\", linewidth = 1) +  # make the line a loess curve\n  scale_x_log10(labels = scales::label_dollar()) + # stretch axis, add '$' format\n  scale_y_continuous(labels = scales::label_percent(scale = 1)) + # add % label\n  labs(\n    x= \"GDP per Capita\", # x-axis title\n    y = \"Female Labor Force Participation\", # y-axis title\n    title = \"Wealth and female labor force participation\", # plot title\n    caption = \"Source: World Bank Development Indicators\", # caption\n    color = \"Region\" # legend title\n    )\n\nwealth_flfp + scale_color_viridis_d(option = \"plasma\")\n\n\n\n\nNow let’s try adding a ColorBrewer scheme to a line chart. Here we will use the flfp_ts data frame that we prepped in our prework routine.\n\nflfp_line &lt;- ggplot(flfp_ts, aes(x = year, y = flfp, color = region)) +\n  geom_line(linewidth = 1) + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(\n    x = \"Year\", \n    y = \"Female Labor Force Participation\", \n    title = \"Regional trends in female labor force participation\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\"\n  )\n\nflfp_line + scale_color_brewer(palette = \"YlOrRd\")"
  },
  {
    "objectID": "modules/module-2.2.html#themes",
    "href": "modules/module-2.2.html#themes",
    "title": "Module 2.2",
    "section": "Themes",
    "text": "Themes\n\nAnother thing that we can do to improve the overall look of our plots is to change the theme. Here is a list of themes that are available with ggplot2.\nThere are also many extension packages that you can use to apply even more themes, some of which we may encounter later in the course.\nFor now, let’s take a couple of plots that we developed earlier in the lesson and apply some ggplot2 themes to them. We can do this by simply adding the name of the theme to our code.\n\nwealth_flfp + scale_color_viridis_d(option = \"plasma\") + theme_dark()\n\n\n\n\n\nflfp_region + scale_fill_brewer(palette = \"YlGn\") + theme_minimal()"
  },
  {
    "objectID": "modules/module-2.2.html#annotations",
    "href": "modules/module-2.2.html#annotations",
    "title": "Module 2.2",
    "section": "Annotations",
    "text": "Annotations\n\nSometimes it makes sense to include annotations in our charts. We can achieve this by applying the annotate() function. To add a text annotation, we include “text” for the first argument, then the value of x and y at which we want our annotation to appear, and finally the text of the annotation that we want to display. Let’s try adding text to our indicating where high-, middle- and low-income countries are concentraed on the wealth_flfp scatter plot that we developed earlier.\n\nwealth_flfp &lt;- wealth_flfp + scale_color_viridis_d(option = \"plasma\") + theme_minimal()\n\nwealth_flfp + annotate(\"text\", x = 90000, y = 75, label = \"Wealthy\") + \n  annotate(\"text\", x = 1000, y = 80, label = \"Low income\") +\n  annotate(\"text\", x = 10000, y = 20, label = \"Middle income\")\n\n\n\n\nAnother common annotation involves combining text with a horizontal or vertical reference line. For a horizontal intercept line we include an additional geom called geom_hline. The first argument is the value yintercept where we want the reference line to cross. Then we can add additional arguments to define the style, color and size of the line.\n\nflfp_line &lt;- flfp_line + scale_color_viridis_d() \n\nflfp_line + geom_hline(yintercept=52, linetype=\"dashed\", color = \"red\", size = 1) +\n  annotate(\"text\", x = 1995, y = 55, label = \"Global average\")\n\n\n\n\nThe same logic applies for a vertical reference line, except this time the geom is called geom_vline and the first argument, xintercept, is the point at which we want the line to cross the x-axis.\n\nflfp_line &lt;- flfp_line + scale_color_viridis_d() \n\nflfp_line + geom_vline(xintercept=2020, linetype = \"dashed\", size = 1) +\n  annotate(\"text\", x = 2017, y = 35, label = \"Pandemic\")"
  },
  {
    "objectID": "modules/module-2.2.html#interactivity",
    "href": "modules/module-2.2.html#interactivity",
    "title": "Module 2.2",
    "section": "Interactivity",
    "text": "Interactivity\n\nOne final thing we can do, which is really fun, is to add interactivity to our plots with plotly. We can do this by simply calling ggplotly() on our plot object.\n\nlibrary(plotly)\n\nggplotly(flfp_line)\n\n\n\n\n\nIn a lot of cases, we may want to control the tool tip of the plot. The tool tip is what appears when the user hovers over information on the chart. In this next example, the chart does not look that great unless we add the tooltip argument. But it is fairly simple to do. We just add the elements that we want to appear in a combine function, e.g. c(). In this case we will include region and female labor force participation in the tool tip.\n\nflfp_region &lt;- flfp_region + scale_fill_brewer(palette = \"YlGn\") + theme_minimal()\n\nggplotly(flfp_region, tooltip = c(\"region\", \"flfp\")) # controlling the tooltip output\n\n\n\n\n\nAnother thing we may want to do is to include some additional annotations. We might also notice that some of the things we include in the labs argument in ggplot2 do not get picked up by plotly and that we have to add them back with a layout(annotations = ) call. One additional idiosyncrasy is that any item that we want to include in the plotly chart has to be passed as an argument in the ggplot code. For example, we need to include aes(label = country) to view country in tool tip. But plotly does support the R native pipe operator and that makes it a little easier to layer on multiple annotations.\n\nlibrary(plotly)\n\nwealth_flfp_plotly &lt;- wealth_flfp  + \n  scale_color_viridis_d(option = \"plasma\") +\n  theme_minimal() +\n  aes(label = country)  # need so ggplot retains label for plotly\n\nggplotly(wealth_flfp_plotly, tooltip = c(\"country\", \"flfp\", \"gdp_pc\")) |&gt; \n  \n  layout(annotations = list(text = \"Source: World Bank Development Indicators\",  \n                            font = list(size = 10), showarrow = FALSE,\n                            xref = 'paper', x = 1.1, xanchor = 'right', xshift = 0,\n                            yref = 'paper', y = -.1, yanchor = 'auto', yshift = 0)) |&gt; \n  # add web address\n  layout(annotations = list(text = \"www.dataviz-gwu.rocks\", \n                            font = list(size = 10, color = 'grey'), showarrow = FALSE,\n                            xref = 'paper', x = .5, xanchor = 'center', xshift = 0,\n                            yref = 'paper', y = 1, yanchor = 'top', yshift = 0))\n\n\n\n\n\nNotice that plotly has some fairly unique syntax for the layout() function. It helps to read the documentation but also to search around on google and Stack Overflow. Each annotation needs to be inputted in a list format. The first time in the list is the text you want to include in the annotation. From there you can include multiple arguments to specify the font size and location of the annotation."
  },
  {
    "objectID": "modules/module-3.1.html",
    "href": "modules/module-3.1.html",
    "title": "Module 3.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall rnaturalearth (install.packages(\"rnaturalearth\")) and have a look at the documentation\n\nInstall the rnaturalearth data package (install.packages(\"rnaturalearthdata\"))\nInstall ggthemes (install.packages(\"ggthemes\"))and have a look at this post) for a brief explanation of how it works\nCreate a Quarto document called “module-3.1.qmd” in your modules folder for the code-along\nInstall magick and underlying file system to remove whitespace around maps\nThen insert this code chunk somewhere in your module 3.1 Quarto document:\n\n\n# create a hook to crop maps as recommended by pmassicotte\n# must have `magick` and its dependencies installed\n\nknitr::knit_hooks$set(crop = knitr::hook_pdfcrop)"
  },
  {
    "objectID": "modules/module-3.1.html#overview",
    "href": "modules/module-3.1.html#overview",
    "title": "Module 3.1",
    "section": "Overview",
    "text": "Overview\nThe focus of this module is going to be on how to make choropleth maps. A choropleth map is a type of data visualization used to show a geographical distribution of data where areas or regions are shaded based on quantities or levels represented in each area or region.\nOne important concept in mapping that we are going to come across this week: simple features. Simple features is a formal international standard for representing objects in the real world in digital space.\nA “feature” is basically any object in the real world that can be represented in two or three-dimensional space. A tree or a house can be a feature as can a forest or a body of water. But in politics we are usually focused on mapping the political boundaries of different administrative units like countries, states or provinces, counties and cities.\nSimple features allow us to work with such boundaries easily in a data frame in R. We can take all of the points associated with a geometry and store it in a special data frame column (usually labeled ‘geom’ or ‘geometry’). This ability to store all of the geographic information in one column differs from how spatial data are organized under the traditional spatial objects standard and makes it much easier to work with geographic data in R."
  },
  {
    "objectID": "modules/module-3.1.html#using-rnaturalearth",
    "href": "modules/module-3.1.html#using-rnaturalearth",
    "title": "Module 3.1",
    "section": "Using rnaturalearth",
    "text": "Using rnaturalearth\n\nIn this module we are going to be with the rnaturalearth package, which facilitates working with Natural Earth map data in R. Natural Earth is a public domain map dataset based on Tom Patterson’s Natural Earth projection that provides data suitable for making small-scale world, regional and country maps. Natural Earth contains country boundaries, first-order admin boundaries like provinces and states, urban polygons and more. rnaturalearth supports both simple features (sf) and spatial objects (sp) formats, but we are going to be focused on using simple features for the reasons stated earlier.\nGrabbing country shapes with ne_countries()\nLet’s start by loading country shapes using the ne_countries() function from rnaturalearth. We will start by loading rnaturalearth and dplyr. Next we will load the country boundaries into an object called world_map_df while filtering out Antarctica. Then, let’s glimpse() the data and have a closure look at the geometry column.\n\nlibrary(rnaturalearth)\nlibrary(dplyr)\n\nworld_map_df &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\") |&gt;\n    filter(name != \"Antarctica\") # remove Antarctica\n\n#world_map_df |&gt;\n#glimpse()\n\n# view contents of geometry column\nworld_map_df |&gt;\n  select(geometry) \n\nSimple feature collection with 240 features and 0 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -58.49229 xmax: 180 ymax: 83.59961\nGeodetic CRS:  +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\nFirst 10 features:\n                         geometry\n1  MULTIPOLYGON (((-69.89912 1...\n2  MULTIPOLYGON (((74.89131 37...\n3  MULTIPOLYGON (((14.19082 -5...\n4  MULTIPOLYGON (((-63.00122 1...\n5  MULTIPOLYGON (((20.06396 42...\n6  MULTIPOLYGON (((20.61133 60...\n7  MULTIPOLYGON (((1.706055 42...\n8  MULTIPOLYGON (((53.92783 24...\n9  MULTIPOLYGON (((-64.54917 -...\n10 MULTIPOLYGON (((45.55234 40...\n\n\nMake a map with geom_sf()\nNow, let’s make our first choropleth map with the data. Let’s map World Bank income groups. Here we will use the special features geom_sf() from ggplot2 and for our aesthetics mapping we will specify fill = income_grp.\n\nlibrary(ggplot2)\n\nggplot(data = world_map_df) +\n  geom_sf(aes(fill = income_grp)) + \n  labs(title = \"World Bank country income categories\")\n\n\n\n\nBeautify your map\nThe default ggplot settings are pretty good for a preview, but we could make it look a lot better. Let’s add some labels, a ggtheme map theme and the default viridis color mapping.\n\nlibrary(ggthemes)\n\nggplot(data = world_map_df) +\n  geom_sf(aes(fill = income_grp)) + \n  labs(\n    title = \"World Bank country income categories\",\n    fill = \"Category\"\n    ) +\n    scale_fill_viridis_d() +\n    theme_map()"
  },
  {
    "objectID": "modules/module-3.1.html#using-rnaturalearth-to-map-other-data",
    "href": "modules/module-3.1.html#using-rnaturalearth-to-map-other-data",
    "title": "Module 3.1",
    "section": "Using rnaturalearth to map other data",
    "text": "Using rnaturalearth to map other data\n\nNow that we know how to make a map with Natural Earth shapes and geom_sf(), we can merge in data and map data from other sources. Let’s go ahead and merge some data on oil rents from the World Bank. We will do a left_join() based on iso3c country codes. In the World Bank data the iso3c codes are simply called “iso3c.” In rnaturalearth there are a number of options, but the best here for our purposes is “iso_a3”\n\n\n\n\n\n\nWarning\n\n\n\nAt the time I made the video, the codes for “iso_a3” and some of the others were missing so I recommended using “iso_a3_eh.” But now the issue has been fixed, so please use “iso_a3.”\n\n\n\nlibrary(wbstats)\n\noil_rents_df &lt;- wb_data(c(oil_rents_gdp = \"NY.GDP.PETR.RT.ZS\"), mrnev = 1) \n\nrents_map_df &lt;- left_join(world_map_df, oil_rents_df, join_by(iso_a3 == iso3c))\n\nrents_map_df |&gt;\n  select(last_col(5):last_col()) |&gt; #select last 5 columns of df\n  glimpse() \n\nRows: 240\nColumns: 6\n$ date          &lt;dbl&gt; 2021, 2021, 2021, NA, 2021, NA, NA, 2021, 2021, 2021, 20…\n$ oil_rents_gdp &lt;dbl&gt; 0.00000000, 0.01786951, 28.27443988, NA, 1.04218369, NA,…\n$ obs_status    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ footnote      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ last_updated  &lt;date&gt; 2023-05-10, 2023-05-10, 2023-05-10, NA, 2023-05-10, NA,…\n$ geometry      &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((-69.89912 1..., MULTIPOLYGO…\n\n\nNow we can map these data. Everything here is pretty much the same as before, except we change the fill to oil_rents_gdp. We will also add a subtitle and make a few other cosmetic changes like shifting the position of the legend title, bolding the plot title and changing the viridis color scale from discrete to continuous.\n\nggplot(data = rents_map_df) +\n  geom_sf(aes(fill = oil_rents_gdp)) + # shade based on oil rents\n  labs(\n    title = \"Oil rents (% of GDP)\",\n    subtitle = \"(Most recent available data)\", # add subtitle\n    fill = \"Percent\", \n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(\n    legend.position = \"right\", \n    #legend.title = element_text(size = 8),\n    #legend.text = element_text(size = 6)\n    plot.title = element_text(face = \"bold\"), # move legend\n    ) +\n  scale_fill_viridis_c( # chg from discrete (_d) to continuous (_c)\n      option = \"magma\", #  chg to magma theme\n      labels = scales::label_percent(scale = 1) # add % label for legend\n      )"
  },
  {
    "objectID": "modules/module-3.1.html#turn-your-map-into-a-function",
    "href": "modules/module-3.1.html#turn-your-map-into-a-function",
    "title": "Module 3.1",
    "section": "Turn your map into a function",
    "text": "Turn your map into a function\n\nSometimes you may want to map more than one variable in a paper or display variables with a map in an app. For these situations, it can help to create your own function that allows you to change various components of the map code without having to type out all of the code every time you want to create a map.\nCreate the map function\nThe first thing that you want to do is to write out the script for your function. That should include any packages that you need to run that may not already be loaded.\nFrom there, you can build your function. The code for your function contains three elements: 1) a name; 2) the arguments you will include in your function; and 3) a code block of code that will execute when you call the function.\nIn this example, we are going to call our function create_map(). It is going to include five arguments: var_id, title, legend_title, theme and direction. var_id refers to the World Bank variable id, title and legend_title refer to the title of the plot and the title of the legend respectively. theme will allow the user to adjust the viridis theme. And direction refers to whether the color scale is light to dark or dark to light.\nThe code block will first join the country shapes to the selected World Bank data and then map those data by piping them into a ggplot() call. Everything is pretty similar to our previous use of ggplot() and geom_sf(), but one tricky part here is that we have to use eval(parse(text=var_id)))) to remove the quotes surrounding the variable code entered by the user.\n\nlibrary(rnaturalearth)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(wbstats)\n\ncreate_map &lt;- function(var_id, title, legend_title, theme, direction){\n\nne_countries(scale = \"medium\", returnclass = \"sf\") |&gt; \n  left_join(\n    wb_data(var_id, mrnev = 1), # change variable id\n    join_by(iso_a3 == iso3c)\n  ) |&gt; \n  filter(name != \"Antarctica\") |&gt;  \n  ggplot() + \n  geom_sf(aes(fill = eval(parse(text=var_id)))) + # remove quotes\n  labs(\n    title =  title, # change title\n    fill = legend_title, # change legend title\n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n  ) +\n  scale_fill_viridis_c( \n    option = \"magma\", #  chg theme\n    direction = direction # change direction of scale\n    )\n}\n\nDeploy the function in another document\nTo deploy the function in a Quarto or R Markdown dackument, we need to source it as an external R script. First we will save the previous code as a source document. Let’s name our file wb-maps.R and save it in a subdirectory called functions. From there, we can use the source() function so that we can call our create_map() function in subsequent code chunks in our document.\n\nsource(\"functions/wb-maps.R\", local = knitr::knit_global())\n\nNow let’s call our create_map() function that we just made using female labor force particpation.\n\ncreate_map(var_id = \"SL.TLF.CACT.FE.ZS\", \n           title= \"Female Labor Force Participation\", \n           legend_title = \"FLFP %\", \n           theme = \"inferno\", \n           direction = -1)\n\n\n\n\nNow search for an indicator we want to use. We will look for something related to GDP per capita.\n\nwb_search(\"GDP per capita\") \n\n# A tibble: 24 × 3\n   indicator_id       indicator                                   indicator_desc\n   &lt;chr&gt;              &lt;chr&gt;                                       &lt;chr&gt;         \n 1 5.51.01.10.gdp     Per capita GDP growth                       GDP per capit…\n 2 6.0.GDPpc_constant GDP per capita, PPP (constant 2011 interna… GDP per capit…\n 3 NV.AGR.PCAP.KD.ZG  Real agricultural GDP per capita growth ra… The growth ra…\n 4 NY.GDP.PCAP.CD     GDP per capita (current US$)                GDP per capit…\n 5 NY.GDP.PCAP.CN     GDP per capita (current LCU)                GDP per capit…\n 6 NY.GDP.PCAP.KD     GDP per capita (constant 2010 US$)          GDP per capit…\n 7 NY.GDP.PCAP.KD.ZG  GDP per capita growth (annual %)            Annual percen…\n 8 NY.GDP.PCAP.KN     GDP per capita (constant LCU)               GDP per capit…\n 9 NY.GDP.PCAP.PP.CD  GDP per capita, PPP (current international… This indicato…\n10 NY.GDP.PCAP.PP.KD  GDP per capita, PPP (constant 2017 interna… GDP per capit…\n# ℹ 14 more rows\n\n\nNow let’s take that info. and use it to make a plot of GDP per capita.\n\ncreate_map(var_id = \"NY.GDP.PCAP.PP.KD\", \n           title= \"GDP per capita (constant 2017 internatioal $)\", \n           legend_title = \"Geary-Khamis $\", \n           theme = \"mako\", \n           direction = -1)\n\n\n\n\nThere you go! That’s how we can build and use a map function to easily map different indicators in our document or web app."
  },
  {
    "objectID": "modules/module-3.2.html",
    "href": "modules/module-3.2.html",
    "title": "Module 3.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall states, leaflet, sf and html tools and have a look at the documentation for each.\nHave a look at the leaflet and sf cheatsheets.\n\ninstall.packages(c(\"states\", \"leaflet\", \"sf\", \"htmltools))"
  },
  {
    "objectID": "modules/module-3.2.html#overview",
    "href": "modules/module-3.2.html#overview",
    "title": "Module 3.2",
    "section": "Overview",
    "text": "Overview\nThis module is going to introduce you to how to make maps with markers and pop-ups using leaflet. Markers are icons or symbols that show where something is located. Pop-ups are fields that display information about a location on a map. Together, pop-ups and markers allow you to show information related to a particular point or feature on a map without having to navigate away from the current view.\nMarkers and pop-ups can be used to display information such as an address or the name of a city or town. You can customize how pop-ups look, choose what data to display in them. As you get more advanced, you can do even more cool things like link them to other pages or external websites."
  },
  {
    "objectID": "modules/module-3.2.html#working-with-ucdp-data",
    "href": "modules/module-3.2.html#working-with-ucdp-data",
    "title": "Module 3.2",
    "section": "Working with UCDP data",
    "text": "Working with UCDP data\n\nOur running example in this module is going to involve mapping conflict events for Yemen from the Uppsala Conflict Data Program UCDP. So while we will be building on some of our earlier knowledge, this module is going to depart a bit from previous ones in that we are using an entirely new dataset. Specifically, we will be using the UCDP georeferenced event dataset, which you can download from here.\nAfter you have downloaded the data and saved it in your modules folder, go ahead and, read it in and have a look at its contents with gplimpse().\n\n\n\n\n\n\nNote\n\n\n\nI am working with a truncated version of the UCDP GED data so that I can upload everything to GitHub. Consequently, my glimpse() output may look slightly different from yours if you are using the full data.\n\n\n\nlibrary(readr)\nlibrary(dplyr)\n\nged_data &lt;- read_csv(\"data/GEDEvent_v22_1.csv\")\n\nglimpse(ged_data)\n\nRows: 16,609\nColumns: 49\n$ id                &lt;dbl&gt; 412700, 413023, 412909, 374227, 374229, 374396, 3749…\n$ relid             &lt;chr&gt; \"IRQ-2021-1-524-145\", \"IRQ-2021-1-524-143\", \"IRQ-202…\n$ year              &lt;dbl&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021…\n$ active_year       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ code_status       &lt;chr&gt; \"Clear\", \"Clear\", \"Clear\", \"Clear\", \"Clear\", \"Clear\"…\n$ type_of_violence  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ conflict_dset_id  &lt;dbl&gt; 259, 259, 259, 333, 333, 333, 333, 333, 333, 333, 33…\n$ conflict_new_id   &lt;dbl&gt; 259, 259, 259, 333, 333, 333, 333, 333, 333, 333, 33…\n$ conflict_name     &lt;chr&gt; \"Iraq: Government\", \"Iraq: Government\", \"Iraq: Gover…\n$ dyad_dset_id      &lt;dbl&gt; 524, 524, 524, 735, 735, 735, 735, 735, 735, 735, 73…\n$ dyad_new_id       &lt;dbl&gt; 524, 524, 524, 735, 735, 735, 735, 735, 735, 735, 73…\n$ dyad_name         &lt;chr&gt; \"Government of Iraq - IS\", \"Government of Iraq - IS\"…\n$ side_a_dset_id    &lt;dbl&gt; 116, 116, 116, 130, 130, 130, 130, 130, 130, 130, 13…\n$ side_a_new_id     &lt;dbl&gt; 116, 116, 116, 130, 130, 130, 130, 130, 130, 130, 13…\n$ side_a            &lt;chr&gt; \"Government of Iraq\", \"Government of Iraq\", \"Governm…\n$ side_b_dset_id    &lt;dbl&gt; 234, 234, 234, 303, 303, 303, 303, 303, 303, 303, 30…\n$ side_b_new_id     &lt;dbl&gt; 234, 234, 234, 303, 303, 303, 303, 303, 303, 303, 30…\n$ side_b            &lt;chr&gt; \"IS\", \"IS\", \"IS\", \"Taleban\", \"Taleban\", \"Taleban\", \"…\n$ number_of_sources &lt;dbl&gt; 15, 5, 8, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, …\n$ source_article    &lt;chr&gt; \"\\\"BBC News,2021-08-26,Explosion at Kabul airport\\\";…\n$ source_office     &lt;chr&gt; \"BBC News;ShamshadNews on Twitter;Reuters News;Assoc…\n$ source_date       &lt;chr&gt; \"2021-08-26;2021-08-26;2021-08-27;2021-08-27;2021-08…\n$ source_headline   &lt;chr&gt; \"Explosion at Kabul airport;At least 11 people kille…\n$ source_original   &lt;chr&gt; \"US officials; Taliban spokesman Zabihullah Mujahid;…\n$ where_prec        &lt;dbl&gt; 1, 1, 1, 1, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2…\n$ where_coordinates &lt;chr&gt; \"Kabul international airport\", \"Jalalabad town\", \"Ka…\n$ where_description &lt;chr&gt; \"Kabul airport (Abbey gate entrance)\", \"Police Distr…\n$ adm_1             &lt;chr&gt; \"Kabul province\", \"Nangarhar province\", \"Kabul provi…\n$ adm_2             &lt;chr&gt; \"Kabul district\", \"Jalalabad district\", \"Kabul distr…\n$ latitude          &lt;dbl&gt; 34.56444, 34.42884, 34.53109, 31.61180, 31.64045, 31…\n$ longitude         &lt;dbl&gt; 69.21722, 70.45575, 69.16280, 65.70579, 65.39759, 64…\n$ geom_wkt          &lt;chr&gt; \"POINT (69.2172222 34.5644444)\", \"POINT (70.45575 34…\n$ priogrid_gid      &lt;dbl&gt; 179779, 179061, 179779, 175452, 175451, 175449, 1790…\n$ country           &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghan…\n$ country_id        &lt;dbl&gt; 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 70…\n$ region            &lt;chr&gt; \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"Asi…\n$ event_clarity     &lt;dbl&gt; 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ date_prec         &lt;dbl&gt; 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ date_start        &lt;dttm&gt; 2021-08-26, 2021-08-28, 2021-08-29, 2021-01-01, 202…\n$ date_end          &lt;dttm&gt; 2021-08-26, 2021-08-28, 2021-08-29, 2021-01-01, 202…\n$ deaths_a          &lt;dbl&gt; 13, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ deaths_b          &lt;dbl&gt; 1, 2, 0, 0, 7, 13, 0, 7, 6, 18, 13, 12, 12, 14, 14, …\n$ deaths_civilians  &lt;dbl&gt; 141, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ deaths_unknown    &lt;dbl&gt; 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ best              &lt;dbl&gt; 183, 2, 10, 1, 7, 13, 4, 7, 6, 18, 13, 12, 12, 14, 1…\n$ high              &lt;dbl&gt; 184, 3, 10, 1, 16, 12, 4, 16, 16, 18, 12, 13, 13, 14…\n$ low               &lt;dbl&gt; 171, 0, 9, 1, 7, 13, 4, 6, 7, 18, 13, 12, 12, 14, 14…\n$ gwnoa             &lt;dbl&gt; 645, 645, 645, 700, 700, 700, 700, 700, 700, 700, 70…\n$ gwnob             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\nOne thing we have to manage right away is the specific country codes used in these data. There is a whole art to managing international standards organization (ISO) codes which we have already touched on in our discussion of the countrycodes package. For the pruposes of this course, it is enough to be aware of the fact that country-level data sets use different coding systems and that this poses a small hurdle to the visualization and analysis of country-level data.\nFor this analysis, we are going to want to filter by country and specifically we want conflict data for Yemen. According to the UCDP codebook, this dataset uses Gleditsch-Ward (GW) country identifiers. One option could be to simply look up the GW country code for Yemen. But there is also a nice package developed called states. It has a function called sfind() that we can use to find the relevant country code.\n\nlibrary(states)\n\nsfind(\"Yemen\")[1:6]\n\n    list ccode code3c                   country_name      start        end\n169   GW   678    YEM Yemen (Arab Republic of Yemen) 1918-10-30 9999-12-31\n170   GW   680    YPR    Yemen, People's Republic of 1967-11-30 1990-05-21\n428  COW   678    YAR            Yemen Arab Republic 1926-09-02 1990-05-21\n429  COW   679    YEM                          Yemen 1990-05-22 9999-12-31\n430  COW   680    YPR        Yemen People's Republic 1967-11-30 1990-05-21\n\n\nHere we see that the GW code for Yemen is 678. Although there are many listings for Yemen, we know that it is the right code because the Arab Republic of Yemen (our other option for a GW Yemen code) ceased to exist in 1990 following its unification with the People’s Democratic Republic of Yemen.\nLet’s go ahead and use our newly discovered country code to wrangle some data for Yemen. We will filter for Yemen’s country ID and events from 2021 and, to keep things manageable, we will only include events that started before March 1 2021.\nLooking again at the codebook, we see there are codings for how certain the coders were regarding where an event occurred and that they also coded for the quality of the reporting. We will keep events with a location precision score less than 3 and an event clarity score equal to 1.\nFrom there we will create a new variable deaths that sums the different categories of deaths (side a, side b, civilian and unknown). Then we will select all of these variables and the location coordinates and use the st_as_sf() function from the sf package to conver the coordinates into simple features objects.\n\nged_yemen &lt;- ged_data |&gt; \n  filter(\n    country_id == 678, #gw country code\n    year == 2021,\n    date_start &lt; \"2021-03-01\", \n    where_prec &lt; 3, # keep if certain where event occurred\n    event_clarity == 1, # keep if event reporting is clear\n      ) |&gt; \n  mutate(deaths = deaths_a + deaths_b + deaths_civilians + deaths_unknown) |&gt;\n  select(event_id = id,\n         country_id,\n         date = date_start,\n         gov_deaths = deaths_a, \n         rebel_deaths = deaths_b, \n         civilian_deaths = deaths_civilians, \n         deaths, \n         place = where_coordinates,\n         latitude, \n         longitude) |&gt;\n  sf::st_as_sf(coords = c(\"longitude\", \"latitude\")) \n\nglimpse(ged_yemen)\n\nRows: 83\nColumns: 9\n$ event_id        &lt;dbl&gt; 378022, 378424, 378425, 378904, 378908, 378942, 386614…\n$ country_id      &lt;dbl&gt; 678, 678, 678, 678, 678, 678, 678, 678, 678, 678, 678,…\n$ date            &lt;dttm&gt; 2021-01-06, 2021-01-14, 2021-01-20, 2021-01-22, 2021-…\n$ gov_deaths      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, …\n$ rebel_deaths    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ civilian_deaths &lt;dbl&gt; 6, 1, 1, 1, 1, 1, 1, 1, 5, 1, 7, 1, 1, 1, 3, 1, 1, 0, …\n$ deaths          &lt;dbl&gt; 6, 1, 1, 1, 1, 1, 1, 1, 5, 1, 7, 1, 1, 1, 3, 1, 1, 2, …\n$ place           &lt;chr&gt; \"Al Ḩaymah as Suflá area\", \"Wādī al Ḩājib village\", \"A…\n$ geometry        &lt;POINT&gt; POINT (44.06 13.70564), POINT (44.04394 13.74153), P…"
  },
  {
    "objectID": "modules/module-3.2.html#make-a-leaflet-map",
    "href": "modules/module-3.2.html#make-a-leaflet-map",
    "title": "Module 3.2",
    "section": "Make a leaflet map",
    "text": "Make a leaflet map\n\nNow that we have our data, let’s make our first pop-up map. To do this we are going to be using the leaflet package. Leaflet is a really popular JavaScript library for interactive maps. To get started with leaflet, we’ll make a really simple map with one marker that says “First conflict event.”\nPlot a single marker\nLet’s start with a really simple hypothetical example. Let’s say we want to plot one conflict event that we have the coordinates for and label it “First conflict event.” To do this, we would first call the leaflet()function. From there will add default street map tiles with addTiles() and then our single pop-up marker with addMarkers().\n\nlibrary(leaflet)\n\nleaflet() |&gt;\n  addTiles() |&gt;  # Add default OpenStreetMap map tiles\n  addMarkers(lng = 45.46916, lat = 14.14912, label = \"First conflict event\")\n\n\n\n\n\nPlot some conflict events from Yemen\nNow that you have the hang of it, we can move on to plotting some conflict events from our data frame. Again we will call leaflet() but this time we will add data = ged_yemen as an argument. We will also use setView() to center the map on Yemen’s capital Sana’a. We include two arguments for addMarkers. popup = ~as.character(deaths) displays the number of deaths when the user clicks on the marker and label = ~place displays the name of the town that the coordinates correspond to.\n\n\n\n\n\n\nNote\n\n\n\nNote that arguments for the popup = argument take the form of a one-sided formula, meaning that they require a tilde (~) as a prefix. Scroll to the bottom of this page for a more detailed explanation of the ~ notation in this context.\n\n\n\nleaflet(data = ged_yemen) |&gt; # map points in ged_yemen data frame\n  addTiles() |&gt; # add default tile\n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |&gt; # Sana'a coordinates\n  addMarkers(\n    popup = ~as.character(deaths), # when user clicks, show deaths\n    label = ~place # when user hovers, show town\n    )"
  },
  {
    "objectID": "modules/module-3.2.html#customize-your-leaflet-map",
    "href": "modules/module-3.2.html#customize-your-leaflet-map",
    "title": "Module 3.2",
    "section": "Customize your leaflet map",
    "text": "Customize your leaflet map\n\nNext, let’s do some customization to make our map look amazing. We will talk about changing the icon style, customized the information displayed in the icon and adding base maps.\nUse an awesome icon\nWe can dress our leaflet map up a little bit with the addAwesomeMarkers() function which allows us to use the glyphicons, font awesome and ionicons libraries.\nFirst we will use awesomeIcons() to store the icon we want to use. Here we choose “ios-close” from the ionic library. We will say that we want the icon colorto be black and the surrounding marker color to be red. Then we call addAwesomeMarkers() and specify icon = icon to call the red and black ionic marker.\n\n# save icon\nicon &lt;- awesomeIcons(\n  icon = \"ios-close\",\n  iconColor = \"black\",\n  markerColor = \"red\", \n  library = \"ion\" \n)\n\n# Build map\nleaflet(data = ged_yemen) |&gt;   \n  addTiles() |&gt; \n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |&gt; # Sana'a coordinates\n  addAwesomeMarkers(\n    icon = icon, \n    popup = ~as.character(deaths), \n    label = ~place\n    )\n\n\n\n\n\nChange content of the popup\nLet’s say we want to add more information to our pop-up when the user clicks on it. Instead of just showing the total number of deaths, we also want to show the date of the event and the breakdown of government deaths, rebel deaths and civilian deaths.\nThe easiest way to do this is going to be to add a column to our data frame with a label associated with each event. We will use the base R sprintf() function combined with htmltools to create these labels. sprintf() returns a formatted string using values in a list. The first parameter in sprintf is the format and the second is the values that go into the format.\nIn this example, we are separating the lines of our label with html () and we are passing in a string (%s) for the date and numeric values (%.0f) for the number of deaths.\nThen we call HMTL from htmltools and use lapply() to apply the function to every line in the data frame.\n\nged_yemen$popup_text &lt;- sprintf(\n      \"Date: %s &lt;br&gt; \n       Total Deaths: %.0f &lt;br&gt; \n       Govt. Deaths: %.0f &lt;br&gt; \n       Rebel Deaths: %.0f &lt;br&gt; \n       Civilian Death: %.0f &lt;br&gt;\",\n      ged_yemen$date, \n      ged_yemen$deaths, \n      ged_yemen$gov_deaths, \n      ged_yemen$rebel_deaths,\n      ged_yemen$civilian_deaths\n    ) |&gt; lapply(htmltools::HTML)\n\nNow we can use the new labels to enhance the markers by specifying popup = ~popup_text in the addAwesomeMarkers() function.\n\nleaflet(data = ged_yemen) |&gt;  \n  addTiles() |&gt; \n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |&gt; # Sana'a coordinates\n  addAwesomeMarkers(\n    icon = icon, \n    popup = ~popup_text, \n    label = ~place\n    )\n\n\n\n\n\nNow let’s spot check the labels.\n\nged_yemen |&gt;\n  filter(place == \"Marib Dam\")\n\nSimple feature collection with 1 feature and 9 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 45.24417 ymin: 15.39639 xmax: 45.24417 ymax: 15.39639\nCRS:           NA\n# A tibble: 1 × 10\n  event_id country_id date                gov_deaths rebel_deaths\n*    &lt;dbl&gt;      &lt;dbl&gt; &lt;dttm&gt;                   &lt;dbl&gt;        &lt;dbl&gt;\n1   385602        678 2021-02-26 00:00:00         34           27\n# ℹ 5 more variables: civilian_deaths &lt;dbl&gt;, deaths &lt;dbl&gt;, place &lt;chr&gt;,\n#   geometry &lt;POINT&gt;, popup_text &lt;list&gt;\n\n\nUsing basemaps\nAs a last step, let’s change the basemap. We can do this by specifying addProviderTiles() instead of addTiles() and specifying the basemap that we want to use. Here is a list of available basemaps. For this example, we are going to use “OpenTopoMap.”\n\nleaflet(data = ged_yemen) |&gt; # Jan and Feb  \n  addProviderTiles(\"OpenTopoMap\") |&gt; # include name of provider here\n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |&gt; # Sana'a coordinates\n  addAwesomeMarkers(\n    icon = icon, \n    popup = ~popup_text, \n    label = ~place\n    )\n\n\n\n\n\nNow we can see a bit more about the topography, which could be super-useful for conflict analysis."
  },
  {
    "objectID": "modules/module-4.1.html",
    "href": "modules/module-4.1.html",
    "title": "Module 4.1",
    "section": "",
    "text": "Prework\n\n\n\n\nGet a U.S. Census api key\n\nInstall tidycensus to retrieve the data we will use\nInstall kableExtra and gt, out packages for making tables\ninstall webshot2 for exporting gt tables\n\ninstall.packages(c(\"tidycensus\", \"kableExtra\", \"gt\", \"webshot2\"))\n\nWe will be using the stringr package, which is part of the Tidyverse, so you probably already have it installed. But spend some time reading about its usage and features.\nInstall webshot2 for the purposes of saving a .png of your table (install.packages(\"webshot2\"))"
  },
  {
    "objectID": "modules/module-4.1.html#overview",
    "href": "modules/module-4.1.html#overview",
    "title": "Module 4.1",
    "section": "Overview",
    "text": "Overview\nThis week we are going to be talking about making tables in R. Tables can be a great way to summarize data for your audience. While there are no hard and fast rules about when to use a table versus a plot, typically we use tables when we want to present summary statistics that we want to compare across groups or when we want to show the precise values for individual data points. This can be true when we have a small number of cases that we want to discuss.\nIn this module we are going to be working with the tidycensus package to download income data from the American Community Survey (ACS) and the kableExtra and gt packages to visualize it. Along the way, we discuss “the grammar of tables” and some situations where a table would be less appropriate than other methods of visualizing our data."
  },
  {
    "objectID": "modules/module-4.1.html#working-with-tidycensus",
    "href": "modules/module-4.1.html#working-with-tidycensus",
    "title": "Module 4.1",
    "section": "Working with tidycensus",
    "text": "Working with tidycensus\n\nWe are going to start by using tidycensus to download some income data. To use tidycensus you need a Census API key, which you can get here.\n\nlibrary(tidycensus)\ncensus_api_key(\"YOUR API KEY\") # enter your census api key here in quotes\n\nUse the load_variables() function to import data from the census or ACS for a particular year. There is a cache = TRUE option if you want to cache the data for faster retrieval in the future. We can save our data in an object called v21 and then click on it or use View() and the search function in the data frame viewer to see what data are available.\n\nv21 &lt;- load_variables(2021, \"acs5\", cache = TRUE)\n\n#View(v21)\n\nWe want data on income quintiles, so let’s search for “quintile” in the search field. From there we use get_acs() to retrieve the data based on the codes for the five quintiles and the top five percent of earners.\nIn our call, we specify “state” as the geography and “2021” as the year. This will ensure that data from the 2017-2021 ACS is retrieved. Note that by default, tidycensus returns data such that rows represent a unit-variable combination. To get the data with census variables in the columns, we have to specify wide form with output = \"wide\". We will select all of the variables except for the margin of error and GEOID. Let’s rename NAME so it is in lower case. And for some reason, tidycensus puts an “E” suffix at the end of all of our variables when we specify wide format, so let’s use rename_with() and str_remove from the [stringr] package to get rid of that suffix. We will save the data frame in an object called quintiles.\n\nlibrary(stringr)\nlibrary(dplyr)\n\nquintiles &lt;- get_acs(geography = \"state\", \n                      variables = c(q1 = \"B19081_001\",\n                                    q2 = \"B19081_002\",\n                                    q3 = \"B19081_003\",\n                                    q4 = \"B19081_004\",\n                                    q5 = \"B19081_005\",\n                                    top5 = \"B19081_006\"),\n                      year = 2021,\n                      output = \"wide\") |&gt;\n                      select(\n                        !ends_with(\"M\"), # eliminate margin of error\n                        -GEOID) |&gt; # eliminate geo id\n                      rename(name = NAME) |&gt;\n                      rename_with(~str_remove(., 'E'))\n    \n\nglimpse(quintiles)\n\nRows: 52\nColumns: 7\n$ name &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colora…\n$ q1   &lt;dbl&gt; 11602, 19344, 15486, 12076, 17433, 18963, 17417, 17052, 12971, 14…\n$ q2   &lt;dbl&gt; 31928, 51030, 40774, 31051, 49234, 49711, 48870, 44638, 51060, 37…\n$ q3   &lt;dbl&gt; 55270, 81169, 66384, 52280, 84658, 80679, 84042, 73187, 94478, 62…\n$ q4   &lt;dbl&gt; 88640, 122652, 102299, 82811, 134560, 123359, 133488, 111915, 157…\n$ q5   &lt;dbl&gt; 193311, 242097, 223521, 188510, 309857, 264516, 319533, 238612, 3…\n$ top5 &lt;dbl&gt; 336788, 394694, 395620, 344470, 555007, 466181, 602707, 420859, 6…"
  },
  {
    "objectID": "modules/module-4.1.html#explore-the-data-with-kableextra",
    "href": "modules/module-4.1.html#explore-the-data-with-kableextra",
    "title": "Module 4.1",
    "section": "Explore the data with kableExtra",
    "text": "Explore the data with kableExtra\n\nNow let’s use some dplyr slice functions and kableExtra to subset and explore the data. First let’s see which are the wealthiest states. To do this, we can apply slice_max() to identify the states with the highest incomes among the top 5 percent of wage earners. We will save that list as an object called top_10 and then call kable() to view it.\n\nlibrary(kableExtra)\n\ntop_10 &lt;- quintiles |&gt;\n  slice_max(top5, n = 10)\n\nkable(top_10)\n\n\n\nname\nq1\nq2\nq3\nq4\nq5\ntop5\n\n\n\nDistrict of Columbia\n12971\n51060\n94478\n157803\n375792\n670768\n\n\nConnecticut\n17417\n48870\n84042\n133488\n319533\n602707\n\n\nNew York\n14054\n42220\n75647\n123318\n302676\n574063\n\n\nNew Jersey\n18458\n52339\n90337\n142858\n319140\n562886\n\n\nMassachusetts\n16812\n50519\n89602\n142491\n316447\n558616\n\n\nCalifornia\n17433\n49234\n84658\n134560\n309857\n555007\n\n\nMaryland\n19946\n55165\n91725\n140353\n293979\n503597\n\n\nWashington\n19367\n50803\n82817\n127003\n277165\n487950\n\n\nVirginia\n17922\n48359\n81072\n127411\n280299\n486006\n\n\nIllinois\n15102\n42688\n72900\n114531\n258373\n466713\n\n\n\n\n\nNow let’s do the same thing but searching for the poorest states instead. We will use the slice_min() function to identify the states with the lowest incomes in the first quintile of earners.\n\nbottom_10 &lt;- quintiles |&gt;\n  slice_min(q1, n = 10)\n\nkable(bottom_10)\n\n\n\nname\nq1\nq2\nq3\nq4\nq5\ntop5\n\n\n\nPuerto Rico\n2906\n12144\n22163\n38397\n99043\n187234\n\n\nMississippi\n10096\n27963\n49418\n80125\n175581\n308523\n\n\nLouisiana\n10371\n29781\n53925\n89536\n201514\n357026\n\n\nNew Mexico\n11058\n31274\n54295\n86905\n188282\n323568\n\n\nWest Virginia\n11120\n29606\n51038\n81393\n174019\n299882\n\n\nAlabama\n11602\n31928\n55270\n88640\n193311\n336788\n\n\nKentucky\n11846\n32616\n55838\n88089\n194168\n350411\n\n\nArkansas\n12076\n31051\n52280\n82811\n188510\n344470\n\n\nSouth Carolina\n12680\n34881\n58665\n92118\n207367\n374427\n\n\nDistrict of Columbia\n12971\n51060\n94478\n157803\n375792\n670768\n\n\n\n\n\nOK now let’s make a table with a selection of states that reflects the full range of household incomes. So first, we will use slice_min() and slice_max() without arguments to select the state with the poorest households in q1 and the state with the wealthiest households in top5. The we will use slice_sample() to take a random sample of five additional states.\nWe will store these selections in three objects and then combine them into a single data frame called states using the dplyr function bind_rows. bind_rows() appends data frames with different observations for the same set of columns. You can think of its a kind of “verticle merging” of data frames.\nAfter we have done the append, we can view the new data by calling kable(states).\n\n# lowest \nstate_min &lt;- quintiles |&gt; \n  slice_min(q1) \n\n# highest\nstate_max &lt;- quintiles |&gt; \n  slice_max(top5) \n\n# randomly select five more\nfive_more &lt;- quintiles |&gt;\n   slice_sample(n = 5) \n\nstates &lt;- bind_rows(state_min, state_max, five_more) |&gt;\n  arrange(desc(top5))\n\nkable(states)\n\n\n\nname\nq1\nq2\nq3\nq4\nq5\ntop5\n\n\n\nDistrict of Columbia\n12971\n51060\n94478\n157803\n375792\n670768\n\n\nMassachusetts\n16812\n50519\n89602\n142491\n316447\n558616\n\n\nCalifornia\n17433\n49234\n84658\n134560\n309857\n555007\n\n\nMaryland\n19946\n55165\n91725\n140353\n293979\n503597\n\n\nRhode Island\n15069\n42774\n74564\n115030\n242103\n424473\n\n\nMaine\n14836\n38190\n63621\n97559\n205365\n359776\n\n\nPuerto Rico\n2906\n12144\n22163\n38397\n99043\n187234"
  },
  {
    "objectID": "modules/module-4.1.html#display-the-data-with-a-gt-table",
    "href": "modules/module-4.1.html#display-the-data-with-a-gt-table",
    "title": "Module 4.1",
    "section": "Display the data with a gt table",
    "text": "Display the data with a gt table\n\nNow that we have some good data for a table, let’s make a really beautiful table with the gt package. “gt” stands for “grammar of tables.” So just as we talked about a “grammar of graphics” when we were studying plots, we can talk about the “grammar of tables” and break a table down into its component parts.\ngt envisions six main parts of a table that can be customized in various ways. The table header includes the title and possibly a subtitle. Next, we have the stub section that contains our row labels and, above that, a stubhead label, which we could use to provide more information about what is in the rows. Then, we have column labels that tell us about what is in each column and the table body which contains the actual data that we want to present. Finally, we have the table footer, which would contain any notes that we have about information contained in the table as well as information about sources. Check out the gt function reference to get a sense of all the customizations available.\nLet’s go ahead and start out by making a basic gt table with a title, subtitle, column labels, source note and format the numbers as dollar figures.\nMake a good gt table\n\nlibrary(gt)\n\ngoodtable &lt;- gt(states) |&gt; \n  tab_header(\n    title = \"Mean Household Income of Quintiles, 2021\",\n    subtitle = \"Seven Representative U.S. States\"\n  ) |&gt; \n  cols_label(\n    name = \"\",\n    q1 = \"lowest\",\n    q2 = \"second\",\n    q3 = \"third\",\n    q4 = \"fourth\",\n    q5 = \"highest\",\n    top5 = \"top 5%\"\n  ) |&gt; \n  fmt_currency(\n    columns = c(q1:top5),\n    currency = \"USD\", \n    use_subunits = FALSE\n  ) |&gt;\n  # note that you can use markdown (md) to format the source note for html documents\n  tab_source_note(source_note = md(\"**Source**: US Census Bureau, American Community Survey\"))\n\ngoodtable\n\n\n\n\n\n\n\nMean Household Income of Quintiles, 2021\n    \n\nSeven Representative U.S. States\n    \n\n\n      lowest\n      second\n      third\n      fourth\n      highest\n      top 5%\n    \n\n\n\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\n\n\nMassachusetts\n$16,812\n$50,519\n$89,602\n$142,491\n$316,447\n$558,616\n\n\nCalifornia\n$17,433\n$49,234\n$84,658\n$134,560\n$309,857\n$555,007\n\n\nMaryland\n$19,946\n$55,165\n$91,725\n$140,353\n$293,979\n$503,597\n\n\nRhode Island\n$15,069\n$42,774\n$74,564\n$115,030\n$242,103\n$424,473\n\n\nMaine\n$14,836\n$38,190\n$63,621\n$97,559\n$205,365\n$359,776\n\n\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\n\n\n\n\nSource: US Census Bureau, American Community Survey\n    \n\n\n\n\nChange column width\nNow let’s add some further customization. One thing to pay attention to is the column width. Too narrow of columns can make it difficult to read the information, while too wide of columns can cause the table not to fit on the page. We can adjust the column width of our table with the cols_width() function.\n\nvgoodtable &lt;- goodtable |&gt;\n  cols_width(c(q1:top5) ~ px(90))\n\nvgoodtable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean Household Income of Quintiles, 2021\n    \n\nSeven Representative U.S. States\n    \n\n\n      lowest\n      second\n      third\n      fourth\n      highest\n      top 5%\n    \n\n\n\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\n\n\nMassachusetts\n$16,812\n$50,519\n$89,602\n$142,491\n$316,447\n$558,616\n\n\nCalifornia\n$17,433\n$49,234\n$84,658\n$134,560\n$309,857\n$555,007\n\n\nMaryland\n$19,946\n$55,165\n$91,725\n$140,353\n$293,979\n$503,597\n\n\nRhode Island\n$15,069\n$42,774\n$74,564\n$115,030\n$242,103\n$424,473\n\n\nMaine\n$14,836\n$38,190\n$63,621\n$97,559\n$205,365\n$359,776\n\n\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\n\n\n\n\nSource: US Census Bureau, American Community Survey\n    \n\n\n\n\nChange font\nNext we want to make sure that the fonts that we use are legible and accessible, just like we did for our charts. We can do this with opt_table_font().\n\ngreattable &lt;- vgoodtable |&gt;\n  opt_table_font(font = \"verdana\")\n\ngreattable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean Household Income of Quintiles, 2021\n    \n\nSeven Representative U.S. States\n    \n\n\n      lowest\n      second\n      third\n      fourth\n      highest\n      top 5%\n    \n\n\n\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\n\n\nMassachusetts\n$16,812\n$50,519\n$89,602\n$142,491\n$316,447\n$558,616\n\n\nCalifornia\n$17,433\n$49,234\n$84,658\n$134,560\n$309,857\n$555,007\n\n\nMaryland\n$19,946\n$55,165\n$91,725\n$140,353\n$293,979\n$503,597\n\n\nRhode Island\n$15,069\n$42,774\n$74,564\n$115,030\n$242,103\n$424,473\n\n\nMaine\n$14,836\n$38,190\n$63,621\n$97,559\n$205,365\n$359,776\n\n\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\n\n\n\n\nSource: US Census Bureau, American Community Survey\n    \n\n\n\n\nCenter\nThen we want to check to make sure that information is aligned properly in the table. We can use right, left or center justify our text, depending on its purpose, by calling cols_align().\n\nvgreattable &lt;- greattable |&gt;\n  cols_align(\n  align = \"center\",\n  columns = q1:top5\n)\n\nvgreattable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean Household Income of Quintiles, 2021\n    \n\nSeven Representative U.S. States\n    \n\n\n      lowest\n      second\n      third\n      fourth\n      highest\n      top 5%\n    \n\n\n\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\n\n\nMassachusetts\n$16,812\n$50,519\n$89,602\n$142,491\n$316,447\n$558,616\n\n\nCalifornia\n$17,433\n$49,234\n$84,658\n$134,560\n$309,857\n$555,007\n\n\nMaryland\n$19,946\n$55,165\n$91,725\n$140,353\n$293,979\n$503,597\n\n\nRhode Island\n$15,069\n$42,774\n$74,564\n$115,030\n$242,103\n$424,473\n\n\nMaine\n$14,836\n$38,190\n$63,621\n$97,559\n$205,365\n$359,776\n\n\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\n\n\n\n\nSource: US Census Bureau, American Community Survey\n    \n\n\n\n\nAdd borders and lines\nFinally, we want to think about how to use borders and lines to separate and identify different elements of the table using tab_options() like this.\n\nawesometable &lt;- vgreattable |&gt;\n  tab_options(\n    table.border.top.color = \"black\", \n    table.border.bottom.color = \"black\",\n    heading.border.bottom.color = \"black\", \n    column_labels.border.bottom.color = \"black\", \n    table_body.border.bottom.color = \"black\"\n  )\n\nawesometable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean Household Income of Quintiles, 2021\n    \n\nSeven Representative U.S. States\n    \n\n\n      lowest\n      second\n      third\n      fourth\n      highest\n      top 5%\n    \n\n\n\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\n\n\nMassachusetts\n$16,812\n$50,519\n$89,602\n$142,491\n$316,447\n$558,616\n\n\nCalifornia\n$17,433\n$49,234\n$84,658\n$134,560\n$309,857\n$555,007\n\n\nMaryland\n$19,946\n$55,165\n$91,725\n$140,353\n$293,979\n$503,597\n\n\nRhode Island\n$15,069\n$42,774\n$74,564\n$115,030\n$242,103\n$424,473\n\n\nMaine\n$14,836\n$38,190\n$63,621\n$97,559\n$205,365\n$359,776\n\n\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\n\n\n\n\nSource: US Census Bureau, American Community Survey\n    \n\n\n\n\nExport your table\nNow try exporting your table as .png file with the gtsave() function.\n\ngtsave(awesometable, \"awesometable.png\")"
  },
  {
    "objectID": "modules/module-4.1.html#when-a-plot-is-better-than-a-table",
    "href": "modules/module-4.1.html#when-a-plot-is-better-than-a-table",
    "title": "Module 4.1",
    "section": "When a plot is better than a table",
    "text": "When a plot is better than a table\n\nBe judicious with your use of tables. You would not want to use tables where a plot is more appropriate. For example you would not want to use a table to show a trend over time (a line chart would be more appropriate) or to display the relationship between two variables (where a scatter plot would be more appropriate).\nAnother case where a table would be less effective than a plot is in showing estimates, margins of error and confidence intervals. Let’s do an example with median income estimates. We can start by searching for “median income” and discover that the code for median income is B06011_001. Let’s use that to extract the median income for counties in the state of Massachusetts.\n\nlibrary(janitor)\n\nmass_med_inc &lt;- get_acs(\n  geography = \"county\", \n  variables = c(median_income = \"B06011_001\"), \n  state = \"MA\", \n  year = 2021\n  ) |&gt;\n  mutate(\n    lower_90 = estimate - moe,\n    upper_90 = estimate + moe \n  ) |&gt;\n  clean_names() |&gt;\n  mutate(name = str_replace_all(name, \" County, Massachusetts\", \"\")) |&gt;\n  select(name, estimate, lower_90, upper_90)\n\nglimpse(mass_med_inc)\n\nRows: 14\nColumns: 4\n$ name     &lt;chr&gt; \"Barnstable\", \"Berkshire\", \"Bristol\", \"Dukes\", \"Essex\", \"Fran…\n$ estimate &lt;dbl&gt; 40442, 33040, 36910, 40119, 39756, 34775, 32262, 30795, 51808…\n$ lower_90 &lt;dbl&gt; 39554, 32074, 36347, 34791, 39174, 33712, 31707, 29868, 51337…\n$ upper_90 &lt;dbl&gt; 41330, 34006, 37473, 45447, 40338, 35838, 32817, 31722, 52279…\n\n\nWe can select the county name, median income estimate and the upper and lower confidence intervals and put those in a table.\n\nkable(mass_med_inc)\n\n\n\nname\nestimate\nlower_90\nupper_90\n\n\n\nBarnstable\n40442\n39554\n41330\n\n\nBerkshire\n33040\n32074\n34006\n\n\nBristol\n36910\n36347\n37473\n\n\nDukes\n40119\n34791\n45447\n\n\nEssex\n39756\n39174\n40338\n\n\nFranklin\n34775\n33712\n35838\n\n\nHampden\n32262\n31707\n32817\n\n\nHampshire\n30795\n29868\n31722\n\n\nMiddlesex\n51808\n51337\n52279\n\n\nNantucket\n45717\n38260\n53174\n\n\nNorfolk\n52591\n51991\n53191\n\n\nPlymouth\n43684\n43014\n44354\n\n\nSuffolk\n39200\n38624\n39776\n\n\nWorcester\n39009\n38454\n39564\n\n\n\n\n\nBut this is not very compelling. So instead, we can plot confidence intervals with ggplot using a combination of geom_errorbar() and geom_point().\n\nlibrary(ggplot2)\n\nmass_med_inc |&gt;\n  ggplot(aes(x = estimate, y = reorder(name, estimate))) +\n  geom_errorbar(aes(xmin = lower_90, xmax = upper_90)) +\n  geom_point(color = \"red\", size = 2) +\n  labs(title = \"Household income by county in Massachusetts\",\n       subtitle = \"2017-2021 American Community Survey\",\n       y = \"\",\n       x = \"Median Income\", \n       caption = \"ACS estimate (bars represent 90% confidence intervals)\") +\n  theme_minimal()\n\n\n\n\nThis conveys a lot more information relative to a table."
  },
  {
    "objectID": "modules/module-4.2.html",
    "href": "modules/module-4.2.html",
    "title": "Module 4.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall peacesciencer, broom and modelsummary. Familiarize yourself with the basic purpose and usage of these packages,\n\ninstall.packages(c(\"peacesciencer\", \"broom\", \"modelsummary\"))"
  },
  {
    "objectID": "modules/module-4.2.html#when-a-coefficient-plot-is-better",
    "href": "modules/module-4.2.html#when-a-coefficient-plot-is-better",
    "title": "Module 4.2",
    "section": "When a coefficient plot is better",
    "text": "When a coefficient plot is better\n\nA regression table is great when we have many models that we want to display. But what happens when we have just one model? We could present something like our earlier tidy() output which has the beta coefficient, the standard error, t-statistic and p-values in separate columns, but this would be unconventional and would take up a lot of space. Another option is just to present a table with one column like this:\n\nmodelsummary(conflict_model, \n             stars = TRUE,  \n             gof_map = c(\"nobs\"),\n             coef_map = coef_map,\n             title = caption, \n             notes = reference)\n\n\nTable 1: Predictors of Conflict Onset\n\n\n (1)\n\n\n\nEthnic Frac\n0.800*\n\n\n\n(0.381)\n\n\nReligions Frac\n−0.391\n\n\n\n(0.417)\n\n\nPolyarchy\n−0.602\n\n\n\n(0.509)\n\n\nTerrain\n0.064\n\n\n\n(0.076)\n\n\nPer capita GDP\n−0.372**\n\n\n\n(0.121)\n\n\nPopulation\n0.293***\n\n\n\n(0.067)\n\n\nIntercept\n−5.693***\n\n\n\n(1.408)\n\n\nNum.Obs.\n6151\n\n\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n See appendix for data sources.\n\n\n\n\n\n\nBut this is also somewhat unconventional and makes our regression output look a little bit lonely. A better option could be to display a coefficient plot that shows point estimates and confidence intervals. This is often preferable with one model because it makes our results so much easier to interpret.\nLet’s try making a coefficient plot with modelplot() from the modelsummary package. The syntax for modelplot() is very similar to that of modelsummary() but there are a few small differences.\nFirst, it puts maps the coefficients from the bottom up, so if you to maintain the order of the coefficients you need to reverse the mapping. We do this with the rev() function.\nSecond, we want to omit the intercept with coef_omit = \"Intercept\" because the emphasis in a coefficient plot is less on the exact regression equation and more on the magnitude and significance of the coefficients.\nThird we can customize various things. We can specify the color of the points and confidence intervals and we can load ggplot2 for further customization. Now we can add geoms and labels just like any other ggplot object. Here we add a red vertical intercept line at zero to make it clearer which variables are significant (e.g. the confidence interval does not overlap with zero). And we add a title and a caption using the labs() function.\n\nlibrary(ggplot2)\n\n\nmodelplot(conflict_model, \n          coef_map = rev(coef_map), # rev() reverses list order\n          coef_omit = \"Intercept\", \n          color = \"blue\") + # use plus to add customizations like any ggplot object\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\", linewidth = .75) + # red 0 line\n  labs(\n    title = \"Figure 1: Predictors of Conflict Onset\",\n    caption = \"See appendix for data sources.\"\n  )"
  },
  {
    "objectID": "modules/module-5.1.html#setup",
    "href": "modules/module-5.1.html#setup",
    "title": "Module 5.1",
    "section": "Setup",
    "text": "Setup\n\nI said earlier that there are three main components of a Shiny app (UI, server and call to app). However, with most apps, there is usually a bit of setup int the code before you get to this point. So perhaps you could say there are actually four elements of a Shiny app, with the set up being the “0th” element.\nThere are going to be two components to the setup for this app. First we are going to “pre-wrangle” our data and store it in a .csv file. I will explain why in a minute. Second, we are going to build a setup code chunk that we will include in our app.R file. Let’s get started.\nWrangling and storing the data\nFor this app, we want users to be able to create scatter plots using selected variables from the V-Dem dataset. Let’s say that we want to have a nice mix of variables related to democracy and development so that users can explore how democracy relates to development and vice versa. So we will filter the data for the post-2000 period and select measures relating to democracy, governance and women’s empowerment and then four measures related to development.\nWe will also make sure to code a region variable and include region in the group_by() call so that it stays in the data frame. Then we will take the country mean of the measures for the post-2000 period so that we have one set of observations for each each country.\nFinally, let’s then save these data in a .csv file to include with the app. Alternatively, we could have our app wrangle the data each time the app is loaded. This would ensure that the data are always up to date, but it would require more resources than is available with the free version of the Shiny server due to the size of the V-Dem dataset.\n\nlibrary(vdemdata)\nlibrary(dplyr)\nlibrary(readr)\n\ndem_data &lt;- vdem |&gt;\n  filter(year &gt; 2000) |&gt;\n  select(\n    country = country_name, \n    polyarchy = v2x_polyarchy,\n    clientelism = v2xnp_client,\n    corruption = v2xnp_regcorr,\n    womens_emp = v2x_gender,\n    gdp_pc = e_gdppc,\n    inf_mort = e_peinfmor,\n    life_exp = e_pelifeex,\n    education = e_peaveduc,\n    region = e_regionpol_6C \n  ) |&gt;   mutate(\n    region = case_match(region, \n                        1 ~ \"Eastern Europe\", \n                        2 ~ \"Latin America\",  \n                        3 ~ \"Middle East\",   \n                        4 ~ \"Africa\", \n                        5 ~ \"The West\", \n                        6 ~ \"Asia\")\n  ) |&gt;\n  group_by(country, region) |&gt;\n  summarize_all(mean, na.rm = TRUE)\n\n#glimpse(dem_data)\n\nwrite_csv(dem_data, \"dem_data.csv\")\n\nSetup code chunk\nNow let’s build a setup code chunk that we can include in the app.R script. Here we will load the packages we need for the app and read in the data we just wrangled from the .csv file. Finally, let’s go ahead and create a list of variable names for our dropdown menus in the app and map these to the variables in our data frame.\n\n# load packages\nlibrary(shiny)\nlibrary(readr)\nlibrary(ggplot2)\n\n# load the data \ndem_data &lt;- read_csv(\"dem_data.csv\")\n\n# create list of named values for the input selection\nvars &lt;- c(\"Democracy\" = \"polyarchy\",\n          \"Clientelism\" = \"clientelism\",\n          \"Corruption\" = \"corruption\",\n          \"Women's Empowerment\" = \"womens_emp\",\n          \"Wealth\" = \"gdp_pc\",\n          \"Infant Mortality\" = \"inf_mort\",\n          \"Life Expectancy\" = \"life_exp\", \n          \"Education\" = \"education\")"
  },
  {
    "objectID": "modules/module-5.1.html#ui",
    "href": "modules/module-5.1.html#ui",
    "title": "Module 5.1",
    "section": "UI",
    "text": "UI\n\nThe user interface (UI) defines the layout and appearance of the web application. Here you tell Shiny what elements such as buttons, sliders, text inputs, plots, and other interactive components that you want users to be able to interact with.\nWe will start with the fluidPage() function as the outermost layer of our UI and then add additional container functions within it. First we will add a titlePanel(). You are free to call this app whatever you like but I thought a good title would be “Democracy and Development.”\nThen we can add a sidebar panel with dropdown menus to select the variables to display in the scatter plot. For this we call sidebarLayout() and then within that sidebarPanel(). This next step is really important. We are going to use the list variables called vars from our setup code chunk to populate the dropdown menus. To do this we are going to call selectInput() twice–once for the x-axis variable that the user wants to appear on the scatter plot and once for the y-axis variable.\nThe three main arguments for this function are input, label and choices. input is the input ID that we will use to access the user selection later on in the server function. label refers to the name that we want to appear above the dropdown menu. And choices refers to the list of choices to appear in the dropdown (in our case the list of variables called vars.)\nWe can also include the argument selected in our selectInput() call to determine which variable is selected by default when the app loads. We are going to specify the sixth variable in the list for the y-axis (vars[[6]]) to make sure that the same two variables do not appear on both the x and y axes.\nThe final piece of our UI is the main panel where we want our scatter plot to appear. Let’s go ahead and add mainPanel() and then within that call plotOutput(\"scatterplot\"). This is going to dynamically retrieve the updated scatter plot as the user changes the variables in the dropdown menu.\n\n# Define UI for application that draws a scatter plot\nui &lt;- fluidPage(\n\n    # Application title\n    titlePanel(\"Democracy and Development\"),\n\n    # Sidebar with a two dropdown menus\n    sidebarLayout(\n      sidebarPanel(\n        selectInput(input = 'xcol', label = 'X Variable', choices = vars),\n        selectInput(input = 'ycol', label = 'Y Variable', \n                    choices = vars, selected = vars[[6]])\n      ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"scatterplot\")\n        )\n    )\n)"
  },
  {
    "objectID": "modules/module-5.1.html#server",
    "href": "modules/module-5.1.html#server",
    "title": "Module 5.1",
    "section": "Server",
    "text": "Server\n\nThe server function is where you are going to put the logic and computations of the application. The server function receives input from the user interface, processes it, and generates the corresponding output. It can perform calculations, query databases, apply statistical models, and produce visualizations.\nThe server function contains three arguments. Two of them (input and output) are mandatory. session is an optional parameter that controls the behavior of the app during the user session that we won’t get into here. But we will keep it in the function call for now just to remind us that it is there.\nNext we are going to define the output of the app with output$scatterplot &lt;- renderPlot({}). This bit of code is going to render a plot and then save it to the output in an object called scatterplot. Remember that in the UI, we defined our plot output as plotOutput(\"scatterplot\"). This is where that object scatterplot is going to come from. The scatter plot is going to be created in two steps. First we are going to reactively retrieve the data each time the user selects new inputs. To do this we are going to use the inputs (xcol, ycol) from the UI to subset our data frame demdata, e.g. dem_data[, c(input$xcol, input$ycol, \"region\")]. That is going to create a three-column data frame with the user’s selected x variable, y variable and the region coding and store it in an object called selectedData.\nFrom there, we take selectedData and use it to create a scatter plot with ggplot2. This is done in the usual way, except for a couple of things. First, in our aes() call we need to use get() to specify the x and y variables. aes() uses nonstandard evaluation to capture variable names, meaning that the bare column names of the data frame are read directly so that you do not have to explicitly quote the inputs. However, in this case the names of the inputs are being passed as a string from the user. The get() function enables us to retrieve the value of an object based on its name. So our aes() call will be aes(x = get(x = input$xcol), y = get(input$ycol)).\nThe other thing we need to do is to add some special code to deal with the x- and y-axis labels because these are going to change every time the user selects a different variable. Here we are going to use the names() function to return the names of the the object selected in the vars vector of variable names. To make sure we get the right name from the vector, we are going to use the which() function. which() returns the value that satisfies a given function, in this case the index number of the vars vector that matches the user input. So for example, our x label will be defined as x = names(vars[which(vars == input$xcol)]. Here the number returned by [which(vars == input$xcol)] is going to be used to subset the vars list so that x displays the name of the variable selected by the user.\n\n# Define server logic required to draw a scatter plot\nserver &lt;- function(input, output, session) {\n  \n  # Render the plot\n  output$scatterplot &lt;- renderPlot({\n    \n    # ggplot call\n    ggplot(dem_data, aes(x = get(input$xcol), y = get(input$ycol))) +\n      geom_point(aes(color = region)) +\n      geom_smooth(method = \"loess\") +\n      scale_color_viridis_d(option = \"plasma\") +\n      theme_minimal() +\n      labs(\n        x =  names(vars[which(vars == input$xcol)]), # select names in vars that\n        y =  names(vars[which(vars == input$ycol)]), # match input selections\n        caption = \"Source: V-Dem Institute\",\n        color = \"Region\"\n      )\n  })\n}"
  },
  {
    "objectID": "modules/module-5.1.html#call-to-shiny-app",
    "href": "modules/module-5.1.html#call-to-shiny-app",
    "title": "Module 5.1",
    "section": "Call to Shiny app",
    "text": "Call to Shiny app\n\n# See above for the definitions of ui and server\nui &lt;- ...\n\nserver &lt;- ...\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "project/project-datasets.html",
    "href": "project/project-datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "Here are some datasets that you might consider using for your final project:\n\nILOSTAT is the statistical database of the International Labour Organisation. It has data pertaining to labor, working conditions, industrial relations, poverty and inequality.\nGoogle Public Data Explorer contains information about dozens of databases related to governance and the economy. You cannot download the raw data from Google, but you can use the site to visualize the data and then follow the link to the original source.\nOECD DATA provides data related to the performance of high income countries.\nOur World in Data is a good general resource for political economy data. The site is centered around blog posts but you can also search for a topic, view a visualization related to that topic and then download the data used to create it.\nStatista is a good place to look for data on more niche topics.\nUNCTADstat is the United Nations Conference on Trade and Development statistical database. It provides harmonized data on a range of topics related to economic performance, trade and statistics.\nThe UN Human Development Reports include a number of important indicators related to human development, gender and sustainable development goals (SDGs).\nVarieties of Democracy (V-DEM) provides original measures of the quality of democracy for every country dating back to the 18th century.\nWorld Bank Development Indicators (WDI) is the primary World Bank database for development data from officially-recognized international sources.\nThe World Bank DataBank provides access to dozens of additional World Bank databases on topics such as regional development, governance, education, gender and the environment.\n\nFor information on more specific resources available, see this page on the Gelman Library website."
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "📖 Review the course syllabus and support resources\n📖 r4ds\n\n8.1 & 8.2 on importing data\n6.1 - 6.3 on tidy data\n20.3 on mutating joins\n4.5 on grouping data\n\n\n\n\n📖 Norris, The Impact of Electoral Reform on Women’s Representation"
  },
  {
    "objectID": "weeks/week-1.html#readings",
    "href": "weeks/week-1.html#readings",
    "title": "Week 1",
    "section": "",
    "text": "📖 Review the course syllabus and support resources\n📖 r4ds\n\n8.1 & 8.2 on importing data\n6.1 - 6.3 on tidy data\n20.3 on mutating joins\n4.5 on grouping data\n\n\n\n\n📖 Norris, The Impact of Electoral Reform on Women’s Representation"
  },
  {
    "objectID": "weeks/week-1.html#assignments",
    "href": "weeks/week-1.html#assignments",
    "title": "Week 1",
    "section": "Assignments",
    "text": "Assignments\n📘 Quiz 1\n📘 Quiz 2\n🧮 Coding Assignment 1"
  },
  {
    "objectID": "modules/module-4.2.html#overview",
    "href": "modules/module-4.2.html#overview",
    "title": "Module 4.2",
    "section": "Overview",
    "text": "Overview\nA very common use of tables in the social sciences is to present regression results. There are numerous packages available for presenting regression output. In this lesson, we are going to focus on one of them that I think is particularly good for both pdf and html output: modelsummary. modelsummary also includes a function (modelplot()) for plotting point estimates and confidence intervals. So part of the objective of this lesson is going to be to learn when you should use a table to present your regression results versus when you should use a plot.\nWe will be taking our example from the peace studies literature. We are going to download data using the peacesciencer package and use it to partially reproduce a famous analysis of conflict onset by Fearon and Laitin."
  },
  {
    "objectID": "modules/module-4.2.html#run-a-regression-model-and-display-results-with-broom",
    "href": "modules/module-4.2.html#run-a-regression-model-and-display-results-with-broom",
    "title": "Module 4.2",
    "section": "Run a regression model and display results with broom",
    "text": "Run a regression model and display results with broom\n\nWe will start off by building a data frame for our analysis with the peacesciencer package. peacesciencer is designed to make standard analysis for conflict studies more convenient and includes many of the control variables that you would use to estimate the likelihood of conflict onset or duration.\nTo start, we call create_stateyears() to create a time-series data set for all available countries. We will specify system = 'gw' to denote the Gleditsch-Ward country coding system. Then we will filter for roughly the same years of Fearon and Laitin’s original analysis (1945-99) with the caveat that peacesciencer only has conflict data starting in 1946.\nThen we add a bunch of data to the data frame using the various add_X functions available in the package. Here we add UCDP conflict data which includes our dependent variable for this analysis–conflict onset. Then we add measures of democracy, ethno-religious fractionalization, GDP and terrain.\n\nlibrary(peacesciencer)\nlibrary(dplyr)\n\nconflict_df &lt;- create_stateyears(system = 'gw') |&gt;\n  filter(year %in% c(1946:1999)) |&gt;\n  add_ucdp_acd(type=c(\"intrastate\"), only_wars = FALSE) |&gt;\n  add_democracy() |&gt;\n  add_creg_fractionalization() |&gt;\n  add_sdp_gdp() |&gt;\n  add_rugged_terrain()\n\nglimpse(conflict_df)\n\nRows: 7,036\nColumns: 20\n$ gwcode         &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ statename      &lt;chr&gt; \"United States of America\", \"United States of America\",…\n$ year           &lt;dbl&gt; 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1…\n$ ucdpongoing    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ucdponset      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ maxintensity   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ conflict_ids   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ v2x_polyarchy  &lt;dbl&gt; 0.605, 0.587, 0.599, 0.599, 0.587, 0.602, 0.601, 0.594,…\n$ polity2        &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n$ xm_qudsest     &lt;dbl&gt; 1.259180, 1.259180, 1.252190, 1.252190, 1.270106, 1.259…\n$ ethfrac        &lt;dbl&gt; 0.2226323, 0.2248701, 0.2271561, 0.2294918, 0.2318781, …\n$ ethpol         &lt;dbl&gt; 0.4152487, 0.4186156, 0.4220368, 0.4255134, 0.4290458, …\n$ relfrac        &lt;dbl&gt; 0.4980802, 0.5009111, 0.5037278, 0.5065309, 0.5093204, …\n$ relpol         &lt;dbl&gt; 0.7769888, 0.7770017, 0.7770303, 0.7770729, 0.7771274, …\n$ wbgdp2011est   &lt;dbl&gt; 28.539, 28.519, 28.545, 28.534, 28.572, 28.635, 28.669,…\n$ wbpopest       &lt;dbl&gt; 18.744, 18.756, 18.781, 18.804, 18.821, 18.832, 18.848,…\n$ sdpest         &lt;dbl&gt; 28.478, 28.456, 28.483, 28.469, 28.510, 28.576, 28.611,…\n$ wbgdppc2011est &lt;dbl&gt; 9.794, 9.762, 9.764, 9.730, 9.752, 9.803, 9.821, 9.857,…\n$ rugged         &lt;dbl&gt; 1.073, 1.073, 1.073, 1.073, 1.073, 1.073, 1.073, 1.073,…\n$ newlmtnest     &lt;dbl&gt; 3.214868, 3.214868, 3.214868, 3.214868, 3.214868, 3.214…\n\n\nNow let’s go ahead and run the analysis. We will specify a logit model using the glm() function and specifying family = binomial(link = \"logit\"). We will store our model in an object called conflict_model. And from there we can use the tidy() function from the broom package to view the results.\nBefore doing this, though, try calling summary() from base R on the model. This provides us with a basic regression table and it is great insofar as we don’t want to do anything else with these estimates. Next, go ahead and call View() on the model object of just click on it to see what it looks like. You will notice that the results are stored in a complicated list format.\nThe tidy() function enables us to take the results from this list and store them in a “tibble”, which is the Tidyverse equivalent of a data frame. Once the results are stored like this, we can easily access the estimates for anything that we might want to do with them including combining the results of different models or displaying particular estimates in our document using all of the tools that we have learned in this course. We can also set conf.int = TRUE) as an argument in tidy() to create and store confidence intervals.\nBy default, tidy() returns p-values with large numbers of digits following the decimal point, making hard to tell whether the variables are significant. To fix this, we can pipe our tidy() output into a mutate_if() call and specify that we want numeric output to round to five decimal places.\n\nlibrary(broom)\n\nconflict_model &lt;- glm(ucdponset ~ ethfrac + relfrac + v2x_polyarchy + \n                        rugged + wbgdppc2011est + wbpopest,\n                  data= conflict_df,\n                  family = binomial(link=\"logit\"))\n\n# summary(conflict_model)\n\ntidy_model &lt;- conflict_model |&gt;\n  tidy(conf.int = TRUE) |&gt;\n  mutate_if(is.numeric, round, 5)\n\ntidy_model\n\n# A tibble: 7 × 7\n  term           estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     -5.69      1.41      -4.04  0.00005  -8.44      -2.92 \n2 ethfrac          0.800     0.381      2.10  0.0356    0.0670     1.56 \n3 relfrac         -0.391     0.417     -0.939 0.348    -1.22       0.420\n4 v2x_polyarchy   -0.602     0.509     -1.18  0.237    -1.61       0.387\n5 rugged           0.0641    0.0760     0.843 0.399    -0.0923     0.207\n6 wbgdppc2011est  -0.372     0.121     -3.08  0.00204  -0.613     -0.140\n7 wbpopest         0.293     0.0673     4.35  0.00001   0.162      0.426\n\n\nHow did we do relative to Fearon and Latin’s original analysis. Well, one thing that F&L were pretty certain about is that ethnic and religious fractionalization do not matter for conflict onset. But here we find a statistically significant relationship between these variables and conflict onset. But one thing we do find in common with their analysis is the importance of wealth and population. Both of these variables are significant in the expected direction. Wealthier countries experience less risk of conflict onset while more populous ones have a higher risk."
  },
  {
    "objectID": "modules/module-4.2.html#run-many-regressions-and-display-with-modelsummary",
    "href": "modules/module-4.2.html#run-many-regressions-and-display-with-modelsummary",
    "title": "Module 4.2",
    "section": "Run many regressions and display with modelsummary",
    "text": "Run many regressions and display with modelsummary\n\nbroom is really great if we want to just run one regression and see the results in the context of a working document. But what if we want to display our results to other researchers? For this, we need to use a different package. One package that is really good at producing professional-looking tabels is modelsummary and one of its strongest features is the ability to combine multiple models into the same table while still allowing for substantial customization.\nLet’s go ahead and store four models. In the first three, we will feature sets of predictors (ethnicity, democracy and terrain) and then a final model that includes all of our predictors. In each model, we will include wealth (GDP) and population as controls because we have a feeling that these are robust predictors of conflict onset.\n\nethnicity &lt;- glm(ucdponset ~ ethfrac + relfrac + wbgdppc2011est + wbpopest, # store each model in an object\n                  data = conflict_df,\n                  family = binomial(link=\"logit\"))\n\ndemocracy &lt;- glm(ucdponset ~ v2x_polyarchy + wbgdppc2011est +  wbpopest,\n                  data = conflict_df,\n                  family = binomial(link=\"logit\"))\n\nterrain &lt;- glm(ucdponset ~ rugged + wbgdppc2011est + wbpopest ,\n                  data = conflict_df,\n                  family = binomial(link=\"logit\"))\n\nfull_model &lt;- glm(ucdponset ~ ethfrac + relfrac + v2x_polyarchy + rugged +\n                        wbgdppc2011est + wbpopest,\n                  data = conflict_df,\n                  family = binomial(link=\"logit\"))\n\nNext we will store our models as a list with intuitive names that we can display as column headers in our regression table. Then we will store a new coefficient mapping where we rename our variables and change the order that they will appear in the table. We will also store a title and a reference.\n\nmodels &lt;- list(\"Ethnicity\" = ethnicity,  # store list of models in an object\n               \"Democracy\" = democracy, \n               \"Terrain\" = terrain, \n               \"Full Model\" = full_model)\n\ncoef_map &lt;- c(\"ethfrac\" = \"Ethnic Frac\",  # map coefficients\n        \"relfrac\" = \"Religions Frac\",     #(change names and order)\n        \"v2x_polyarchy\" = \"Polyarchy\",\n        \"rugged\" = \"Terrain\",\n        \"wbgdppc2011est\" = \"Per capita GDP\",\n        \"wbpopest\" = \"Population\",\n        \"(Intercept)\" = \"Intercept\")\n\ncaption = \"Table 1: Predictors of Conflict Onset\" # store caption\nreference = \"See appendix for data sources.\"      # store reference notes\n\nNow we can call modelsummary(). The first argument is the list of models we want to display. Next we tell modelsummary that we want it to show stars for statistical significance (stars = TRUE). And in gof_map, we say that, of the many goodness of fit statistics available to us, we only want to include the number of observations. Finally we plug our title into title = and a source note into notes =.\n\nlibrary(modelsummary)\n\nmodelsummary(models,                      # display the table\n             stars = TRUE,                # include stars for significance\n             gof_map = c(\"nobs\"),         # goodness of fit stats to include   \n             coef_map = coef_map,         # coefficient mapping\n             title = caption,             # title\n             notes = reference)           # source note\n\n\nTable 1: Predictors of Conflict Onset\n\n\nEthnicity\nDemocracy\nTerrain\nFull Model\n\n\n\nEthnic Frac\n0.744*\n\n\n0.800*\n\n\n\n(0.367)\n\n\n(0.381)\n\n\nReligions Frac\n−0.481\n\n\n−0.391\n\n\n\n(0.411)\n\n\n(0.417)\n\n\nPolyarchy\n\n−0.228\n\n−0.602\n\n\n\n\n(0.436)\n\n(0.509)\n\n\nTerrain\n\n\n0.031\n0.064\n\n\n\n\n\n(0.076)\n(0.076)\n\n\nPer capita GDP\n−0.474***\n−0.512***\n−0.543***\n−0.372**\n\n\n\n(0.104)\n(0.108)\n(0.092)\n(0.121)\n\n\nPopulation\n0.282***\n0.297***\n0.299***\n0.293***\n\n\n\n(0.067)\n(0.051)\n(0.050)\n(0.067)\n\n\nIntercept\n−4.703***\n−4.407***\n−4.296***\n−5.693***\n\n\n\n(1.327)\n(1.205)\n(1.143)\n(1.408)\n\n\nNum.Obs.\n6364\n6772\n6840\n6151\n\n\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n See appendix for data sources."
  },
  {
    "objectID": "modules/module-5.1.html",
    "href": "modules/module-5.1.html",
    "title": "Module 5.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall Shiny (install.packages(\"shiny\"))\nFamiliarize yourself with some of the materials available for developing Shiny Apps on Posit’s Shiny website\n\nOptional: sign up for a free account on shinyapps.io\n\nStart a new Shiny project for this lesson. Go to File, select New Directory and then Shiny App. Browse to where you want to save the app, give the directory a name and click Create Project."
  },
  {
    "objectID": "modules/module-5.1.html#overview",
    "href": "modules/module-5.1.html#overview",
    "title": "Module 5.1",
    "section": "Overview",
    "text": "Overview\nIn this module, we are going to be learning how to make a Shiny app. Shiny is a web application framework that is designed for building interactive web applications. It is available as an open-source package in R that is maintained by the team at Posit.\nShiny enables you to create interactive web-based visualizations and dashboards directly from your R code. It simplifies the process of developing web applications by providing a higher-level abstraction and handling the underlying web technologies. With Shiny, you can allow your users to explore data, change parameters, and see the results of an analysis dynamically without needing extensive web development skills.\nTo display a Shiny app you can just render it locally, but you likely want to share it with a broader audience. For this, you will need to host it on a server. There are lots of different to do this, but the easiest thing to use when you are getting started is shinyapps.io. In a later module we will learn to deploy our apps, but for this one it is fine to just view them locally.\nShiny apps consist of three components:1) a user interface (UI); 2) a server function; and 3) a call to the Shiny app. The UI is the part of the app that defines what the user is going to see and interact with. The server function runs all of the computations and produces the visualizations and output that you want to display. And the call to the Shiny app simply tells Shiny to run the app.\nWe are going to talk about each of these elements in turn, but first, have a look at this scatter plot app that we are going to but first take a few minutes to familiarize yourself with this scatter plot app that we are going to building in this this module:"
  },
  {
    "objectID": "modules/module-5.1.html#scatter-plot-app",
    "href": "modules/module-5.1.html#scatter-plot-app",
    "title": "Module 5.1",
    "section": "Scatter plot app",
    "text": "Scatter plot app"
  },
  {
    "objectID": "modules/module-5.2.html",
    "href": "modules/module-5.2.html",
    "title": "Module 5.2",
    "section": "",
    "text": "Prework\n\n\n\n\nGet a FRED API key\n\nInstall fredr, read about its basic usage and have a look at the FRED website\nInstall ecm, which we will use to build our recession shading helper script\nInstall shinyWidgets and familiarize yourself with its basic functions\nStart a new Shiny project for this lesson. Go to File, select New Directory and then Shiny App. Browse to where you want to save the app, give the directory a name and click Create Project."
  },
  {
    "objectID": "modules/module-5.2.html#overview",
    "href": "modules/module-5.2.html#overview",
    "title": "Module 5.2",
    "section": "Overview",
    "text": "Overview\nA fundmental concept in R Shiny is reactivity. Reactivity refers to the automatic responsiveness and dynamic behavior of the application based on user input and data changes. It allows the application to update and re-render specific parts of the user interface (UI) in response to changes in input values, data updates, or other reactive triggers.\nAll Shiny apps have an element of reactivity. In a basic Shiny app like we say in the last module, reactivity occurs when user input is fed to the server function through functions like renderPlot() or renderTable(). But we might also want to add additional elements of reactivity by using reactive functions like reactive() or observe(). In this lesson, we are going to look at how to use the reactive() function to control two separate reactive inputs to a line chart: the indicator the user wishes to view and the date range that the way to view it for. Here is the app that we are going to be building:"
  },
  {
    "objectID": "modules/module-5.2.html#app-with-a-reactive-api-call-and-date-parameters",
    "href": "modules/module-5.2.html#app-with-a-reactive-api-call-and-date-parameters",
    "title": "Module 5.2",
    "section": "App with a reactive API call and date parameters",
    "text": "App with a reactive API call and date parameters"
  },
  {
    "objectID": "modules/module-5.2.html#setup",
    "href": "modules/module-5.2.html#setup",
    "title": "Module 5.2",
    "section": "Setup",
    "text": "Setup\n\nIn the setup portion of our we want to start by loading the packages we will need to build the app. For this app, we are going to be using the fredr package to download data pertaining to the overall health of the economy from the St. Louis Fed’s Federal Reserve Economic Data (FRED)[https://fred.stlouisfed.org/] API. So here we will also set our FRED API key and assign the codes for the indicators that we want to download to objects.\nNext, we will use the as.Date() function to set the start date of our line series to Januar 1, 1970 and the end date as today’s date (system date). We will also create a list of variable names for our UI dropdown (vars) and relate them to the objects containing the indicator codes.\nFinally, we are going to be using a helper function to generate recession shading for our charts. Scroll down to the bottom of this page to see the code for the helper function. Take this and save it in an R file and put it in your app folder. In this chunk, we are going to call it with the source function, e.g. source(helper.R).\n\n# Load packages\nlibrary(shiny)\nlibrary(fredr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Set Fred API key \nfredr_set_key(\"YOUR FRED API KEY\") \n\n# Assign FRED series to objects\ncci &lt;- \"CSCICP03USM665S\" # consumer confidence\nbci &lt;- \"BSCICP03USM665S\" # business confidence\ncli &lt;- \"USALOLITONOSTSAM\" # composite lead indicator\nunemp_rate &lt;- \"UNRATE\" # unemployment rate\ngrowth &lt;- \"A191RL1Q225SBEA\" # growth rate\n\n# set start and end date\nstart_date &lt;- as.Date(\"1970-01-01\")\nend_date &lt;- as.Date(Sys.Date())\n\n# Create list of named values for the input selection\nvars &lt;- c(\"Consumer Confidence\" = cci, \n          \"Business Confidence\" = bci, \n          \"Composite Indicator\" = cli, \n          \"Unemployment Rate\" = unemp_rate,\n          \"Growth Rate\" = growth)\n\n# Load helper script\nsource(\"helper.R\") # scroll down, code pasted below"
  },
  {
    "objectID": "modules/module-5.2.html#ui",
    "href": "modules/module-5.2.html#ui",
    "title": "Module 5.2",
    "section": "UI",
    "text": "UI\n\nNow we can get started on developing the UI for our app. For this app, we are going to have a title panel and two main display elements. The first is a panel where the user can select the indicator that they want to chart and the second is a plot with a slider where users can select the years they want to view. So let’s divide the UI into two sections using the fluidRow() and column()\nThe fluidRow() function creates horizontal containers while the column() function is used to create vertical containers. Since we our app is going to display a single row, we will have just one fluidRow() call. Then we can divide that row into two columns using the column() function. The first argument in column()is the column width. Since column widths in Shiny are based on the Boots Bootstrap 12-wide grid system, our column widths must add up to 12. So let’s make our panel for selecting the indicator 4 units wide and the area where we will display the plot 8 units wide.\nFrom there, we can define the panel as a wellPanel() to give it an inset look and a grey background. We include selectInput() to get our dropdown where users can select an indicator from the vars list. Let’s also use the helpText() function to display some instructions regarding how to use the app.\nFor the main display section, we are going to have our plot out along with the slider input. We are going to call this input “range” and leave the label blank. Then we need to define a min value, a max value and a range for the slider. For min and max, we will use start_date and end_date, which we defined earlier in the setup and the combination of these to define the range (value). Then we set width to 100% because we want the slider to expand to fit the entire width of the plot. `\n\nui &lt;- fluidPage(\n\n    # Application title\n    titlePanel(\"FRED Data App\"),\n    \n    fluidRow(\n      \n      # 12 columns on one row: this panel will take 1/3 of it\n      column(4, wellPanel(\n        selectInput(\"indicator\", \"Indicator:\", vars)\n        ),\n      helpText(\"Select an indicator, choose a date range and view the trend. \n               The grey bars represent economic recessions. \n               The data for this app comes from the St. Louis Fed's \n               FRED database. The consumer confidence, business confidence and \n               lead composite indicators are OECD data downloaded through FRED.\")\n      ), \n      \n      # Remaining 2/3 occupied by plot\n      column(8,\n        plotOutput(\"lineChart\"),     \n        sliderInput(\n          \"range\",\n          \"\",\n          min = start_date,\n          max = end_date, \n          value = c(start_date, end_date), \n          width = \"100%\"\n        )\n      )\n    )\n)"
  },
  {
    "objectID": "modules/module-5.2.html#server",
    "href": "modules/module-5.2.html#server",
    "title": "Module 5.2",
    "section": "Server",
    "text": "Server\n\nFor our server function, we are going to define two separate reactive() functions. This is how we are going to dynamically update the plot based on two different user inputs. First, we will define an input for the indicator where input$indicator takes the user input from the dropdown menu to perform a fresh API call whenever the selected indicator changes. Then, we take that input and filter it based on the input from the slider, e.g. input$range. Then we render the plot based on these updated data.\nNotice that whenever we want to use the stored data from the reactive calls we need to add parentheses after the objects, e.g. fred_indicator() in the second reactive function or fred_data() in the ggplot call. This is to ensure that the reactive expression is evaluated and its current value is used as the input data for the plot.\nFinally, we are going to use the add_rec_shade() helper function to add the recession shading to the chart. We again use the inputs from the two reactive functions to define the start date and end date of the shading as well as the y-min and y-max values of the shaded rectangles.\n\nserver &lt;- function(input, output) {\n  \n    # Download data from FRED with reactive function. \n    # Only updates when user selects new indicator\n    fred_indicator &lt;- reactive({\n      fredr(series_id = input$indicator,\n        observation_start = start_date,\n        observation_end = end_date)\n    })\n  \n    # Filter data according to chosen years \n    # Only updates when user selects new data range\n    fred_data &lt;- reactive({\n      fred_indicator() |&gt;\n      filter(between(date, input$range[1],input$range[2])) \n   })\n\n    # Render line chart\n    output$lineChart &lt;- renderPlot({\n      \n      # Build plot with ggplot2\n      ggplot(fred_data(), aes(x = date, y = value)) + \n        geom_line(color = \"navyblue\") +\n        labs(\n          x = \"\", \n          y =  names(vars[which(vars == input$indicator)])\n        ) +\n        theme_minimal() +\n        # add recession shading\n        add_rec_shade(st_date = input$range[1], \n                      ed_date = input$range[2], \n                      shade_color = \"darkgrey\",\n                      y_min = min(fred_data()$value),\n                      y_max = max(fred_data()$value))\n    })\n}"
  },
  {
    "objectID": "modules/module-5.2.html#call-to-shiny-app",
    "href": "modules/module-5.2.html#call-to-shiny-app",
    "title": "Module 5.2",
    "section": "Call to Shiny app",
    "text": "Call to Shiny app\nOnce we have our UI and server functions defined we are ready to go. But don’t forget to include the call to the Shiny app or the app won’t run! Once this is in place, you can click “Run App” in the RStudio IDE to view the app locally. Optionally, right now, you can try setting up an account on shinyapps.io and try publishing your app on their server.\n\n# See above for the definitions of ui and server\nui &lt;- ...\n\nserver &lt;- ...\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "modules/module-5.2.html#helper-script",
    "href": "modules/module-5.2.html#helper-script",
    "title": "Module 5.2",
    "section": "Helper script",
    "text": "Helper script\nThis is the helper script for shaded recession rectangles. Save in a file called helper.R in same folder as your app.R file. See this post for more details.\n\nlibrary(ecm) # forlagpad\n\n# define add_rec_shade function\nadd_rec_shade&lt;-function(st_date,ed_date,shade_color, y_min, y_max) {\n  \n  # download NBER recession indicators, peak through trough\n  recession&lt;- fredr(series_id = \"USRECD\",\n                    observation_start = as.Date(st_date), \n                    observation_end = as.Date(ed_date))\n  \n  #code 1 for 1st day of recession, -1 for 1st day after it ends\n  recession$diff&lt;-recession$value-lagpad(recession$value,k=1)\n  \n  #drop 1st N.A. value\n  recession&lt;-recession[!is.na(recession$diff),] \n  \n  #create vector of recession start dates\n  recession.start&lt;-recession[recession$diff==1,]$date \n  \n  #create vector of recession end dates\n  recession.end&lt;-recession[recession$diff==(-1),]$date \n  \n  # if there are more dates listed in recession.start than recession.end\n  if(length(recession.start)&gt;length(recession.end))\n  # then enter system date for last date in recession.end\n  {recession.end&lt;-c(recession.end,Sys.Date())} \n  \n  # if there are more dates listed in recession.end than recession.start\n  if(length(recession.end)&gt;length(recession.start))       \n  # then enter the earliest date in recession$date as first date in recession.start  \n  {recession.start&lt;-c(min(recession$date),recession.start)} \n  \n  # make a dataframe out of recession.start and recession.end\n  recs&lt;-as.data.frame(cbind(recession.start,recession.end))\n  \n  # convert recession.start into a date\n  recs$recession.start&lt;-as.Date(\n    as.numeric(recs$recession.start),\n    origin=as.Date(\"1970-01-01\")) \n\n  # convert recession.end into a date\n  recs$recession.end&lt;-as.Date(\n    recs$recession.end,\n    origin=as.Date(\"1970-01-01\")) \n  \n  # if the number of rows in recs &gt; 0\n  if(nrow(recs)&gt;0) \n  # draw the rectangle  \n  {rec_shade&lt;-geom_rect(data=recs, \n                         # inherit.aes=F overrides default aesthetics\n                         inherit.aes=F, \n                         aes(xmin=recession.start, \n                         xmax=recession.end, \n                         ymin=y_min, ymax=y_max), \n                         fill=shade_color, alpha=0.5)\n    return(rec_shade)\n  }\n}"
  },
  {
    "objectID": "modules/module-5.1.knit.html",
    "href": "modules/module-5.1.knit.html",
    "title": "Module 5.1",
    "section": "",
    "text": "Tip\n\n\n\n\nGet a FRED API key\nInstall fredr and read about its basic usage\nInstall shiny and read about the"
  },
  {
    "objectID": "modules/module-5.1.knit.html#overview",
    "href": "modules/module-5.1.knit.html#overview",
    "title": "Module 5.1",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "modules/module-5.1.knit.html#scatter-plot-app",
    "href": "modules/module-5.1.knit.html#scatter-plot-app",
    "title": "Module 5.1",
    "section": "Scatter plot app",
    "text": "Scatter plot app"
  },
  {
    "objectID": "modules/module-5.1.knit.html#setup",
    "href": "modules/module-5.1.knit.html#setup",
    "title": "Module 5.1",
    "section": "Setup",
    "text": "Setup\n\n\nWrangle data and produce .csv file\nSay something about how to set up an app.R script. We could include this code in app.R file, but it would require more resources than a free account. So instead we will wrangle the data first and save it in a .csv file.\n\nlibrary(vdemdata)\nlibrary(dplyr)\nlibrary(readr)\n\ndem_data <- vdem |>\n  filter(year > 2000) |>\n  select(\n    country = country_name, \n    polyarchy = v2x_polyarchy,\n    clientelism = v2xnp_client,\n    corruption = v2xnp_regcorr,\n    womens_emp = v2x_gender,\n    gdp_pc = e_gdppc,\n    inf_mort = e_peinfmor,\n    life_exp = e_pelifeex,\n    education = e_peaveduc,\n    region = e_regionpol_6C \n  ) |>   mutate(\n    region = case_match(region, \n                        1 ~ \"Eastern Europe\", \n                        2 ~ \"Latin America\",  \n                        3 ~ \"Middle East\",   \n                        4 ~ \"Africa\", \n                        5 ~ \"The West\", \n                        6 ~ \"Asia\")\n  ) |>\n  group_by(country, region) |>\n  summarize_all(mean, na.rm = TRUE)\n\n#glimpse(dem_data)\n\nwrite_csv(dem_data, \"dem_data.csv\")\n\nThis chunk we will include in the app.R script.\n\n# load packages\nlibrary(shiny)\nlibrary(readr)\nlibrary(ggplot2)\n\n# load the data \ndem_data <- read_csv(\"dem_data.csv\")\n\n# create list of named values for the input selection\nvars <- c(\"Democracy\" = \"polyarchy\",\n          \"Clientelism\" = \"clientelism\",\n          \"Corruption\" = \"corruption\",\n          \"Women's Empowerment\" = \"womens_emp\",\n          \"Wealth\" = \"gdp_pc\",\n          \"Infant Mortality\" = \"inf_mort\",\n          \"Life Expectancy\" = \"life_exp\", \n          \"Education\" = \"education\")"
  },
  {
    "objectID": "modules/module-5.1.knit.html#ui",
    "href": "modules/module-5.1.knit.html#ui",
    "title": "Module 5.1",
    "section": "ui",
    "text": "ui\n\n\n# Define UI for application that draws a histogram\nui <- fluidPage(\n\n    # Application title\n    titlePanel(\"Democracy and Development\"),\n\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n      sidebarPanel(\n        selectInput('xcol', 'X Variable', vars),\n        selectInput('ycol', 'Y Variable', vars, selected = vars[[6]])\n      ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"scatterplot\")\n        )\n    )\n)"
  },
  {
    "objectID": "modules/module-5.1.knit.html#server",
    "href": "modules/module-5.1.knit.html#server",
    "title": "Module 5.1",
    "section": "Server",
    "text": "Server\n\n\n# Define server logic required to draw a scatter plot\nserver <- function(input, output, session) {\n  \n  # Render the plot\n  output$scatterplot <- renderPlot({\n    \n    # Combine the selected variables into a new data frame\n    selectedData <- dem_data[, c(input$xcol, input$ycol, \"region\")]\n    \n    # ggplot call\n    ggplot(selectedData(), aes_string(x = input$xcol, y = input$ycol)) +\n      geom_point(aes(color = region)) +\n      geom_smooth(method = \"loess\") +\n      scale_color_viridis_d(option = \"plasma\") +\n      theme_minimal() +\n      labs(\n        x =  names(vars[which(vars == input$xcol)]),\n        y =  names(vars[which(vars == input$ycol)]),\n        caption = \"Source: V-Dem Institute\", # caption\n        color = \"Region\" # legend title\n      )\n  })\n}"
  },
  {
    "objectID": "modules/module-5.1.knit.html#call-to-shiny-app",
    "href": "modules/module-5.1.knit.html#call-to-shiny-app",
    "title": "Module 5.1",
    "section": "Call to Shiny app",
    "text": "Call to Shiny app\n\n# See above for the definitions of ui and server\nui <- ...\n\nserver <- ...\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "modules/module-5.2.knit.html",
    "href": "modules/module-5.2.knit.html",
    "title": "Module 5.2",
    "section": "",
    "text": "Tip\n\n\n\n\nReview the prework for module 5.1 and make sure that you have everything installed\nInstall ecm, which we will use to build our recession shading helper script\nInstall shinyWidgets and familiarize yourself with its basic functions\nWe will be using lubridate, which is part of the Tidyverse. So it should already be installed; but take some time to familiarize yourself with its basic purpose and functions."
  },
  {
    "objectID": "modules/module-5.2.knit.html#overview",
    "href": "modules/module-5.2.knit.html#overview",
    "title": "Module 5.2",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "modules/module-5.2.knit.html#app-with-a-reactive-api-call-and-date-parameters",
    "href": "modules/module-5.2.knit.html#app-with-a-reactive-api-call-and-date-parameters",
    "title": "Module 5.2",
    "section": "App with a reactive API call and date parameters",
    "text": "App with a reactive API call and date parameters"
  },
  {
    "objectID": "modules/module-5.2.knit.html#setup",
    "href": "modules/module-5.2.knit.html#setup",
    "title": "Module 5.2",
    "section": "Setup",
    "text": "Setup\n\n\n# Load packages\nlibrary(shiny)\nlibrary(fredr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n# Set Fred API key \nfredr_set_key(\"YOUR FRED API KEY\") \n\n# Assign FRED series to objects\ncci <- \"CSCICP03USM665S\" # consumer confidence\nbci <- \"BSCICP03USM665S\" # business confidence\ncli <- \"USALOLITONOSTSAM\" # composite lead indicator\nunemp_rate <- \"UNRATE\" # unemployment rate\ngrowth <- \"A191RL1Q225SBEA\" # growth rate\n\n# set start and end date\nstart_date <- as.Date(\"1970-01-01\")\nend_date <- as.Date(Sys.Date())\n\n# Create list of named values for the input selection\nvars <- c(\"Consumer Confidence\" = cci, \n          \"Business Confidence\" = bci, \n          \"Composite Indicator\" = cli, \n          \"Unemployment Rate\" = unemp_rate,\n          \"Growth Rate\" = growth)\n\n# Load helper script\nsource(\"helper.R\") # scroll down, code pasted below"
  },
  {
    "objectID": "modules/module-5.2.knit.html#ui",
    "href": "modules/module-5.2.knit.html#ui",
    "title": "Module 5.2",
    "section": "ui",
    "text": "ui\n\nDefine UI for application that draws a line chart\n\nui <- fluidPage(\n\n    # Application title\n    titlePanel(\"FRED Data App\"),\n    \n    fluidRow(\n      \n      # 12 columns on one row: this panel will take 1/4 of it\n      column(3, wellPanel(\n        selectInput(\"indicator\", \"Indicator:\", vars)\n        ),\n      helpText(\"Select an indicator, choose a date range and view the trend. \n               The grey bars represent economic recessions. \n               The data for this app comes from the St. Louis Fed's \n               FRED database. The consumer confidence, business confidence and \n               lead composite indicators are OECD data downloaded through FRED.\")\n      ), \n      \n      # Remaining 3/4 occupied by plot\n      column(8,\n        plotOutput(\"lineChart\"),     \n        sliderInput(\n          \"range\",\n          \"\",\n          min = my(\"01-1970\"),\n          max = today(), \n          value = c(my(\"01-1970\"), today()), \n          width = \"100%\"\n        )\n      )\n    )\n)"
  },
  {
    "objectID": "modules/module-5.2.knit.html#server",
    "href": "modules/module-5.2.knit.html#server",
    "title": "Module 5.2",
    "section": "Server",
    "text": "Server\n\nDefine server logic required to draw a histogram.\n\nserver <- function(input, output) {\n  \n    # Download data from FRED with reactive function. \n    # Only updates when user selects new indicator\n    fred_indicator <- reactive({\n      fredr(series_id = input$indicator,\n        observation_start = start_date,\n        observation_end = end_date)\n    })\n  \n    # Filter data according to chosen years \n    # Only updates when user selects new data range\n    fred_data <- reactive({\n      fred_indicator() |>\n      filter(date %in% (input$range[1]:input$range[2]))\n   })\n\n    # Render line chart\n    output$lineChart <- renderPlot({\n      \n      # Build plot with ggplot2\n      ggplot(fred_data(), aes(x = date, y = value)) + \n        geom_line(color = \"navyblue\") +\n        labs(\n          x = \"\", \n          y =  names(vars[which(vars == input$indicator)])\n        ) +\n        theme_minimal() +\n        # add recession shading\n        add_rec_shade(st_date = input$range[1], \n                      ed_date = input$range[2], \n                      shade_color = \"darkgrey\",\n                      y_min = min(fred_data()$value),\n                      y_max = max(fred_data()$value))\n    })\n}"
  },
  {
    "objectID": "modules/module-5.2.knit.html#call-to-shiny-app",
    "href": "modules/module-5.2.knit.html#call-to-shiny-app",
    "title": "Module 5.2",
    "section": "Call to Shiny app",
    "text": "Call to Shiny app\n\n# See above for the definitions of ui and server\nui <- ...\n\nserver <- ...\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "modules/module-5.2.knit.html#helper-script",
    "href": "modules/module-5.2.knit.html#helper-script",
    "title": "Module 5.2",
    "section": "Helper script",
    "text": "Helper script\nHelper script for shaded recession rectangles. Save in a file called helper.R in same folder as your app.R file. See this post for more details.\n\n# build recession shading function \nlibrary(ecm)\n\nadd_rec_shade<-function(st_date,ed_date,shade_color, y_min, y_max) # are st_date and ed_date being used in this function?\n{\n  \n  recession<-fredr(series_id = \"USRECD\",observation_start = as.Date(st_date),observation_end = as.Date(ed_date))\n  \n  recession$diff<-recession$value-lagpad(recession$value,k=1) #code 1 for 1st day of recession, -1 for first day after recession ends\n  recession<-recession[!is.na(recession$diff),] #drop 1st N.A. value\n  recession.start<-recession[recession$diff==1,]$date #create vector of recession start dates\n  recession.end<-recession[recession$diff==(-1),]$date #create vector of recession end dates\n  \n  if(length(recession.start)>length(recession.end)) # if there are more dates listed in recession.start than recession.end\n  {recession.end<-c(recession.end,Sys.Date())} # enter system date for last date in recession.end\n  if(length(recession.end)>length(recession.start)) # if there are more dates listed in recession.end than recession.start         \n  {recession.start<-c(min(recession$date),recession.start)} # enter the earliest date in recession$date as first date in recession.start\n  \n  recs<-as.data.frame(cbind(recession.start,recession.end)) # make a dataframe out of recession.start and recession.end\n  recs$recession.start<-as.Date(as.numeric(recs$recession.start),origin=as.Date(\"1970-01-01\")) # convert recession.start into a date\n  recs$recession.end<-as.Date(recs$recession.end,origin=as.Date(\"1970-01-01\")) # convert recession.end into a \n  if(nrow(recs)>0) # if the number of rows in recs > 0\n  {\n    rec_shade<-geom_rect(data=recs, inherit.aes=F, #inherit.aes=F overrides default aesthetics\n                         aes(xmin=recession.start, xmax=recession.end, ymin=y_min, ymax=y_max), \n                         fill=shade_color, alpha=0.5)\n    return(rec_shade)\n  }\n}"
  },
  {
    "objectID": "index_temp.html",
    "href": "index_temp.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This page displays an outline of the topics, content, and assignments for the term. Each module starts on a Monday. There are no assignments due on Sundays.\n\n\n\n\n\n\n\nModule\n\n\n\n\nDate\n\n\n\n\nSkills\n\n\n\n\nPackages\n\n\n\n\nFunctions\n\n\n\n\nReadings\n\n\n\n\nReference\n\n\n\n\nVideos\n\n\n\n\nAssignments\n\n\n\n\n\n\n\n\n1.1\n\n\n\n\nr advdate(mon,0)\n\n\n\n\nRead data into R\n\n\n\n\nreadr\n\n\n\n\nread_csv(), glimpse()\n\n\n\n\n\n\n📖\n\n\n\n\n🖥️ 🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(tues,0)\n\n\n\n\nReshape data\n\n\n\n\ntidyr\n\n\n\n\npivot_longer()\n\n\n\n\n\n\n📖\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(wed,0)\n\n\n\n\nClean data\n\n\n\n\ndplyr, janitor , readr\n\n\n\n\nmutate_at(), clean_names() , write_csv()\n\n\n\n\n📖\n\n\n\n\n\n\n🖥️ 🖥️\n\n\n\n\n\n\n\n\n1.2\n\n\n\n\nr advdate(thur,0)\n\n\n\n\nDownload and filter data, select and create variables\n\n\n\n\nwbstats, vdemdata, dplyr\n\n\n\n\nwbstats(), vdem,\n\n\nfilter() , select(), mutate()\n\n\n\n\n\n\n\n\n🖥️ 🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(fri,0)\n\n\n\n\nMerge data frames\n\n\n\n\ncountrycode, dplyr\n\n\n\n\ncountry_code(), left_join()\n\n\n\n\n\n\n📖\n\n\n\n\n🖥️ 🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(sat,0)\n\n\n\n\nGroup, summarize and arrange data\n\n\n\n\ndplyr\n\n\n\n\ngroup_by(), summarize(), arrange()\n\n\n\n\n\n\n📖\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n2.1\n\n\n\n\nr advdate(mon,1)\n\n\n\n\nBar charts and histograms\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️ 🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 1)\n\n\n\n\nLine charts\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 1)\n\n\n\n\nScatter plots\n\n\n\n\n\n\n\n\n📖\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n2.2\n\n\n\n\nr advdate(thur, 1)\n\n\n\n\nColor schemes\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 1)\n\n\n\n\nAdd themes and annotations\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️ 🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 1)\n\n\n\n\nMake an interactive plot\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n3.1\n\n\n\n\nr advdate(mon, 2)\n\n\n\n\nChoropleth map\n\n\n\n\nrnaturalearth\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 2)\n\n\n\n\nMap data\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 2)\n\n\n\n\nMake a map function\n\n\n\n\n\n\n\n\n📖\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n3.2\n\n\n\n\nr advdate(thur, 2)\n\n\n\n\nUpload UCDP data\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 2)\n\n\n\n\nMake a leaflet map\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 2)\n\n\n\n\nCustomize your map\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n4.1\n\n\n\n\nr advdate(mon, 3)\n\n\n\n\nExploring tabular data\n\n\n\n\ntidycensus, kableExtra\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 3)\n\n\n\n\nMake a gt table\n\n\n\n\ngt\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 3)\n\n\n\n\nPlot confidence intervals\n\n\n\n\n\n\n\n\n📖\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n4.2\n\n\n\n\nr advdate(thur, 3)\n\n\n\n\nDisplay regression tables\n\n\n\n\nbroom\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 3)\n\n\n\n\nMake regression tables\n\n\n\n\nmodelsummary\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 3)\n\n\n\n\nCoefficient plots\n\n\n\n\n\n\n`\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n5.1\n\n\n\n\nr advdate(mon, 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 4)\n\n\n\n\n\n\n\n\n\n\n📖\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n5.2\n\n\n\n\nr advdate(thur, 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n6.1\n\n\n\n\nr advdate(mon, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n6.2\n\n\n\n\nr advdate(thur, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🖥️"
  },
  {
    "objectID": "modules/getting-started.html#github-and-github-classroom",
    "href": "modules/getting-started.html#github-and-github-classroom",
    "title": "Getting Started",
    "section": "GitHub and GitHub Classroom",
    "text": "GitHub and GitHub Classroom\n\nGitHub is a platform for hosting version control repositories. In this course we will learn to use GitHub to store, manage and collaborate on code.\nOne central concept you want to be familiar with is a repository or “repo” for short. Repos are essentially folders where code can be stored and then accessed and changed by multiple users. All of the assignments for this course will be managed in repos.\nGitHub repos are managed using a version control system named Git. Git allows developers to make and track changes to the code stored in the repo. Git also enables users to create branches to work on the code without affecting the main codebase and then merge those changes back into the main branch when they are ready.\nThe first thing you are going to want to do is to register a GitHub account. From there, you want to install Git and initiate Git using the usethis package. Be sure to install usethis first (install.packages(\"usethis\")) if you don’t have it installed already. Then load usethis (library(usethis)) and type use_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\") substituting the name and email associated with your GitHub account.\nNext, you need to generate a personal access token (PAT) by typing create_github_token() and set your credentials with the gitcreds package. This is pretty simple once you have your PAT. After installing and loading gitcreds (install.packages(\"gitcreds\"); library(gitcreds)), you can type gitcreds_get() to see whether you already have credentials set up. Then type gitcreds_set() to enter your new credentials (your username and your password, which will be the PAT that you just generated).\nNow, you can create a GitHub repo and clone it to your computer in RStudio. There a number of ways to clone a repo, but the recommended method for this course involves creating a new project in RStudio and selecting “Version Control” for the method (instead of “New Directory” as we did before). From there, select “Git”, copy the URL from the green “Code” tab in the GitHub repo, and paste it into “Repository URL” field. Next, select the directory where you want the repository to be created and click “create project.”\nFor our purposes all of your repos will be private repos in the GitHub Classroom environment. To access them, simply click on the invitation link that you see for the coding assignment in the relevant module on Blackboard. This should take you directly to the repo. Then you can clone it using the steps outlined in the previous paragrah."
  },
  {
    "objectID": "modules/module-1.2.html#merge-two-data-frames",
    "href": "modules/module-1.2.html#merge-two-data-frames",
    "title": "Module 1.2",
    "section": "Merge two data frames",
    "text": "Merge two data frames\n\nNow that we have a common country code, we can join the two data sets. There are many different types of joins. First there is a distinction between mutating joins, which add observations from one dataset to another, and filtering joins, which filter out observations based on their presence or absence in another dataset. Here we are going to be focused on mutating joins.\nThere are four kinds of mutating joins we can do in dplyr. An inner_join() keeps only the observations that are common in both datasets that you want to merge. A full_join() does the opposite. It keeps all of the observations present in both datasets regardless of whether or not they have a match. A left_join() keeps all of the observations in dataset \\(x\\) and only the matching observations in dataset \\(y\\). A right_join() does the same thing, but instead keeps all of the observations from dataset \\(y\\) and only matching observations from dataset \\(x\\).\nWe are going to use left_join() to merge our two datasets. left_join() takes three essential arguments: \\(x\\); \\(y\\); and \\(by\\) which identifies the column that we want to join on. For this exercise, the \\(x\\) dataset is going to be the democracy dataset, the \\(y\\) dataset is the women empowerment dataset, and we want to join on both the “iso3c” and “year” columns.\nWhen dplyr does a join, it renames any duplicate columns with suffixes like .x or .y. In our data, country is a duplicate column across the democracy and women’s empowerment datasets. So dplyr renames these country.x and country.y. It doesn’t really matter which one we keep, so let’s just rename country.x to country and filter out country.y using select().\nWe can can pipe all of these functions together and store the resulting data frame in a new object called dem_women. Let’s also save these data as a .csv file for future use with write_csv(). The first argument for write_csv() is the name of the data frame or tibble that we want to save. The second argument is the path and name of the file that we want to save it to.\n\n# Load readr\nlibrary(readr)\n\n# Perform left join using common iso3c variable and year\ndem_women &lt;- left_join(democracy, women_emp, by = c(\"iso3c\", \"year\")) |&gt; \n  rename(country = country.x) |&gt; # rename country.x\n  select(!country.y)             # crop country.y\n\n# Save as .csv for future use\nwrite_csv(dem_women, \"data/dem_women.csv\")\n\n# View the data\nglimpse(dem_women)  \n\nRows: 5,846\nColumns: 9\n$ country      &lt;chr&gt; \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico…\n$ vdem_ctry_id &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n$ iso3c        &lt;chr&gt; \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"…\n$ year         &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199…\n$ polyarchy    &lt;dbl&gt; 0.396, 0.418, 0.441, 0.451, 0.472, 0.489, 0.511, 0.560, 0…\n$ gdp_pc       &lt;dbl&gt; 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1…\n$ region       &lt;chr&gt; \"Latin America\", \"Latin America\", \"Latin America\", \"Latin…\n$ women_rep    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 14.20, 17.40, 18.20, 16.00, 1…\n$ flfp         &lt;dbl&gt; 33.94, 34.24, 35.01, 35.85, 36.38, 37.62, 37.69, 39.65, 3…"
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Course Syllabus",
    "section": "",
    "text": "Instructor: Prof. Emmanuel Teitelbaum\nEmail: ejt@gwu.edu\nThe best way to contact me is via email.\nVirtual Office/Student Hours: By appointment only. Please email me directly.\nCredit Hours: 3.0."
  },
  {
    "objectID": "course-syllabus.html#what-our-course-is-about",
    "href": "course-syllabus.html#what-our-course-is-about",
    "title": "Course Syllabus",
    "section": "What Our Course Is About",
    "text": "What Our Course Is About\nThis course will focus on working with data and code to engage data science questions. Students will develop coding, data visualization, and data presentation skills."
  },
  {
    "objectID": "course-syllabus.html#course-objectives-what-youll-be-able-to-do",
    "href": "course-syllabus.html#course-objectives-what-youll-be-able-to-do",
    "title": "Course Syllabus",
    "section": "Course Objectives: What You’ll Be Able To Do",
    "text": "Course Objectives: What You’ll Be Able To Do\nCourse and module objectives are guides to gauge your skill and knowledge development. By the end of this course, you should be able to:\n\nAnalyze data sets using modern computational tools.\nIdentify salient data points as they relate to key political science concepts.\nExplore ethical issues around data wrangling and visualization.\nApply data wrangling concepts to optimize data for modeling purposes.\nSummarize simple and complex relationships between and among variables in a data set.\nIdentify the most appropriate visualization format for a given data set.\nModel and visualize data based on requirements provided by stakeholders."
  },
  {
    "objectID": "course-syllabus.html#aiming-for-success",
    "href": "course-syllabus.html#aiming-for-success",
    "title": "Course Syllabus",
    "section": "Aiming For Success",
    "text": "Aiming For Success\nI care about your learning and also about this subject matter, and I am here to help you have a meaningful learning experience. I expect you to take ownership of your learning: you can get more out of the course by thoughtfully participating in discussions, actively taking notes on readings and lectures, and giving your best effort overall. I will hold you to the highest standards for academic honesty and integrity in your work. I will also encourage you to collaborate and learn from your peers through thoughtful and respectful discussion. It is recommended you log in daily order to keep up with course requirements. I must highlight that communication is vital, so I hope you feel comfortable reaching out to me if you are struggling or have concerns or need accommodations beyond accessibility. We can determine strategies to set you up for success. Finally, I look forward to collaborating with you in this course to create a meaningful experience for everyone."
  },
  {
    "objectID": "course-syllabus.html#office-hours",
    "href": "course-syllabus.html#office-hours",
    "title": "Course Syllabus",
    "section": "Office Hours",
    "text": "Office Hours\nAnother way we can work toward your success in the course is through office/student hours. Please make an appointment to talk with me during this time. You can work with me to:\n\nClarify any questions about the syllabus or course content\nReview an assignment you’ve completed and have questions about\nStep through practice problems or questions\nGet study strategies\nDiscuss grades\n\nTo make the meeting more effective, you can:\n\nGather materials (assignments, notes, etc.) ready in advance\nBe ready to take notes during office hours\nAsk follow up questions if you need clarification\nConfirm any action plan at the close of the meeting\nFollowing through on any action plan"
  },
  {
    "objectID": "course-syllabus.html#prerequisites",
    "href": "course-syllabus.html#prerequisites",
    "title": "Course Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nAcademic\nPSC 2101 or STAT 1051/1053/1111.\n\n\nTechnological\n\nConfiguration and software\nTo fully participate in our course, you will need regular access to broadband Internet access as well as other technology components. Please consult GW Online’s Technical Requirements and Support for details on recommended configurations and software available to you. You will need to use the following tools and platforms:\n\nRStudio: an IDE for generating data visualizations using the programming language, R.\nGitHub: a web-based code repository.\nGit: version control protocol.\nDiscord: a real-time chat application.\n\nPlease see the Blackboard Ultra course website for more on these tools and their policies.\n\n\nSkills\nFor our course, you should be able to:\n\nAccess and use GW’s Blackboard system.\nUse your GW email for university-related communications per university policy.\nUse productivity software (e.g., Office 365, Google Suite) to collaborate with peers and submit assignments.\nUse web conferencing tools (e.g., Zoom, Webex) to collaborate with peers and me.\nUse a mobile device and/or computer to upload documents, images, and recordings.\nSeek technology help and tools by contacting GW Information Technology | (202)-994-4948 | ithelp@gwu.edu.\n\nIf you need assistance with technology tools we’ll use in this course, please visit the Technology Support link in the left navigation menu in our course on Blackboard."
  },
  {
    "objectID": "course-syllabus.html#materials-youll-need",
    "href": "course-syllabus.html#materials-youll-need",
    "title": "Course Syllabus",
    "section": "Materials You’ll Need",
    "text": "Materials You’ll Need\nYou will need to download RStudio, Git and the Discord desktop application. You can find our weekly assigned readings through GW libraries. You must use your GW credentials to access these readings. Other course materials will be provided in our Blackboard course modules."
  },
  {
    "objectID": "course-syllabus.html#course-credit-hour-policy",
    "href": "course-syllabus.html#course-credit-hour-policy",
    "title": "Course Syllabus",
    "section": "Course Credit Hour Policy",
    "text": "Course Credit Hour Policy\nSummer courses are more than twice as intensive as those held during the academic year. Over 6 weeks, students will spend approximately 18.75 hours per week doing independent learning, including, but not limited to, readings, quizzes, assignments and a final project. This amounts to 36 hours of direct-instruction and 76.5 hours independent coursework.\n\nHow this applies to you\nUse the credit hour policy to plan and manage your workload and time spent on this course. Please contact me if you are having difficulty managing your workload, and we can discuss strategies to help you succeed in the course."
  },
  {
    "objectID": "course-syllabus.html#how-you-will-learn-and-demonstrate-knowledge",
    "href": "course-syllabus.html#how-you-will-learn-and-demonstrate-knowledge",
    "title": "Course Syllabus",
    "section": "How You Will Learn and Demonstrate Knowledge",
    "text": "How You Will Learn and Demonstrate Knowledge\nMy aim is to provide you opportunities for active learning and skills development that help you meet course learning objectives and also grow in your knowledge of this field.\n\nInstruction\nI’ve designed the following instructional components to support your learning and growth in the course.\n\nLecture Videos: Each week you will be responsible for watching or listening to video mini-lectures and/or podcasts. These media support provide you essential information in order to complete course activities and assessments. Please note that recorded lectures and podcasts are not a substitute for required readings.\nTutorial Videos: Each week you have the opportunity to explore a topic further by watching additional videos. These draw on the expertise of various organizations or individuals and can be used to help you complete activities and assessments.\nReadings: Each week you will be responsible for various reading assignments. The readings contain essential content for completing the course assignments.\n\n\n\nAssessment\nThe following assessments help you gauge and demonstrate your progress in the course and support you in meeting course learning objectives.\n\nDiscord: We will discuss course topics further through the Discord. You are expected to post original thoughts/reflections and respond substantively to others.[1] \nAssignments: You will develop various skills through regular assignments. You are expected to one coding assignment per week. Thoughtfully completing weekly assignments helps you meet course objectives.\nFinal Project: You will develop your own interactive data visualization application as your final project during Week 6/Module\n\n\n\n\n\nQuizzes: In this course, you will have opportunities to assess your own knowledge. You are expected to complete two weekly quizzes that provide immediate feedback and support ongoing learning.\n\nYou’ll find support for Blackboard and other tools used for course activities and assignments under the Technology Support link in the left navigation menu in our course on Blackboard."
  },
  {
    "objectID": "course-syllabus.html#demonstrating-academic-integrity",
    "href": "course-syllabus.html#demonstrating-academic-integrity",
    "title": "Course Syllabus",
    "section": "Demonstrating Academic Integrity",
    "text": "Demonstrating Academic Integrity\nAll of us in the course will comply with the GW Code of Academic Integrity. It states that “we, the Students, Faculty, Librarians, Staff, and Administration of The George Washington University, believing academic integrity to be central to the mission of the University, commit ourselves to promoting high standards for the integrity of academic work. Commitment to academic integrity upholds educational equity, development, and dissemination of meaningful knowledge, and mutual respect that our community values and nurtures. The George Washington University Code of Academic Integrity is established to further this commitment.”\nAcademic dishonesty is defined as cheating of any kind, including misrepresenting one’s own work, taking credit for the work of others without crediting them and without appropriate authorization, and the fabrication of information. For details and complete code, see the Code of Academic Integrity.Common examples of academic dishonesty include cheating, fabrication, plagiarism, falsification, forgery of University academic documents, and facilitating academic dishonesty by others. Learn more about avoiding these:\n\nGW guidance for students on academic integrity.\nPlagiarism: What is it and how to avoid it from GW Libraries.\nMaintaining academic honesty can be a challenging skill to learn. If you have questions about maintaining our course standards, please talk with me early on."
  },
  {
    "objectID": "course-syllabus.html#assignments",
    "href": "course-syllabus.html#assignments",
    "title": "Course Syllabus",
    "section": "Assignments",
    "text": "Assignments\n\nQuizzes (20%)\nCoding assignments (40%)\nFinal project (40% of final grade)\n\nAssignment 1 (10%)\nAssignment 2 (10%)\nAssignment 3 (20%)\n\n\n\nQuizzes\nStudents will complete ten graded quizzes. These exercises will be oriented towards strengthening the student’s ability to manipulate, visualize and communicate data with R and Quarto.\n\n\nCoding Assignments\nStudents will complete five weekly coding assignments. These assignments are designed to provide students with the opportunity to apply their newly-acquired skills to a classic question in political science.\n\n\nFinal Project\nEach student will complete a final project that will be developed throughout the semester in three parts. The ultimate objective of this project is for the student to design and program an R Shiny App. politics."
  },
  {
    "objectID": "course-syllabus.html#course-grading",
    "href": "course-syllabus.html#course-grading",
    "title": "Course Syllabus",
    "section": "Course Grading",
    "text": "Course Grading\nThe grading scale below maps your final point or percentage total to your final letter grade for the course.\n\n\n\nRange\nLetter Grade\n\n\n\n\n94-100\nA\n\n\n90-93\nA-\n\n\n87-89\nB+\n\n\n84-86\nB\n\n\n80-83\nB-\n\n\n77-79\nC+\n\n\n74-76\nC\n\n\n70-73\nC-\n\n\n67-69\nD+\n\n\n64-66\nD\n\n\n60-63\nD-\n\n\n&lt;59\nF"
  },
  {
    "objectID": "course-syllabus.html#late-work",
    "href": "course-syllabus.html#late-work",
    "title": "Course Syllabus",
    "section": "Late Work",
    "text": "Late Work\nIf you miss an assignment deadline, it is your responsibility to contact me via email. Accommodations are automatically approved for university-approved absences such as sporting events, religious holidays, etc."
  },
  {
    "objectID": "course-syllabus.html#incomplete-grades",
    "href": "course-syllabus.html#incomplete-grades",
    "title": "Course Syllabus",
    "section": "Incomplete Grades",
    "text": "Incomplete Grades\n\nUndergraduate students\nIncomplete grades may be given to undergraduate students only if for reasons beyond the student’s control (such as medical or family emergency) they are unable to complete the final work of the course. Faculty should not assign an Incomplete grade if not asked by the student.\nA contractmust be signed by the instructor and the student and filed in the department office. A copy should be submitted to the Academic Advising office in Phillips 107. A student has up to a calendar year to finish the coursework for the class, and when completed a grade change form must be submitted to the Academic Advising office to update the grade.\nFor further policy and contract information for undergraduate students, please consult with your advisor and also visit the website for Columbian College of Arts and Sciences Academic Advising.\n\n\nGraduate students\nIncomplete grades may be given to graduate students only if for reasons beyond the student’s control (such as medical or family emergency) they are unable to complete the final work of the course. Faculty should not assign an Incomplete grade if not asked by the student.\nFor further information, please consult with your advisor and complete a CCAS graduate student incomplete grade form."
  },
  {
    "objectID": "course-syllabus.html#course-communication",
    "href": "course-syllabus.html#course-communication",
    "title": "Course Syllabus",
    "section": "Course Communication",
    "text": "Course Communication\nCommunication in our course is essential; clearing up questions earlier than later is a good practice, so please don’t hesitate to reach out to me. In any mode of communication used in our course, all of us will follow netiquette found in our syllabus.\nWe will communicate primarily through GW’s Blackboard System and the Discord server. Announcements and emails sent through Blackboard automatically go to your GW email address (i.e., userid@gwu.edu). Please check your GW email account on a daily basis or forward your GW email to another address that you check daily.\nI will respond to emails/discussion posts within 48 hours (i.e., “24 hours on weekdays and on the next business day over weekends and holidays.”) I will provide feedback on assignments/exams within 3 days (i.e., “five days on weekdays and on the next business day over weekends and holidays.”)\nYou can post general course-related questions to our Discord server. Please post your question here first rather than emailing me directly if your question regards the course material. However, if you have a question that is more personal in nature (i.e., grades), please email me directly to set up an appointment."
  },
  {
    "objectID": "course-syllabus.html#netiquette",
    "href": "course-syllabus.html#netiquette",
    "title": "Course Syllabus",
    "section": "Netiquette",
    "text": "Netiquette\nBehind every name there is a person.\nTo ensure safe and meaningful learning experiences for everyone, we all agree to:\n\nRemain professional, respectful, and courteous at all times on all platforms.\nKeep in mind this is a college class. Something that would be inappropriate in an in-person classroom is also inappropriate in an online classroom.\nWhen upset, we’ll wait a day or two prior to posting. Messages posted or emailed in anger are often regretted later.\nAsk one another for clarification if we find a communication offensive or difficult to understand.\nAvoid sweeping generalizations. Back up our stated opinions with facts and reliable sources.\nUnderstand that we may disagree and that exposure to other people’s opinions is part of the learning experience.\nJust as we would like our privacy respected, we will respect the privacy of other course participants and what they share.\n\nI (the instructor) reserve the right to delete any post or communication in our course that is deemed inappropriate without prior notification to the student. This includes anything containing language that is offensive, rude, profane, racist, or hateful. Items that are seriously off-topic or serve no purpose other than to vent frustration will also be removed.\nUsing outside communication apps\nI am aware that you and your peers might communicate using tools outside of GW’s Blackboard, my course website, our course Discord channel, or email systems. Rules of netiquette and appropriate communication extend to these tools as well as to Blackboard. If you see any tool being used inappropriately (i.e., any communication containing language that is offensive, rude, profane, racist, or hateful; uses that promote cheating of any kind), contact me as soon as possible to speak privately about it.\n(Adapted from Lake Superior Connect, Creative Commons Attribution 3.0)"
  },
  {
    "objectID": "course-syllabus.html#policies",
    "href": "course-syllabus.html#policies",
    "title": "Course Syllabus",
    "section": "Policies",
    "text": "Policies\nTo make this a meaningful learning experience for everyone, please read and understand the following policies. All GW policies can be found on the GW Office of Ethics, Compliance, and Privacy site. All GW community members are responsible for adhering to and activating in accordance with all university policies. Please contact me if you have any questions."
  },
  {
    "objectID": "course-syllabus.html#accessibility-and-accommodations",
    "href": "course-syllabus.html#accessibility-and-accommodations",
    "title": "Course Syllabus",
    "section": "Accessibility and Accommodations",
    "text": "Accessibility and Accommodations\n\nGW’s Disability Support Services\nIf you are a student with a disability, or think you may have a disability, you can let me know, and/or you can talk to GW’s Office of Disability Support Services (DSS). DSS works with both students with disabilities and instructors to identify reasonable accommodations. Contact the DSS office at (202) 994-8250, by email on dss@gwu.edu, or in-person in Rome Hall Suite 102 to establish eligibility and to coordinate reasonable accommodations. If you have already been approved for accommodations, please send me your accommodation letter and meet with me so we can develop an implementation plan together.\nHow are course technology tools accessible to everyone? To find out, access Technology Support Technology Tools Policies in the Blackboard course menu.\n\n\nAccommodations Beyond Disability\nEveryone has different needs for learning. If you don’t have a documented disability but feel that you would benefit from learning support for other reasons, please don’t hesitate to talk to me. If you have substantial non-academic obligations or other concerns (e.g., food insecurity, work, childcare, athletic commitments, language barriers, financial issues, technology access, commuting, etc.) that make learning difficult, please contact me. I’ll keep this information confidential, and together, we can brainstorm ways to meet your needs.\n\n\nOther Needs\nAny student who has difficulty affording groceries or accessing sufficient food to eat every day, or who lacks a safe and stable place to live, and believes this may affect their performance in the course, is urged to contact GW’s Office of Student Financial Assistance for support. Furthermore, please notify me if you are comfortable doing so. Some other resources to support you are found under the course menu item Student Resources and include support for academic achievement and personal well-being. (Adapted from Goldrick-Rab, 2017)"
  },
  {
    "objectID": "course-syllabus.html#counseling-and-psychological-services",
    "href": "course-syllabus.html#counseling-and-psychological-services",
    "title": "Course Syllabus",
    "section": "Counseling and Psychological Services",
    "text": "Counseling and Psychological Services\nGW’s Health Center offers counseling and psychological services to GW students. Please note that staff is licensed to offer short term therapy to students in Washington, DC, Maryland, and Virginia. If you are living outside these regions, the office may be able to refer you elsewhere. Assistance and referrals 24 hours a day, 365 days a year and can be reached on (202) 994-5300.\nThe Center provides assistance and referral to address students’ personal, social, career, and study skills problems. Services for students include: crisis and emergency mental health consultations, confidential assessment, counseling services (individual and small group), and referrals.\nVirtual Workshops are open to any student regardless of geographic location. These can be exceptionally valuable and help you build essential skills and cope with common ongoing mental health concerns. Please contact the GW Health Center on (202) 994-5300 for more information."
  },
  {
    "objectID": "course-syllabus.html#religious-observances",
    "href": "course-syllabus.html#religious-observances",
    "title": "Course Syllabus",
    "section": "Religious Observances",
    "text": "Religious Observances\nAs members of the GW community, you have the right to observe religious holidays. University policy requires that students notify their instructors during the first week of the semester if they plan to be absent from class on days of religious observance. For further details, please consult the university policy on religious holiday observance."
  },
  {
    "objectID": "course-syllabus.html#key-dates",
    "href": "course-syllabus.html#key-dates",
    "title": "Course Syllabus",
    "section": "Key Dates",
    "text": "Key Dates\nPlease defer to the due dates listed on the course website. You can also view due dates in the gradebook and under each individual course assignment item in Blackboard Ultra."
  },
  {
    "objectID": "project/project-assignment-1.html",
    "href": "project/project-assignment-1.html",
    "title": "Project Assignment 1",
    "section": "",
    "text": "For your final project in this course, you will be producing your very own Shiny App. The purpose of this assignment is to get you to think through the basic content and layout off your app. As you will learn, Shiny Apps are comprised of two basic elements: a user interface and a server function. We are going to be focusing on the user interface side of things for now and later we will talk about how to generate the content for the user. What do you want your user to see and experience with your app? That is the question you will answer here."
  },
  {
    "objectID": "project/project-assignment-1.html#step-1-think-about-a-layout-for-your-app-25-pts.",
    "href": "project/project-assignment-1.html#step-1-think-about-a-layout-for-your-app-25-pts.",
    "title": "Project Assignment 1",
    "section": "Step 1: Think about a layout for your app (25 pts.)",
    "text": "Step 1: Think about a layout for your app (25 pts.)\nGo to the Shiny gallery and have a look at examples of the Shiny Apps there. You can also go forward in the course a bit and have a look at the apps that we are going to be building together in modules 5.1 and 5.2. Among these apps, which layouts appeal to you most? Link to a few of them and talk about what you like here."
  },
  {
    "objectID": "project/project-assignment-1.html#step-2-think-about-the-basic-content-25-pts.",
    "href": "project/project-assignment-1.html#step-2-think-about-the-basic-content-25-pts.",
    "title": "Project Assignment 1",
    "section": "Step 2: Think about the basic content (25 pts.)",
    "text": "Step 2: Think about the basic content (25 pts.)\nNext, think about the basic content of your app. What subject matter and data do you want to have your user explore? What do you want them to get out of the experience? What datasets would you use for your app? These could be datasets that we have used for the course or other sources but it should be comprehensive and convenient to work with. You will not have time in this course to do original data collection. Discuss in a paragraph below."
  },
  {
    "objectID": "project/project-assignment-1.html#step-3-think-about-the-visualization-25-pts.",
    "href": "project/project-assignment-1.html#step-3-think-about-the-visualization-25-pts.",
    "title": "Project Assignment 1",
    "section": "Step 3: Think about the visualization (25 pts.)",
    "text": "Step 3: Think about the visualization (25 pts.)\nWhat is the type of visualization that you want to display. This could be a line chart, scatter plot, bar chart or map and could include some text elements as well. How would your selected visualization contribute to the knowledge enhancement that you want your user to experience? What would it teach them. Discuss in a paragraph below."
  },
  {
    "objectID": "project/project-assignment-1.html#step-4-think-about-user-input-25-pts.",
    "href": "project/project-assignment-1.html#step-4-think-about-user-input-25-pts.",
    "title": "Project Assignment 1",
    "section": "Step 4: Think about user input (25 pts.)",
    "text": "Step 4: Think about user input (25 pts.)\nWhat would the user manipulate in your app? It could be a dropdown menu, a slider or some other control. See here for a list of control widgets. When your user interacts with the control, what output will it produce, e.g. what will change when the user manipulates the widget? How would your chosen control widget enhance the user’s experience and contribute to the overall purpose of the app?"
  },
  {
    "objectID": "project/project-assignment-2.html",
    "href": "project/project-assignment-2.html",
    "title": "Project Assignment 2",
    "section": "",
    "text": "For the first project assignment, you thought about some rough content for your app and how the user would produce some sort of visualization with it. For this assignment, we will take the next step and think about how we will generate that output on the server side. For this, we need to think concretely about what kind of setup or prework we need to do in the app.R file. Then we need to think about reactivity and how user input will change the output rendered by the app. We also want to think about any helper functions and externally sourced code that we want to include (although this is not imperative in every case)."
  },
  {
    "objectID": "project/project-assignment-2.html#step-1-think-about-the-packages-you-will-need-for-your-app",
    "href": "project/project-assignment-2.html#step-1-think-about-the-packages-you-will-need-for-your-app",
    "title": "Project Assignment 2",
    "section": "Step 1: Think about the packages you will need for your app",
    "text": "Step 1: Think about the packages you will need for your app\nStarting with shiny you will need to load packages in the app.R. Likely you will also include ggplot2. What other packages are you going to need? Will you need dplyr to wrangle some data? readr to read in a .csv file? You may find you need other packages as you go along, but list the ones you know about now."
  },
  {
    "objectID": "project/project-assignment-2.html#step-2-how-will-you-wranlge-or-load-data",
    "href": "project/project-assignment-2.html#step-2-how-will-you-wranlge-or-load-data",
    "title": "Project Assignment 2",
    "section": "Step 2: How will you wranlge or load data?",
    "text": "Step 2: How will you wranlge or load data?\nWhat indicators, countries, regions, etc. will the user get to select and how will you wrangle the data so that it is available to them? How will you get your data into the app? Will you wrangle it ahead of time and store it in a .csv file? Or will your app include an API call? If you have an API call, how will you keep it from overwhelming the resources of your server (for example, Shiny.io only allows 1GB of RAM for the free version of its hosting service)?"
  },
  {
    "objectID": "project/project-assignment-2.html#step-3-what-kinds-of-lists-will-you-need",
    "href": "project/project-assignment-2.html#step-3-what-kinds-of-lists-will-you-need",
    "title": "Project Assignment 2",
    "section": "Step 3: What kinds of lists will you need?",
    "text": "Step 3: What kinds of lists will you need?\nWhat kinds of lists will you need for your dropdown menus or other input? How will you filter(), select() and pull() from your data frame to create these lists?"
  },
  {
    "objectID": "project/project-assignment-2.html#step-4-what-is-the-rough-structure-of-your-ui",
    "href": "project/project-assignment-2.html#step-4-what-is-the-rough-structure-of-your-ui",
    "title": "Project Assignment 2",
    "section": "Step 4: What is the rough structure of your ui?",
    "text": "Step 4: What is the rough structure of your ui?\nWhat is the rough structure of your ui? For example, how many columns will be occupied by user input fields versus how many columns will be occupied by your visualization? And, crucially, what input functions will you include?"
  },
  {
    "objectID": "project/project-assignment-2.html#step-5-what-is-the-rough-structure-for-your-server",
    "href": "project/project-assignment-2.html#step-5-what-is-the-rough-structure-for-your-server",
    "title": "Project Assignment 2",
    "section": "Step 5: What is the rough structure for your server?",
    "text": "Step 5: What is the rough structure for your server?\nWhat are the reactive functions of your server? Will you have just one reactive function for your plot call? Or will you need multiple reactive functions in order to coordinate different inputs, like dropdown menus that select a country case and a slider that selects a range of years?"
  },
  {
    "objectID": "project/project-assignment-2.html#step-6-how-will-you-call-your-data-for-your-visualization",
    "href": "project/project-assignment-2.html#step-6-how-will-you-call-your-data-for-your-visualization",
    "title": "Project Assignment 2",
    "section": "Step 6: How will you call your data for your visualization?",
    "text": "Step 6: How will you call your data for your visualization?\nWhat will be the basic variables that you will call in aes()? How specifically do you anticipate grabbing the data in a reactive context?"
  },
  {
    "objectID": "project/project-assignment-3.html",
    "href": "project/project-assignment-3.html",
    "title": "Project Assignment 3",
    "section": "",
    "text": "Now that you have a clear sense of where you are going with your app, it is time to build it. This is the hard part and you will likely have to invest significant time in wrangling your data and debugging the app. Be patient! It will turn out great and you will have a nice project to show for it."
  },
  {
    "objectID": "project/project-assignment-3.html#step-1-setup",
    "href": "project/project-assignment-3.html#step-1-setup",
    "title": "Project Assignment 3",
    "section": "Step 1: Setup",
    "text": "Step 1: Setup\nStart a new Shiny app in R Studio. In your app.R file, begin by loading your packages, loading and/or wrangling your data, and creating lists for your inputs."
  },
  {
    "objectID": "project/project-assignment-3.html#step-2-define-the-ui",
    "href": "project/project-assignment-3.html#step-2-define-the-ui",
    "title": "Project Assignment 3",
    "section": "Step 2: Define the ui",
    "text": "Step 2: Define the ui\nStarting with ui &lt;- fluidPage(), start building your UI. Add a titlePanel(), a fluidRow() and then add the various columnar elements that you want to include such as inputs, text and the plot output. Try running your app just with the ui set up and see how it looks."
  },
  {
    "objectID": "project/project-assignment-3.html#step-3-define-the-server-logic",
    "href": "project/project-assignment-3.html#step-3-define-the-server-logic",
    "title": "Project Assignment 3",
    "section": "Step 3: Define the server logic",
    "text": "Step 3: Define the server logic\nBuild your reactive function(s) and specify how the data and output will change based on user input(s). This is a process that is very specific to each project, so it is hard to say anything general here. But when in the process of building your server function, it often helps to look back at examples we have done in class or those that you might find helpful in the Shiny gallery."
  },
  {
    "objectID": "project/project-assignment-3.html#step-4-debug-your-app",
    "href": "project/project-assignment-3.html#step-4-debug-your-app",
    "title": "Project Assignment 3",
    "section": "Step 4: Debug your app",
    "text": "Step 4: Debug your app\nAre you having issues with your code? See this post and reach out for help on Discord."
  },
  {
    "objectID": "project/project-assignment-3.html#step-5-post-your-app-to-shinyapps.io",
    "href": "project/project-assignment-3.html#step-5-post-your-app-to-shinyapps.io",
    "title": "Project Assignment 3",
    "section": "Step 5: Post your app to shinyapps.io",
    "text": "Step 5: Post your app to shinyapps.io\nSign up for a free account at https://www.shinyapps.io/. When you are ready, hit the little blue icon at the top of your app.R window to publish it."
  },
  {
    "objectID": "project/project-assignment-3.html#step-6-record-a-video-or-writeup-your-results",
    "href": "project/project-assignment-3.html#step-6-record-a-video-or-writeup-your-results",
    "title": "Project Assignment 3",
    "section": "Step 6: Record a video or writeup your results",
    "text": "Step 6: Record a video or writeup your results\nYou have two options for presenting your app. You can post a five- to ten-minute video using a service like Vimeo or you can write two pages about your app.In your presentationk, talk about the main features of the app. What kinds of data can users explore and then also what kinds of patterns emerge from the data and what we learn from the visualization that we might not have thought of before."
  },
  {
    "objectID": "project/project-assignment-2.html#step-1-what-packages-you-will-need-for-your-app",
    "href": "project/project-assignment-2.html#step-1-what-packages-you-will-need-for-your-app",
    "title": "Project Assignment 2",
    "section": "Step 1: What packages you will need for your app?",
    "text": "Step 1: What packages you will need for your app?\nStarting with shiny you will need to load packages in the app.R. Likely you will also include ggplot2. What other packages are you going to need? Will you need dplyr to wrangle some data? readr to read in a .csv file? You may find you need other packages as you go along, but list the ones you know about now."
  },
  {
    "objectID": "project/project-assignment-2.html#step-2-how-will-you-wrangle-or-load-data",
    "href": "project/project-assignment-2.html#step-2-how-will-you-wrangle-or-load-data",
    "title": "Project Assignment 2",
    "section": "Step 2: How will you wrangle or load data?",
    "text": "Step 2: How will you wrangle or load data?\nWhat indicators, countries, regions, etc. will the user get to select and how will you wrangle the data so that it is available to them? How will you get your data into the app? Will you wrangle it ahead of time and store it in a .csv file? Or will your app include an API call? If you have an API call, how will you keep it from overwhelming the resources of your server (for example, Shiny.io only allows 1GB of RAM for the free version of its hosting service)?"
  },
  {
    "objectID": "assignments/coding-assignment-2.html",
    "href": "assignments/coding-assignment-2.html",
    "title": "Coding Assignment 2",
    "section": "",
    "text": "For this assignment, you are going to evaluate modernization theory as laid out in Seymour Martin Lipset’s classic article entitled “Some Social Requisites of Democracy: Economic Development and Political Legitimacy.” How classic is this article? According to Google Scholar, this piece has been cited more than 11.5 thousand times!\nWe are going to use data from V-Dem and modern data viz tools to explore Lipset’s hypothesis that economic modernization is highly correlated with democracy. We have already done this to some extent by looking at the relationship between wealth and the polyarchy score. But we are going to broaden things out by looking at other measures of modernization and democracy contained in the V-Dem dataset.\nBefore starting on this assignment, you will want to have a look at the V-Dem codebook. Look through the sections titled “V-Dem Indicators” and “Background Factors (E).” There are five democracy indicators, one of which is the polyarchy index. There are a number of background factors, many of which pertain to economic modernization. We are going to be looking at the relationship between these two sets of variables.\nNow have a look at “Some Social Requisites of Democracy” and in particular pay attention to the indicators in Table II and the discussion surrounding them. Think of each indicator (e.g. urbanization, education, etc.) as a sub-hypothesis of his theory. Which of these sub-hypotheses about modernization do you think is most compelling? Which would you like to test?\nSubmission note: Accept the invitation on Blackboard to submit this assignment via GitHub."
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-1-gather-your-data",
    "href": "assignments/coding-assignment-2.html#step-1-gather-your-data",
    "title": "Coding Assignment 2",
    "section": "Step 1: Gather Your Data",
    "text": "Step 1: Gather Your Data\nUse the vdemdata package to download data for your analysis. Since we already looked at the polyarchy score and wealth in class, you need to use a different measure of democracy and a different background factor for your analysis. Use a select() verb to include country, year, region (e_regionpol_6C), at least one of the other four measures of democracy, and one background factor that is not per capita GDP. Store your data in an object called dem_data. Pipe in a mutate() verb and use case_match() to label the regions. Review module 1.2 if you are confused on how to do this."
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-2-make-a-bar-chart",
    "href": "assignments/coding-assignment-2.html#step-2-make-a-bar-chart",
    "title": "Coding Assignment 2",
    "section": "Step 2: Make a bar chart",
    "text": "Step 2: Make a bar chart\na) Insert a code chunk below this line and label it. Wrangle your data for the bar chart. Filter by year to include data since 2000, group by region and summarize by mean. Save the new data in an object called bar_chart_data.\nb) Insert a code chunk below this line and label it. Use ggplot() and geom_col() to create a bar chart showing levels of democracy across the regions with your wrangled data. Make sure to add appropriate axis labels, a title and a caption. Add a theme to spruce it up a bit.\nNote: From here on out I will expect you to know to add a code chunk and label it."
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-3-make-a-colorblind-friendly-line-chart",
    "href": "assignments/coding-assignment-2.html#step-3-make-a-colorblind-friendly-line-chart",
    "title": "Coding Assignment 2",
    "section": "Step 3: Make a colorblind-friendly line chart",
    "text": "Step 3: Make a colorblind-friendly line chart\na) Filter your dem_data to include three or four countries of your choosing and create a line chart of your democracy indicator. You can save the data as a new data frame called dem_data_line or you can pipe your filtered data directly into ggplot().\nb) Use cvdPlot() to view your chart from the standpoint of someone with red-green color blindness and describe what you see.\nc) Add a colorblind-friendly color map using viridis or ColorBrewer.\nd) Run the plot through cvdPlot() and describe what you see. Is your plot colorblind friendly?"
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-4-make-a-scatter-plot-with-annotation",
    "href": "assignments/coding-assignment-2.html#step-4-make-a-scatter-plot-with-annotation",
    "title": "Coding Assignment 2",
    "section": "Step 4: Make a scatter plot with annotation",
    "text": "Step 4: Make a scatter plot with annotation\na) Using dem__data, filter out a ten year period. This could be the most recent ten years of data or a distinct ten year period that you want to look at. If you choose a recent period, make sure that you have enough data to take an average of ten years. Some of the background variables in V-Dem are not entirely up to date. You can check the availability of the data by looking at the V-Dem codebook or using glimpse() or View() to look at your data.Group by country and summarize by mean. Save your your data in a new object called dem_data_scatter.\nb) Now build a scatter plot with ggplot2. Put your modernization-related variable (background variable) on the x-axis and your measure of democracy on the y-axis and color the points by region. Add a trend line with geom_smooth(). This could be a linear model or a loess curve. Add appropriate labels and a viridis or ColorBrewer color map and change the theme to theme_minimal.\nc) Add an annotation to your scatter plot using annotate() and geom_vline() or geom_hline(). Your annotation could highlight a particular year or level of democracy that is relevant for your analysis. Explain briefly why you included this annotation"
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-5-make-your-scatter-plot-interactive",
    "href": "assignments/coding-assignment-2.html#step-5-make-your-scatter-plot-interactive",
    "title": "Coding Assignment 2",
    "section": "Step 5: Make your scatter plot interactive",
    "text": "Step 5: Make your scatter plot interactive\na) Make your scatter plot interactive using ggplotly(). Make sure that your tooltip includes the information that you want to display to the user.\nb) Interpret your results. Does your plot show a relationship between the two variables? Which countries are outliers in your analysis? Why do you think they are outliers and how does your explanation relate to Lipset’s hypothesis?"
  },
  {
    "objectID": "assignments/coding-assignment-1.html",
    "href": "assignments/coding-assignment-1.html",
    "title": "Coding Assignment 1",
    "section": "",
    "text": "For this assignment, you are going to download some variables using the wbstats and vdemdata packages. Then you are going to wrangle these data and merge the two data sets into one and analyze how they relate to women’s representation in national parliaments. Do your work for each step in the code chunks provided. Be sure to label your code chunks.\nSubmission note: Accept the invitation on Blackboard to submit this assignment via GitHub."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-1-download-data-from-the-v-dem-dataset",
    "href": "assignments/coding-assignment-1.html#step-1-download-data-from-the-v-dem-dataset",
    "title": "Coding Assignment 1",
    "section": "Step 1: Download data from the V-Dem Dataset",
    "text": "Step 1: Download data from the V-Dem Dataset\nLook at the V-Dem codebook. Identify two measures of democracy that are not the polyarchy score that we used in Module 1.2.\nTry to pick variables that will relate to women’s representation and read the description of the variable to make sure that it includes data for a sufficient number of years, e.g. that the data will be somewhat recent. Select the most recent 20 years of data for your analysis.\nMake sure to load the packages that you need and glimpse() the data or View() it to make sure that it downloaded properly."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-2-download-data-from-the-world-bank",
    "href": "assignments/coding-assignment-1.html#step-2-download-data-from-the-world-bank",
    "title": "Coding Assignment 1",
    "section": "Step 2: Download data from the World Bank",
    "text": "Step 2: Download data from the World Bank\nNext, download the variable on women’s represenation that we used in Module 1.2 (“SG.GEN.PARL.ZS”) and at least one additional measure related to women’s empowerment. Go to the WDI site the wb_search() function to identify relevant variables. Download the most recent 20 years of data for your analysis.\nMake sure that the indicator has enough data to conduct your analysis, i.e. that it has data for most countries and years."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-3-merge-the-data",
    "href": "assignments/coding-assignment-1.html#step-3-merge-the-data",
    "title": "Coding Assignment 1",
    "section": "Step 3: Merge the data",
    "text": "Step 3: Merge the data\nNow add country codes using the countrycode package and merge the data using left_join()."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-4-summarize-your-combined-data-set",
    "href": "assignments/coding-assignment-1.html#step-4-summarize-your-combined-data-set",
    "title": "Coding Assignment 1",
    "section": "Step 4: Summarize your combined data set",
    "text": "Step 4: Summarize your combined data set\nUse group_by(), summarize() and arrange() to glean insights about your data. For example, how do regions compare on mean values of women’s representation and how do these values relate to the values of other variables in your data set? Which countries stand out in terms of women’s representation? Etc."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-5-interpret-your-data",
    "href": "assignments/coding-assignment-1.html#step-5-interpret-your-data",
    "title": "Coding Assignment 1",
    "section": "Step 5: Interpret your data",
    "text": "Step 5: Interpret your data\nWrite a paragraph or so relating your insights to the Norris reading about electoral reform and women’s representation. Picking a handful of country cases from your data, how does your analysis relate to her arguments about the relevance of electoral systems, statutory quotas, reserved seats or voluntary quotas?"
  },
  {
    "objectID": "assignments/coding-assignment-5.html",
    "href": "assignments/coding-assignment-5.html",
    "title": "Assignment 5",
    "section": "",
    "text": "For this assignment, you are going to be reproducing a version of this Shiny app and using it to evaluate Samuel Huntington’s classic book, The Third Wave which, according to Google, has been cited more than 19,700 times! For convenience, we will be looking a Journal of Democracy article by Huntington that summarizes his main points from the book. You will be doing most of your coding in the separate app.R template provided for you. A big part of your grade for this assignment will be based on getting that file to produce your Shiny App. However, you can use this document as a worksheet to help generate the various elements of code for your App.\nSubmission note: For this assignment you should submit your working Shiny App code via GitHub. You can use this workbook to develop your code."
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-1-wrangle-your-data",
    "href": "assignments/coding-assignment-5.html#step-1-wrangle-your-data",
    "title": "Assignment 5",
    "section": "Step 1: Wrangle your data",
    "text": "Step 1: Wrangle your data\nLoad vdemdata, dplyr and readr into a separate R script or code chunk in a Quarto document. Select country_name, year, and three V-Dem democracy indicators: v2x_polyarchy, v2x_libdem, and v2x_paritpdem. Now go to the V-Dem codebook and select four additional indicators related to democracy that you would like to explore. Make sure that your chosen indicators cover the same time period as those in the app (1789-2021). Have a glimpse() and the data to make sure everythign is there. Then store your data in an object called vdem_trends and then save it as a .csv file by the same name."
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-2-do-the-setup-work",
    "href": "assignments/coding-assignment-5.html#step-2-do-the-setup-work",
    "title": "Assignment 5",
    "section": "Step 2: Do the setup work",
    "text": "Step 2: Do the setup work\nNow, in your app.R file, load your packages, load the data into an object called vdem_trends, and create lists of the variables and countries for the ui.\nPackages: You will need to load shiny, shinyWidgets, readr, dplyr, ggplot2 and lubridate.\nData: These will be loaded in from the .csv file you created in Step 1.\nVariable list: Create a list of values using the combine function (c()) to be used in the “Indicator” dropdown menu. Some starter code is provided for you here:\n\nvars &lt;- c(\"Polyarchy\" = \"v2x_polyarchy\"), # be sure to insert the variable names you have \n          \"Liberal Democracy\" = ......   # in your wrangled data on the right hand side\n          )                              # of these equations \n\nCountry names list: To get a list of country names, filter() vdem_trends for one year (tip: you can use max(year) for this), pull() the country column and pipe that into sort() (with no arguments) so that the country names are arranged in alphabetical order. Store the list of country names in an object called countries.\n\ncountries &lt;- vdem_trends |&gt;\n  filter(....) |&gt; # filter what?\n  pull(....) |&gt;   # pull what?\n  sort()          # no arguments for sort"
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-3-define-the-ui",
    "href": "assignments/coding-assignment-5.html#step-3-define-the-ui",
    "title": "Assignment 5",
    "section": "Step 3: Define the UI",
    "text": "Step 3: Define the UI\nDefine the UI using code similar to what we saw for the FRED line chart app in Module 5.2. You will want a quarter of the columns to be occupied by the wellPanel() with the “Indicator:” and “Country:” dropdown menus and some help text. The remaining 3/4 of the space is going to be occupied by your plot output. For the slider input, use this code:\n\n           sliderTextInput(\n             \"range\",\n             NULL,\n             grid = TRUE,\n             choices = 1789:2021,\n             selected = c(1789, 2021),\n             width = \"100%\"\n           )"
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-4-define-the-server-logic",
    "href": "assignments/coding-assignment-5.html#step-4-define-the-server-logic",
    "title": "Assignment 5",
    "section": "Step 4: Define the server logic",
    "text": "Step 4: Define the server logic\nNow the tricky part. This app is going to require two reactive functions. The first is going to be for the country and indicator dropdowns:\n\n  ctry_indicator &lt;- reactive({\n    vdem_trends |&gt;\n    filter(country == INPUT) |&gt; # replace INPUT with relevant input\n    select(year, INPUT)         # ditto\n    })\n\nThe second is going to be for the year slider:\n\n  plot_df &lt;- reactive({\n    ctry_indicator() |&gt;\n    filter(year %in% (INPUT:INPUT)) # replace INPUT with relevant input\n   })\n\nNow you need to render the plot. In the ggplot() call your data is going to be the saved in the second reactive function plot_df() (don’t forget the parentheses!). In aes() x will simply be year but y is a little tricky. Here you need to call get(input$indicator)) You might have guessed the input$indicator part, but to non-standard evaluation in aes(), you cannot pass your column into ggplot before you remove the parentheses. get() is one of many ways to do this.\nFor the y-labels, you can use names(vars[which(vars == input$indicator)])) to get the name of the selected indicator."
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-5-run-the-app-and-interpret-the-results",
    "href": "assignments/coding-assignment-5.html#step-5-run-the-app-and-interpret-the-results",
    "title": "Assignment 5",
    "section": "Step 5: Run the app and interpret the results",
    "text": "Step 5: Run the app and interpret the results\nUse the shinyApp() funciton to run the app. Does it work? If not, try some of the debugging techniques we talked about in class or reach out on Discord for help.\nOnce you get the app running, take some time to explore the data in a few of your favorite countries. How do the trends in your chosen cases speak to Huntington’s idea about a third wave of democratization or, anecdotally, the types barriers that remain to democratization in that country? Type your answer below (not in your app.R file!)."
  },
  {
    "objectID": "assignments/coding-assignment-3.html",
    "href": "assignments/coding-assignment-3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "For this assignment, we are going to be evaluating Michael Ross’s influential book The Oil Curse. According to Michael Ross, oil undermines democracy in a number of ways. We will map some data in order to evaluate different aspects of his argument.\nSubmission note: Accept the invitation on Blackboard to submit this assignment via GitHub."
  },
  {
    "objectID": "assignments/coding-assignment-3.html#step-1-create-a-data-frame-with-country-shapes-25-pts",
    "href": "assignments/coding-assignment-3.html#step-1-create-a-data-frame-with-country-shapes-25-pts",
    "title": "Assignment 3",
    "section": "Step 1: Create a data frame with country shapes (25 pts)",
    "text": "Step 1: Create a data frame with country shapes (25 pts)\nUse rnaturalearth to extract and store country shapes as simple features in a data frame. Filter out Antarctica and glimpse() the data to make sure everything looks right."
  },
  {
    "objectID": "assignments/coding-assignment-3.html#step-2-visualize-democracy-25-pts",
    "href": "assignments/coding-assignment-3.html#step-2-visualize-democracy-25-pts",
    "title": "Assignment 3",
    "section": "Step 2: Visualize democracy (25 pts)",
    "text": "Step 2: Visualize democracy (25 pts)\na. Download one of the democracy (e.g. electoral democracy, liberal democracy, participatory democracy, deliberative democracy or egalitarian democracy) from V-Dem using the vdemdata package. Then use the vdemdata package to download this indicator and add iso3c codes to it with the countrycode package. See module 1.2 to refresh your memory on how to do this. (Note: you don’t have to add region names for this exercise.) glimpse() the data to make sure everything is there.\nb. Using iso_a3_eh codes from rnaturalearth and the iso3c codes you just added to the V-Dem data, join the V-Dem data to the country shapes. glimpse() the data to make sure everything look right.\nc. Use ggplot() and geom_sf() to map the data. Use theme_map() from ggthemes and give it a viridis color scheme. Give the map appropriate labels.\nd. Briefly, do you see preliminary evidence of a relationship between democracy, as displayed in this map, and the map of oil rents that we built together in module 3.1?"
  },
  {
    "objectID": "assignments/coding-assignment-3.html#step-3-use-a-map-app-to-explore-the-relevance-of-other-indicators-25-pts",
    "href": "assignments/coding-assignment-3.html#step-3-use-a-map-app-to-explore-the-relevance-of-other-indicators-25-pts",
    "title": "Assignment 3",
    "section": "Step 3: Use a map app to explore the relevance of other indicators (25 pts)",
    "text": "Step 3: Use a map app to explore the relevance of other indicators (25 pts)\nThe central argument in Michael Ross’s book is that oil rents undermine democracy because oil provides a non-tax source of revenue to governments. If people don’t have to worry about taxes, then they don’t have to be concerned about what their leaders are doing. He calls this the “fiscal theory of democracy.” Let’s use the map app we built in module 3.1 for exploring World Bank data to evaluate this claim.\na. In your assignment folder, create a subfolder called ‘function’ and use it to store your map function helper script like we did in module 3.1.\nb. Now add the source() code chunk that will enable you to call the map function in your Quarto document.\nc. Use your function to map income taxes as a percent of government revenue (GC.TAX.GSRV.RV.ZS). Do you see evidence of a relationship between this variable and oil rents?\nd. Use the wb_search() function to identify at least one other variable related to taxation that would be relevant for evaluating Ross’s theory. Use your function to map that variable. Then describe the relationship with oil wealth (if any) and how the map is relevant to Ross’s theory."
  },
  {
    "objectID": "assignments/coding-assignment-3.html#step-4-make-a-leaflet-map-of-conflict-to-explore-the-relvance-of-oil-25-pts",
    "href": "assignments/coding-assignment-3.html#step-4-make-a-leaflet-map-of-conflict-to-explore-the-relvance-of-oil-25-pts",
    "title": "Assignment 3",
    "section": "Step 4: Make a leaflet map of conflict to explore the relvance of oil (25 pts)",
    "text": "Step 4: Make a leaflet map of conflict to explore the relvance of oil (25 pts)\nIn Chapter 5 of the Oil Curse, Michael Ross argues that oil wealth is destabilizing for developing countries due to the fact that rebels and the government fight over oil. Your task for this question is to explore the relationship between conflict and oil in a leaflet map.\nWe will harness OpenAI’s ChatGPT in our research for this question. Note that because AI has a tendency to “halucinate”, you should always use other sources like Google to verify the information that ChatGPT provides.\na. Select a country case to work with. This should be a oil-rich country that has recently experienced high levels of internal conflict. Examples include Iraq, Syria, Yemen and Nigeria. Use your AI to identify a country and a period of time to analyze. Say a few words about your country case and the time period you will be looking at.\nb. Now, following the step laid out in module 3.2, filter a few months of conflict data from the UCDP GED dataset for your selected country and convert the coordinates simple features using the st_as_sf() function from the sf package.\nc. Next, produce a leaflet map that displays markers representing conflict events. Have the markers display the name of the location where the conflict event occurred when the user hovers over them. Have the popup windows display the number of deaths and the date of the event when the user clicks on them. Use “OpenTopoMap” as your basemap.\nd. Now let’s do some research into the location of oil fields. Ask your AI to give you a list of the ten biggest oil fields and in your country and their geographic coordinates. Now ask your AI how you can export those coordinates to a .csv file. Make sure that your columns are appropriately labeled (e.g. snake case) and save your file as oil_fields.csv in your assignment folder. Then read the data into R using readr and store them in an object called oil_fields.\ne. Now map the oil fields using leaflet(), giving each marker a label that displays the name of the oil field. Do you notice that conflict events occur close to oil fields in your chosen country?"
  },
  {
    "objectID": "assignments/coding-assignment-4.html",
    "href": "assignments/coding-assignment-4.html",
    "title": "Assignment 4",
    "section": "",
    "text": "There are two parts to this assignment. In Part I, you will use tidycensus and the gt package to produce nice tables of census data. In Part II you will use peacesciencer, broom and modelsummary to do an analysis of conflict onset.`\nSubmission note: Accept the invitation on Blackboard to submit this assignment via GitHub."
  },
  {
    "objectID": "assignments/coding-assignment-4.html#part-i-income-tables",
    "href": "assignments/coding-assignment-4.html#part-i-income-tables",
    "title": "Assignment 4",
    "section": "Part I: Income Tables",
    "text": "Part I: Income Tables\n\nStep 1: Download data on income quintiles (20 pts)\nChoose your favorite state or one that you think would be interesting to analyze from the standpoint of income distrubitions. Using tidycensus, download data on income quintiles at the county level. Be sure to specify “county for geography = and the state that you want to download the data from in state =. Also make sure to clean the variable names and use a mutate(name = str_replace_all()) so that you just have the county names and not”X County, State” in your tables.\n\n\nStep 2: Make a gt table (20 pts)\nUse the gt package to generate a table of the income quintiles for the counties in your selected state. Make sure to add a title and subtitle, relabel the columns, format the numbers as dollar figures and add a source note. Take other steps to beautify your table as you see fit. Finally, interpret the table. Which counties stand out?"
  },
  {
    "objectID": "assignments/coding-assignment-4.html#part-ii-regression-tables",
    "href": "assignments/coding-assignment-4.html#part-ii-regression-tables",
    "title": "Assignment 4",
    "section": "Part II: Regression Tables",
    "text": "Part II: Regression Tables\nFor Part II of this assignment, we are going to be evaluating another classic article in political science: Fearon and Laitin’s Ethnicity, Insurgency and Civil War. According to Google, this article has been cited about 11k times!\nFearon and Laitin’s provocative thesis is that ethnic diversity (per se) is not an important predictor of civil conflict. In this assignment, we are going to try to approximate F&L’s analysis using the peacesciencer package and produce some regression tables to interpret our results.\n\nStep 1: Build your dataset (20 pts)\nUsing create_stateyears() and the various “add” functions (e.g. add_ucdp_acd(), add_democracy(), etc.), assemble a data frame for analyzing conflict onset as we did in module 4.2. One benefit we have of doing this analysis today is an additional 20 years of data, so filter your data for 1946 to 2019.\n\n\nStep 2: Run a regression (20 pts)\nLoad broom and regress ucdponset on ethfrac, relfrac, v2x_polyarchy, rugged, wbgdppc2011est and wbpopest. Use tidy() to review the results and use mutate_if() to round the variables four or five decimal places. Compare your results to Table 1 in Fearon and Laitin’s article. Are there any differences in your results?\n\n\nStep 3: Make a table with multiple models (20 pts)\nNow use modelsummary to produce a handsome table with multiple models, but change out some of the measures. Try looking at ethnic and relgious polarization (ethfrac, relfrac) instead of fractionalization. For democracy, use the polity2 score. And for terrain, try newlmtnest (a measure of mountainous terrain) instead of rugged. How do yur results change and how are they different from Fearon and Laitin’s results?"
  },
  {
    "objectID": "assignments/coding-assignment-4.html#bonus-section-use-confidence-intervals-instead-of-tables-10-pts",
    "href": "assignments/coding-assignment-4.html#bonus-section-use-confidence-intervals-instead-of-tables-10-pts",
    "title": "Assignment 4",
    "section": "Bonus section: Use confidence intervals instead of tables (10 pts)",
    "text": "Bonus section: Use confidence intervals instead of tables (10 pts)\n1. Display median income with a plot of point estimates and confidence intervals for the counties in your selected state. What additional light does such a plot shed on your analysis of the income distrubtion in that state? (5 pts)\n2. Use modelplot to display the results of one of your regression models with point estimates and confidence intervals. What are some of the tradeoffs associated with displaying your results in this fashion as opposed to doing it in tabular form?"
  },
  {
    "objectID": "weeks/week-1.html#modules-and-videos",
    "href": "weeks/week-1.html#modules-and-videos",
    "title": "Week 1",
    "section": "Modules and Videos",
    "text": "Modules and Videos\nModule 1.1\nModule 1.2"
  },
  {
    "objectID": "weeks/week-1.html#modules",
    "href": "weeks/week-1.html#modules",
    "title": "Week 1",
    "section": "Modules",
    "text": "Modules\nModule 1.1–Working with Flat Files\nModule 1.2–Working with APIs"
  },
  {
    "objectID": "course-syllabus.html#course-information",
    "href": "course-syllabus.html#course-information",
    "title": "Course Syllabus",
    "section": "",
    "text": "Instructor: Prof. Emmanuel Teitelbaum\nEmail: ejt@gwu.edu\nThe best way to contact me is via email.\nVirtual Office/Student Hours: By appointment only. Please email me directly.\nCredit Hours: 3.0."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#overview",
    "href": "assignments/coding-assignment-1.html#overview",
    "title": "Coding Assignment 1",
    "section": "",
    "text": "For this assignment, you are going to download some variables using the wbstats and vdemdata packages. Then you are going to wrangle these data and merge the two data sets into one and analyze how they relate to women’s representation in national parliaments. Do your work for each step in the code chunks provided. Be sure to label your code chunks.\nSubmission note: Accept the invitation on Blackboard to submit this assignment via GitHub."
  },
  {
    "objectID": "assignments/coding-assignment-2.html#overview",
    "href": "assignments/coding-assignment-2.html#overview",
    "title": "Coding Assignment 2",
    "section": "",
    "text": "For this assignment, you are going to evaluate modernization theory as laid out in Seymour Martin Lipset’s classic article entitled “Some Social Requisites of Democracy: Economic Development and Political Legitimacy.” How classic is this article? According to Google Scholar, this piece has been cited more than 11.5 thousand times!\nWe are going to use data from V-Dem and modern data viz tools to explore Lipset’s hypothesis that economic modernization is highly correlated with democracy. We have already done this to some extent by looking at the relationship between wealth and the polyarchy score. But we are going to broaden things out by looking at other measures of modernization and democracy contained in the V-Dem dataset.\nBefore starting on this assignment, you will want to have a look at the V-Dem codebook. Look through the sections titled “V-Dem Indicators” and “Background Factors (E).” There are five democracy indicators, one of which is the polyarchy index. There are a number of background factors, many of which pertain to economic modernization. We are going to be looking at the relationship between these two sets of variables.\nNow have a look at “Some Social Requisites of Democracy” and in particular pay attention to the indicators in Table II and the discussion surrounding them. Think of each indicator (e.g. urbanization, education, etc.) as a sub-hypothesis of his theory. Which of these sub-hypotheses about modernization do you think is most compelling? Which would you like to test?\nSubmission note: Accept the invitation on Blackboard to submit this assignment via GitHub."
  },
  {
    "objectID": "assignments/coding-assignment-3.html#overview",
    "href": "assignments/coding-assignment-3.html#overview",
    "title": "Assignment 3",
    "section": "",
    "text": "For this assignment, we are going to be evaluating Michael Ross’s influential book The Oil Curse. According to Michael Ross, oil undermines democracy in a number of ways. We will map some data in order to evaluate different aspects of his argument.\nSubmission note: Accept the invitation on Blackboard to submit this assignment via GitHub."
  },
  {
    "objectID": "assignments/coding-assignment-4.html#overview",
    "href": "assignments/coding-assignment-4.html#overview",
    "title": "Assignment 4",
    "section": "",
    "text": "There are two parts to this assignment. In Part I, you will use tidycensus and the gt package to produce nice tables of census data. In Part II you will use peacesciencer, broom and modelsummary to do an analysis of conflict onset.`\nSubmission note: Accept the invitation on Blackboard to submit this assignment via GitHub."
  },
  {
    "objectID": "assignments/coding-assignment-5.html#overview",
    "href": "assignments/coding-assignment-5.html#overview",
    "title": "Assignment 5",
    "section": "",
    "text": "For this assignment, you are going to be reproducing a version of this Shiny app and using it to evaluate Samuel Huntington’s classic book, The Third Wave which, according to Google, has been cited more than 19,700 times! For convenience, we will be looking a Journal of Democracy article by Huntington that summarizes his main points from the book. You will be doing most of your coding in the separate app.R template provided for you. A big part of your grade for this assignment will be based on getting that file to produce your Shiny App. However, you can use this document as a worksheet to help generate the various elements of code for your App.\nSubmission note: For this assignment you should submit your working Shiny App code via GitHub. You can use this workbook to develop your code."
  },
  {
    "objectID": "project/project-assignment-1.html#overview",
    "href": "project/project-assignment-1.html#overview",
    "title": "Project Assignment 1",
    "section": "",
    "text": "For your final project in this course, you will be producing your very own Shiny App. The purpose of this assignment is to get you to think through the basic content and layout off your app. As you will learn, Shiny Apps are comprised of two basic elements: a user interface and a server function. We are going to be focusing on the user interface side of things for now and later we will talk about how to generate the content for the user. What do you want your user to see and experience with your app? That is the question you will answer here."
  },
  {
    "objectID": "project/project-assignment-2.html#overview",
    "href": "project/project-assignment-2.html#overview",
    "title": "Project Assignment 2",
    "section": "",
    "text": "For the first project assignment, you thought about some rough content for your app and how the user would produce some sort of visualization with it. For this assignment, we will take the next step and think about how we will generate that output on the server side. For this, we need to think concretely about what kind of setup or prework we need to do in the app.R file. Then we need to think about reactivity and how user input will change the output rendered by the app. We also want to think about any helper functions and externally sourced code that we want to include (although this is not imperative in every case)."
  },
  {
    "objectID": "project/project-assignment-3.html#overview",
    "href": "project/project-assignment-3.html#overview",
    "title": "Project Assignment 3",
    "section": "",
    "text": "Now that you have a clear sense of where you are going with your app, it is time to build it. This is the hard part and you will likely have to invest significant time in wrangling your data and debugging the app. Be patient! It will turn out great and you will have a nice project to show for it."
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-1-gather-your-data-20-pts",
    "href": "assignments/coding-assignment-2.html#step-1-gather-your-data-20-pts",
    "title": "Coding Assignment 2",
    "section": "Step 1: Gather Your Data (20 pts)",
    "text": "Step 1: Gather Your Data (20 pts)\nUse the vdemdata package to download data for your analysis. Since we already looked at the polyarchy score and wealth in class, you need to use a different measure of democracy and a different background factor for your analysis. Use a select() verb to include country, year, region (e_regionpol_6C), at least one of the other four measures of democracy, and one background factor that is not per capita GDP. Store your data in an object called dem_data. Pipe in a mutate() verb and use case_match() to label the regions. Review module 1.2 if you are confused on how to do this."
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-2-make-a-bar-chart-20-pts",
    "href": "assignments/coding-assignment-2.html#step-2-make-a-bar-chart-20-pts",
    "title": "Coding Assignment 2",
    "section": "Step 2: Make a bar chart (20 pts)",
    "text": "Step 2: Make a bar chart (20 pts)\na) Insert a code chunk below this line and label it. Wrangle your data for the bar chart. Filter by year to include data since 2000, group by region and summarize by mean. Save the new data in an object called bar_chart_data.\nb) Insert a code chunk below this line and label it. Use ggplot() and geom_col() to create a bar chart showing levels of democracy across the regions with your wrangled data. Make sure to add appropriate axis labels, a title and a caption. Add a theme to spruce it up a bit.\nNote: From here on out I will expect you to know to add a code chunk and label it."
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-3-make-a-colorblind-friendly-line-chart-20-pts",
    "href": "assignments/coding-assignment-2.html#step-3-make-a-colorblind-friendly-line-chart-20-pts",
    "title": "Coding Assignment 2",
    "section": "Step 3: Make a colorblind-friendly line chart (20 pts)",
    "text": "Step 3: Make a colorblind-friendly line chart (20 pts)\na) Filter your dem_data to include three or four countries of your choosing and create a line chart of your democracy indicator. You can save the data as a new data frame called dem_data_line or you can pipe your filtered data directly into ggplot().\nb) Use cvdPlot() to view your chart from the standpoint of someone with red-green color blindness and describe what you see.\nc) Add a colorblind-friendly color map using viridis or ColorBrewer.\nd) Run the plot through cvdPlot() and describe what you see. Is your plot colorblind friendly?"
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-4-make-a-scatter-plot-with-annotation-20-pts",
    "href": "assignments/coding-assignment-2.html#step-4-make-a-scatter-plot-with-annotation-20-pts",
    "title": "Coding Assignment 2",
    "section": "Step 4: Make a scatter plot with annotation (20 pts)",
    "text": "Step 4: Make a scatter plot with annotation (20 pts)\na) Using dem__data, filter out a ten year period. This could be the most recent ten years of data or a distinct ten year period that you want to look at. If you choose a recent period, make sure that you have enough data to take an average of ten years. Some of the background variables in V-Dem are not entirely up to date. You can check the availability of the data by looking at the V-Dem codebook or using glimpse() or View() to look at your data.Group by country and summarize by mean. Save your your data in a new object called dem_data_scatter.\nb) Now build a scatter plot with ggplot2. Put your modernization-related variable (background variable) on the x-axis and your measure of democracy on the y-axis and color the points by region. Add a trend line with geom_smooth(). This could be a linear model or a loess curve. Add appropriate labels and a viridis or ColorBrewer color map and change the theme to theme_minimal.\nc) Add an annotation to your scatter plot using annotate() and geom_vline() or geom_hline(). Your annotation could highlight a particular year or level of democracy that is relevant for your analysis. Explain briefly why you included this annotation"
  },
  {
    "objectID": "assignments/coding-assignment-2.html#step-5-make-your-scatter-plot-interactive-20-pts",
    "href": "assignments/coding-assignment-2.html#step-5-make-your-scatter-plot-interactive-20-pts",
    "title": "Coding Assignment 2",
    "section": "Step 5: Make your scatter plot interactive (20 pts)",
    "text": "Step 5: Make your scatter plot interactive (20 pts)\na) Make your scatter plot interactive using ggplotly(). Make sure that your tooltip includes the information that you want to display to the user.\nb) Interpret your results. Does your plot show a relationship between the two variables? Which countries are outliers in your analysis? Why do you think they are outliers and how does your explanation relate to Lipset’s hypothesis?"
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-1-download-data-from-the-v-dem-dataset-20pts",
    "href": "assignments/coding-assignment-1.html#step-1-download-data-from-the-v-dem-dataset-20pts",
    "title": "Coding Assignment 1",
    "section": "Step 1: Download data from the V-Dem Dataset (20pts)",
    "text": "Step 1: Download data from the V-Dem Dataset (20pts)\nLook at the V-Dem codebook. Identify two measures of democracy that are not the polyarchy score that we used in Module 1.2.\nTry to pick variables that will relate to women’s representation and read the description of the variable to make sure that it includes data for a sufficient number of years, e.g. that the data will be somewhat recent. Select the most recent 20 years of data for your analysis.\nMake sure to load the packages that you need and glimpse() the data or View() it to make sure that it downloaded properly."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-2-download-data-from-the-world-bank-20-pts",
    "href": "assignments/coding-assignment-1.html#step-2-download-data-from-the-world-bank-20-pts",
    "title": "Coding Assignment 1",
    "section": "Step 2: Download data from the World Bank (20 pts)",
    "text": "Step 2: Download data from the World Bank (20 pts)\nNext, download the variable on women’s represenation that we used in Module 1.2 (“SG.GEN.PARL.ZS”) and at least one additional measure related to women’s empowerment. Go to the WDI site the wb_search() function to identify relevant variables. Download the most recent 20 years of data for your analysis.\nMake sure that the indicator has enough data to conduct your analysis, i.e. that it has data for most countries and years."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-3-merge-the-data-20-pts",
    "href": "assignments/coding-assignment-1.html#step-3-merge-the-data-20-pts",
    "title": "Coding Assignment 1",
    "section": "Step 3: Merge the data (20 pts)",
    "text": "Step 3: Merge the data (20 pts)\nNow add country codes using the countrycode package and merge the data using left_join()."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-4-summarize-your-combined-data-set-20-pts",
    "href": "assignments/coding-assignment-1.html#step-4-summarize-your-combined-data-set-20-pts",
    "title": "Coding Assignment 1",
    "section": "Step 4: Summarize your combined data set (20 pts)",
    "text": "Step 4: Summarize your combined data set (20 pts)\nUse group_by(), summarize() and arrange() to glean insights about your data. For example, how do regions compare on mean values of women’s representation and how do these values relate to the values of other variables in your data set? Which countries stand out in terms of women’s representation? Etc."
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-5-interpret-your-data-20-pts",
    "href": "assignments/coding-assignment-1.html#step-5-interpret-your-data-20-pts",
    "title": "Coding Assignment 1",
    "section": "Step 5: Interpret your data (20 pts)",
    "text": "Step 5: Interpret your data (20 pts)\nWrite a paragraph or so relating your insights to the Norris reading about electoral reform and women’s representation. Picking a handful of country cases from your data, how does your analysis relate to her arguments about the relevance of electoral systems, statutory quotas, reserved seats or voluntary quotas?"
  },
  {
    "objectID": "assignments/coding-assignment-1.html#step-1-download-data-from-v-dem-20pts",
    "href": "assignments/coding-assignment-1.html#step-1-download-data-from-v-dem-20pts",
    "title": "Coding Assignment 1",
    "section": "Step 1: Download data from V-Dem (20pts)",
    "text": "Step 1: Download data from V-Dem (20pts)\nLook at the V-Dem codebook. Identify two measures of democracy that are not the polyarchy score that we used in Module 1.2.\nTry to pick variables that will relate to women’s representation and read the description of the variable to make sure that it includes data for a sufficient number of years, e.g. that the data will be somewhat recent. Select the most recent 20 years of data for your analysis.\nMake sure to load the packages that you need and glimpse() the data or View() it to make sure that it downloaded properly."
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-1-wrangle-your-data-20-pts",
    "href": "assignments/coding-assignment-5.html#step-1-wrangle-your-data-20-pts",
    "title": "Assignment 5",
    "section": "Step 1: Wrangle your data (20 pts)",
    "text": "Step 1: Wrangle your data (20 pts)\nLoad vdemdata, dplyr and readr into a separate R script or code chunk in a Quarto document. Select country_name, year, and three V-Dem democracy indicators: v2x_polyarchy, v2x_libdem, and v2x_paritpdem. Now go to the V-Dem codebook and select four additional indicators related to democracy that you would like to explore. Make sure that your chosen indicators cover the same time period as those in the app (1789-2021). Have a glimpse() and the data to make sure everythign is there. Then store your data in an object called vdem_trends and then save it as a .csv file by the same name."
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-2-do-the-setup-work-20-pts",
    "href": "assignments/coding-assignment-5.html#step-2-do-the-setup-work-20-pts",
    "title": "Assignment 5",
    "section": "Step 2: Do the setup work (20 pts)",
    "text": "Step 2: Do the setup work (20 pts)\nNow, in your app.R file, load your packages, load the data into an object called vdem_trends, and create lists of the variables and countries for the ui.\nPackages: You will need to load shiny, shinyWidgets, readr, dplyr, ggplot2 and lubridate.\nData: These will be loaded in from the .csv file you created in Step 1.\nVariable list: Create a list of values using the combine function (c()) to be used in the “Indicator” dropdown menu. Some starter code is provided for you here:\n\nvars &lt;- c(\"Polyarchy\" = \"v2x_polyarchy\"), # be sure to insert the variable names you have \n          \"Liberal Democracy\" = ......   # in your wrangled data on the right hand side\n          )                              # of these equations \n\nCountry names list: To get a list of country names, filter() vdem_trends for one year (tip: you can use max(year) for this), pull() the country column and pipe that into sort() (with no arguments) so that the country names are arranged in alphabetical order. Store the list of country names in an object called countries.\n\ncountries &lt;- vdem_trends |&gt;\n  filter(....) |&gt; # filter what?\n  pull(....) |&gt;   # pull what?\n  sort()          # no arguments for sort"
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-3-define-the-ui-20-pts",
    "href": "assignments/coding-assignment-5.html#step-3-define-the-ui-20-pts",
    "title": "Assignment 5",
    "section": "Step 3: Define the UI (20 pts)",
    "text": "Step 3: Define the UI (20 pts)\nDefine the UI using code similar to what we saw for the FRED line chart app in Module 5.2. You will want a quarter of the columns to be occupied by the wellPanel() with the “Indicator:” and “Country:” dropdown menus and some help text. The remaining 3/4 of the space is going to be occupied by your plot output. For the slider input, use this code:\n\n           sliderTextInput(\n             \"range\",\n             NULL,\n             grid = TRUE,\n             choices = 1789:2021,\n             selected = c(1789, 2021),\n             width = \"100%\"\n           )"
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-4-define-the-server-logic-20-pts",
    "href": "assignments/coding-assignment-5.html#step-4-define-the-server-logic-20-pts",
    "title": "Assignment 5",
    "section": "Step 4: Define the server logic (20 pts)",
    "text": "Step 4: Define the server logic (20 pts)\nNow the tricky part. This app is going to require two reactive functions. The first is going to be for the country and indicator dropdowns:\n\n  ctry_indicator &lt;- reactive({\n    vdem_trends |&gt;\n    filter(country == INPUT) |&gt; # replace INPUT with relevant input\n    select(year, INPUT)         # ditto\n    })\n\nThe second is going to be for the year slider:\n\n  plot_df &lt;- reactive({\n    ctry_indicator() |&gt;\n    filter(year %in% (INPUT:INPUT)) # replace INPUT with relevant input\n   })\n\nNow you need to render the plot. In the ggplot() call your data is going to be the saved in the second reactive function plot_df() (don’t forget the parentheses!). In aes() x will simply be year but y is a little tricky. Here you need to call get(input$indicator)) You might have guessed the input$indicator part, but to non-standard evaluation in aes(), you cannot pass your column into ggplot before you remove the parentheses. get() is one of many ways to do this.\nFor the y-labels, you can use names(vars[which(vars == input$indicator)])) to get the name of the selected indicator."
  },
  {
    "objectID": "assignments/coding-assignment-5.html#step-5-run-the-app-and-interpret-the-results-20-pts",
    "href": "assignments/coding-assignment-5.html#step-5-run-the-app-and-interpret-the-results-20-pts",
    "title": "Assignment 5",
    "section": "Step 5: Run the app and interpret the results (20 pts)",
    "text": "Step 5: Run the app and interpret the results (20 pts)\nUse the shinyApp() funciton to run the app. Does it work? If not, try some of the debugging techniques we talked about in class or reach out on Discord for help.\nOnce you get the app running, take some time to explore the data in a few of your favorite countries. How do the trends in your chosen cases speak to Huntington’s idea about a third wave of democratization or, anecdotally, the types barriers that remain to democratization in that country? Type your answer below (not in your app.R file!)."
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "📖 r4ds\n\nChapter 2 on data visualization\n12.2 on labels\n10.1 - 10.4 on layers, geoms and facets\n12.4 on scales\n12.3 & 12.5 on themes and annotations\n\n\n\n\n📖 Lipset, Some Social Requisites of Democracry"
  },
  {
    "objectID": "weeks/week-2.html#readings",
    "href": "weeks/week-2.html#readings",
    "title": "Week 2",
    "section": "",
    "text": "📖 r4ds\n\nChapter 2 on data visualization\n12.2 on labels\n10.1 - 10.4 on layers, geoms and facets\n12.4 on scales\n12.3 & 12.5 on themes and annotations\n\n\n\n\n📖 Lipset, Some Social Requisites of Democracry"
  },
  {
    "objectID": "weeks/week-2.html#modules",
    "href": "weeks/week-2.html#modules",
    "title": "Week 2",
    "section": "Modules",
    "text": "Modules\nModule 2.1–Working with Flat Files\nModule 2.2–Working with APIs"
  },
  {
    "objectID": "weeks/week-2.html#assignments",
    "href": "weeks/week-2.html#assignments",
    "title": "Week 2",
    "section": "Assignments",
    "text": "Assignments\n📘 Quiz 1\n📘 Quiz 2\n🧮 Coding Assignment 2"
  },
  {
    "objectID": "modules/module-5.1.html#displaying-your-app",
    "href": "modules/module-5.1.html#displaying-your-app",
    "title": "Module 5.1",
    "section": "Displaying your app",
    "text": "Displaying your app\nAt this point it should be relatively simple to view your app. Just add the call to the Shiny app, e.g. shinyApp(ui = ui, server = server) and click “Run App” in RStudio.\n\n# See above for the definitions of ui and server\nui &lt;- ...\n\nserver &lt;- ...\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\nOptionally, right now, you can try setting up an account on shinyapps.io. Read over the shinyapps.io user guide and see if you can get it to work. For your final project, you will need to be able to deploy your app but but right now it is fine if you only want to view it locally."
  },
  {
    "objectID": "modules/module-3.1.knit.html",
    "href": "modules/module-3.1.knit.html",
    "title": "Module 3.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall rnaturalearth (install.packages(\"rnaturalearth\")) and have a look at the documentation\nInstall the rnaturalearth data package (install.packages(\"rnaturalearthdata\"))\nInstall ggthemes (install.packages(\"ggthemes\"))and have a look at this post) for a brief explanation of how it works\nCreate a Quarto document called “module-3.1.qmd” in your modules folder for the code-along\nInstall magick and underlying file system to remove whitespace around maps\nThen insert this code chunk somewhere in your module 3.1 Quarto document:\n\n\n# create a hook to crop maps as recommended by pmassicotte\n# must have `magick` and its dependencies installed\n\nknitr::knit_hooks$set(crop = knitr::hook_pdfcrop)"
  },
  {
    "objectID": "modules/module-3.1.knit.html#overview",
    "href": "modules/module-3.1.knit.html#overview",
    "title": "Module 3.1",
    "section": "Overview",
    "text": "Overview\nThe focus of this module is going to be on how to make choropleth maps. A choropleth map is a type of data visualization used to show a geographical distribution of data where areas or regions are shaded based on quantities or levels represented in each area or region.\nOne important concept in mapping that we are going to come across this week: simple features. Simple features is a formal international standard for representing objects in the real world in digital space.\nA “feature” is basically any object in the real world that can be represented in two or three-dimensional space. A tree or a house can be a feature as can a forest or a body of water. But in politics we are usually focused on mapping the political boundaries of different administrative units like countries, states or provinces, counties and cities.\nSimple features allow us to work with such boundaries easily in a data frame in R. We can take all of the points associated with a geometry and store it in a special data frame column (usually labeled ‘geom’ or ‘geometry’). This ability to store all of the geographic information in one column differs from how spatial data are organized under the traditional spatial objects standard and makes it much easier to work with geographic data in R."
  },
  {
    "objectID": "modules/module-3.1.knit.html#using-rnaturalearth",
    "href": "modules/module-3.1.knit.html#using-rnaturalearth",
    "title": "Module 3.1",
    "section": "Using rnaturalearth",
    "text": "Using rnaturalearth\n\nIn this module we are going to be with the rnaturalearth package, which facilitates working with Natural Earth map data in R. Natural Earth is a public domain map dataset based on Tom Patterson’s Natural Earth projection that provides data suitable for making small-scale world, regional and country maps. Natural Earth contains country boundaries, first-order admin boundaries like provinces and states, urban polygons and more. rnaturalearth supports both simple features (sf) and spatial objects (sp) formats, but we are going to be focused on using simple features for the reasons stated earlier.\n\nGrabbing country shapes with ne_countries()\nLet’s start by loading country shapes using the ne_countries() function from rnaturalearth. We will start by loading rnaturalearth and dplyr. Next we will load the country boundaries into an object called world_map_df while filtering out Antarctica. Then, let’s glimpse() the data and have a closure look at the geometry column.\n\nlibrary(rnaturalearth)\nlibrary(dplyr)\n\nworld_map_df <- ne_countries(scale = \"medium\", returnclass = \"sf\") |>\n    filter(name != \"Antarctica\") # remove Antarctica\n\n#world_map_df |>\n#glimpse()\n\n# view contents of geometry column\nworld_map_df |>\n  select(geometry) \n\nSimple feature collection with 240 features and 0 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -58.49229 xmax: 180 ymax: 83.59961\nGeodetic CRS:  +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\nFirst 10 features:\n                         geometry\n1  MULTIPOLYGON (((-69.89912 1...\n2  MULTIPOLYGON (((74.89131 37...\n3  MULTIPOLYGON (((14.19082 -5...\n4  MULTIPOLYGON (((-63.00122 1...\n5  MULTIPOLYGON (((20.06396 42...\n6  MULTIPOLYGON (((20.61133 60...\n7  MULTIPOLYGON (((1.706055 42...\n8  MULTIPOLYGON (((53.92783 24...\n9  MULTIPOLYGON (((-64.54917 -...\n10 MULTIPOLYGON (((45.55234 40...\n\n\n\n\nMake a map with geom_sf()\nNow, let’s make our first choropleth map with the data. Let’s map World Bank income groups. Here we will use the special features geom_sf() from ggplot2 and for our aesthetics mapping we will specify fill = income_grp.\n\nlibrary(ggplot2)\n\nggplot(data = world_map_df) +\n  geom_sf(aes(fill = income_grp)) + \n  labs(title = \"World Bank country income categories\")\n\n\n\n\n\n\nBeautify your map\nThe default ggplot settings are pretty good for a preview, but we could make it look a lot better. Let’s add some labels, a ggtheme map theme and the default viridis color mapping.\n\nlibrary(ggthemes)\n\nggplot(data = world_map_df) +\n  geom_sf(aes(fill = income_grp)) + \n  labs(\n    title = \"World Bank country income categories\",\n    fill = \"Category\"\n    ) +\n    scale_fill_viridis_d() +\n    theme_map()"
  },
  {
    "objectID": "modules/module-3.1.knit.html#using-rnaturalearth-to-map-other-data",
    "href": "modules/module-3.1.knit.html#using-rnaturalearth-to-map-other-data",
    "title": "Module 3.1",
    "section": "Using rnaturalearth to map other data",
    "text": "Using rnaturalearth to map other data\n\nNow that we know how to make a map with Natural Earth shapes and geom_sf(), we can merge in data and map data from other sources. Let’s go ahead and merge some data on oil rents from the World Bank. We will do a left_join() based on iso3c country codes. In the World Bank data the iso3c codes are simply called “iso3c.” In rnaturalearth there are a number of options, but the best here for our purposes is “iso_a3”\n\n\n\n\n\n\nWarning\n\n\n\nAt the time I made the video, the codes for “iso_a3” and some of the others were missing so I recommended using “iso_a3_eh.” But now the issue has been fixed, so please use “iso_a3.”\n\n\n\nlibrary(wbstats)\n\noil_rents_df <- wb_data(c(oil_rents_gdp = \"NY.GDP.PETR.RT.ZS\"), mrnev = 1) \n\nrents_map_df <- left_join(world_map_df, oil_rents_df, join_by(iso_a3 == iso3c))\n\nrents_map_df |>\n  select(last_col(5):last_col()) |> #select last 5 columns of df\n  glimpse() \n\nRows: 240\nColumns: 6\n$ date          <dbl> 2021, 2021, 2021, NA, 2021, NA, NA, 2021, 2021, 2021, 20…\n$ oil_rents_gdp <dbl> 0.00000000, 0.01786951, 28.27443988, NA, 1.04218369, NA,…\n$ obs_status    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ footnote      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ last_updated  <date> 2023-05-10, 2023-05-10, 2023-05-10, NA, 2023-05-10, NA,…\n$ geometry      <MULTIPOLYGON [°]> MULTIPOLYGON (((-69.89912 1..., MULTIPOLYGO…\n\n\nNow we can map these data. Everything here is pretty much the same as before, except we change the fill to oil_rents_gdp. We will also add a subtitle and make a few other cosmetic changes like shifting the position of the legend title, bolding the plot title and changing the viridis color scale from discrete to continuous.\n\nggplot(data = rents_map_df) +\n  geom_sf(aes(fill = oil_rents_gdp)) + # shade based on oil rents\n  labs(\n    title = \"Oil rents (% of GDP)\",\n    subtitle = \"(Most recent available data)\", # add subtitle\n    fill = \"Percent\", \n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(\n    legend.position = \"right\", \n    #legend.title = element_text(size = 8),\n    #legend.text = element_text(size = 6)\n    plot.title = element_text(face = \"bold\"), # move legend\n    ) +\n  scale_fill_viridis_c( # chg from discrete (_d) to continuous (_c)\n      option = \"magma\", #  chg to magma theme\n      labels = scales::label_percent(scale = 1) # add % label for legend\n      )"
  },
  {
    "objectID": "modules/module-3.1.knit.html#turn-your-map-into-a-function",
    "href": "modules/module-3.1.knit.html#turn-your-map-into-a-function",
    "title": "Module 3.1",
    "section": "Turn your map into a function",
    "text": "Turn your map into a function\n\nSometimes you may want to map more than one variable in a paper or display variables with a map in an app. For these situations, it can help to create your own function that allows you to change various components of the map code without having to type out all of the code every time you want to create a map.\n\nCreate the map function\nThe first thing that you want to do is to write out the script for your function. That should include any packages that you need to run that may not already be loaded.\nFrom there, you can build your function. The code for your function contains three elements: 1) a name; 2) the arguments you will include in your function; and 3) a code block of code that will execute when you call the function.\nIn this example, we are going to call our function create_map(). It is going to include five arguments: var_id, title, legend_title, theme and direction. var_id refers to the World Bank variable id, title and legend_title refer to the title of the plot and the title of the legend respectively. theme will allow the user to adjust the viridis theme. And direction refers to whether the color scale is light to dark or dark to light.\nThe code block will first join the country shapes to the selected World Bank data and then map those data by piping them into a ggplot() call. Everything is pretty similar to our previous use of ggplot() and geom_sf(), but one tricky part here is that we have to use eval(parse(text=var_id)))) to remove the quotes surrounding the variable code entered by the user.\n\nlibrary(rnaturalearth)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(wbstats)\n\ncreate_map <- function(var_id, title, legend_title, theme, direction){\n\nne_countries(scale = \"medium\", returnclass = \"sf\") |> \n  left_join(\n    wb_data(var_id, mrnev = 1), # change variable id\n    join_by(iso_a3 == iso3c)\n  ) |> \n  filter(name != \"Antarctica\") |>  \n  ggplot() + \n  geom_sf(aes(fill = eval(parse(text=var_id)))) + # remove quotes\n  labs(\n    title =  title, # change title\n    fill = legend_title, # change legend title\n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n  ) +\n  scale_fill_viridis_c( \n    option = \"magma\", #  chg theme\n    direction = direction # change direction of scale\n    )\n}\n\n\n\nDeploy the function in another document\nTo deploy the function in a Quarto or R Markdown dackument, we need to source it as an external R script. First we will save the previous code as a source document. Let’s name our file wb-maps.R and save it in a subdirectory called functions. From there, we can use the source() function so that we can call our create_map() function in subsequent code chunks in our document.\n\nsource(\"functions/wb-maps.R\", local = knitr::knit_global())\n\nNow let’s call our create_map() function that we just made using female labor force particpation.\n\ncreate_map(var_id = \"SL.TLF.CACT.FE.ZS\", \n           title= \"Female Labor Force Participation\", \n           legend_title = \"FLFP %\", \n           theme = \"inferno\", \n           direction = -1)\n\n\n\n\nNow search for an indicator we want to use. We will look for something related to GDP per capita.\n\nwb_search(\"GDP per capita\") \n\n# A tibble: 24 × 3\n   indicator_id       indicator                                   indicator_desc\n   <chr>              <chr>                                       <chr>         \n 1 5.51.01.10.gdp     Per capita GDP growth                       GDP per capit…\n 2 6.0.GDPpc_constant GDP per capita, PPP (constant 2011 interna… GDP per capit…\n 3 NV.AGR.PCAP.KD.ZG  Real agricultural GDP per capita growth ra… The growth ra…\n 4 NY.GDP.PCAP.CD     GDP per capita (current US$)                GDP per capit…\n 5 NY.GDP.PCAP.CN     GDP per capita (current LCU)                GDP per capit…\n 6 NY.GDP.PCAP.KD     GDP per capita (constant 2010 US$)          GDP per capit…\n 7 NY.GDP.PCAP.KD.ZG  GDP per capita growth (annual %)            Annual percen…\n 8 NY.GDP.PCAP.KN     GDP per capita (constant LCU)               GDP per capit…\n 9 NY.GDP.PCAP.PP.CD  GDP per capita, PPP (current international… This indicato…\n10 NY.GDP.PCAP.PP.KD  GDP per capita, PPP (constant 2017 interna… GDP per capit…\n# ℹ 14 more rows\n\n\nNow let’s take that info. and use it to make a plot of GDP per capita.\n\ncreate_map(var_id = \"NY.GDP.PCAP.PP.KD\", \n           title= \"GDP per capita (constant 2017 internatioal $)\", \n           legend_title = \"Geary-Khamis $\", \n           theme = \"mako\", \n           direction = -1)\n\n\n\n\nThere you go! That’s how we can build and use a map function to easily map different indicators in our document or web app."
  }
]