[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This page displays an outline of the topics, content, and assignments for the term. Each module starts on a Monday. There are no assignments due on Sundays.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModule\nDate\nTopics\nSkills\nReadings\nVideos\nSlides\nAssignments\n\n\n\n\n1.1\nMay 22\nThe readr package\nRead .csv and excel files into R\n\n\n\n\n\n\n\nMay 23\nDownloading data from APIs\nDownload data from vdemdata and store as an object\n\n\n\n\n\n\n\nMay 24\nExploring APIs\n\n\n\n\n\n\n\n1.2\nMay 25\nThe dplyr package I\nFilter observations, select variables and create new ones\n\n\n\n\n\n\n\nMay 26\nThe dplyr package II\nArrange, group and summarize data\n\n\n\n\n\n\n\nMay 27\nData tidying and cleaning\nPivot data with tidyr; clean data with janitor\n\n\n\n\n\n\n2.1\nMay 29\nThe grammar of graphics and ggplot2\nBasics of ggplot2 syntax\n\n\n\n\n\n\n\nMay 30\nBar charts and line charts\nCreate bar charts, line charts and shaded area charts\n\n\n\n\n\n\n\nMay 31\nScatter plots and linear models\nGroup points using shapes or colors; add fitted lines to data\n\n\n\n\n\n\n2.2\nJun 1\nThemes and annotations\nAdd text, labels, annotations and lines to your graphs\n\n\n\n\n\n\n\nJun 2\nInteractivity\nMake visualizations interactive with plotly\n\n\n\n\n\n\n\nJun 3\nClarity and accessibility\nMake sure everyone can read your graphs\n\n\n\n\n\n\n3.1\nJun 5\nWorld Bank databases\nDownload World Bank with wbstats\n\n\n\n\n\n\n\nJun 6\nCreate a world map\nBasics of sf and rnaturalearth packages\n\n\n\n\n\n\n\nJun 7\nMapping data\nJoin WB data to polygons and map\nSomething related to ethics here?\n\n\n\n\n\n3.2\nJun 8\nThe leaflet package\nMake an OpenStreetMap with markers or popups\n\n\n\n\n\n\n\nJun 9\nMap state-level data\nCreate choropleth with colorBin() and addPolygons() functions\n\n\n\n\n\n\n\nJun 10\nMap interactivity\nAdd interactive labels to state choropleth\n\n\n\n\n\n\n4.1\nJun 12\nThe wid-r-tool package\nUse the download_wid() function to download wealth/income shares\n\n\n\n\n\n\n\nJun 13\nReshaping data I\nTransform data to wide format with pivot_wider()\n\n\n\n\n\n\n\nJun 14\nReshaping data II\nTransform data to long format with pivot_longer()\n\n\n\n\n\n\n4.2\nJun 15\nThe grammar of tables\n\n\n\n\n\n\n\n\nJun 16\nMake a table of income shares\nFormat data with fmt_percent()\n\n\n\n\n\n\n\nJun 17\nModify parts of table\n\n\n\n\n\n\n\n5.1\nJun 19\nWhat is a Shiny app?\n\n\n\n\n\n\n\n\nJun 20\nThe ui and server objects\n\n\n\n\n\n\n\n\nJun 21\nYour first Shiny app\n\n\n\n\n\n\n\n5.2\nJun 22\nThe fredr package\n\n\n\n\n\n\n\n\nJun 23\nIndicator graphing app, Part I\n\n\n\n\n\n\n\n\nJun 24\nIndicator graphing app, Part II\n\n\n\n\n\n\n\n6.1\nJun 26\n\n\n\n\n\n\n\n\n\nJun 27\n\n\n\n\n\n\n\n\n\nJun 28\n\n\n\n\n\n\n\n\n6.2\nJun 29\n\n\n\n\n\n\n\n\n\nJun 30\n\n\n\n\n\n\n\n\n\nJul 1"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Microsoft 365\nüîó on GW IT‚Äôs Microsoft 365 Page\n\n\nTableau\nüîó on Tableau Trial\n\n\nLecture Recordings\nüîó on Blackboard\n\n\nProf T‚Äôs Zoom Office\nüîó on Zoom\n\n\nOffice Hours Appointments\nüîó on Calendly"
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Support",
    "section": "",
    "text": "Writing Center GW‚Äôs Writing Center cultivates confident writers in the University community by facilitating collaborative, critical, and inclusive conversations at all stages of the writing process. Working alongside peer mentors, writers develop strategies to write independently in academic and public settings. Appointments can be booked online here.\nAcademic Commons Academic Commons provides tutoring and other academic support resources to students in many courses. Students can schedule virtual one-on-one appointments or attend virtual drop-in sessions. Students may schedule an appointment, review the tutoring schedule, access other academic support resources, or obtain assistance here."
  },
  {
    "objectID": "course-support.html#support-for-students-outside-the-classroom",
    "href": "course-support.html#support-for-students-outside-the-classroom",
    "title": "Support",
    "section": "Support for students outside the classroom",
    "text": "Support for students outside the classroom\nDisability Support Services (DSS) 202-994-8250 Any student who may need an accommodation based on the potential impact of a disability should contact Disability Support Services to establish eligibility and to coordinate reasonable accommodations.\nCounseling and Psychological Services 202-994-5300 GW‚Äôs Colonial Health Center offers counseling and psychological services, supporting mental health and personal development by collaborating directly with students to overcome challenges and difficulties that may interfere with academic, emotional, and personal success.\nGW aims to create a community that cares for each other.The CARE Team fosters this goal by creating a pathway through which students who may need additional support can be identified and referred to the most appropriate services. Through the CARE Team, students are given the support they need to persist and succeed at GW and beyond.\nSafety and Security:\n\nIn an emergency: call GWPD 202-994-6111 or 911.\nFor situation-specific actions: review the Emergency Response Handbook\nStay informed: safety.gwu.edu/stay-informed"
  },
  {
    "objectID": "instructor.html",
    "href": "instructor.html",
    "title": "Instructor",
    "section": "",
    "text": "Emmanuel Teitelbaum is an associate professor of political science and international affairs at the The George Washington University His research and writing explore how class conflict and compromise intersect with democracy and development. He also has a strong interest in labor standards and understanding how labor unions, nonprofit organizations, consumers and corporations can help to promote them.\nAt GW, Professor Teitelbaum teaches courses on comparative politics, comparative political economy and South Asia. He is on faculty in the Department of Political Science and the Elliott School of International Affairs and am affiliated with the Sigur Center for Asian Studies as well as the Institute for International Economic Policy."
  },
  {
    "objectID": "instructor.html#office-hours",
    "href": "instructor.html#office-hours",
    "title": "Instructor",
    "section": "Office hours",
    "text": "Office hours\nProfessor Teitelbaum‚Äôs office hours are on Tuesdays and Thursdays from 4:00 p.m. to 5:00 p.m. Please sign up for a slot (or two) on his Calendly page. He is available for consultation virtually on Zoom or in his office at 411 Monroe Hall (2115 G. ST NW)."
  },
  {
    "objectID": "project/project-datasets.html",
    "href": "project/project-datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "Here are some datasets that you might consider using for your final project:\n\nILOSTAT is the statistical database of the International Labour Organisation. It has data pertaining to labor, working conditions, industrial relations, poverty and inequality.\nGoogle Public Data Explorer contains information about dozens of databases related to governance and the economy. You cannot download the raw data from Google, but you can use the site to visualize the data and then follow the link to the original source.\nOECD DATA provides data related to the performance of high income countries.\nOur World in Data is a good general resource for political economy data. The site is centered around blog posts but you can also search for a topic, view a visualization related to that topic and then download the data used to create it.\nStatista is a good place to look for data on more niche topics.\nUNCTADstat is the United Nations Conference on Trade and Development statistical database. It provides harmonized data on a range of topics related to economic performance, trade and statistics.\nThe UN Human Development Reports include a number of important indicators related to human development, gender and sustainable development goals (SDGs).\nVarieties of Democracy (V-DEM) provides original measures of the quality of democracy for every country dating back to the 18th century.\nWorld Bank Development Indicators (WDI) is the primary World Bank database for development data from officially-recognized international sources.\nThe World Bank DataBank provides access to dozens of additional World Bank databases on topics such as regional development, governance, education, gender and the environment.\n\nFor information on more specific resources available, see this page on the Gelman Library website."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "PSC/DATS 2102--Summer Schedule",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (‚ÄúPublic License‚Äù). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 ‚Äì Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter‚Äôs License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 ‚Äì Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor ‚Äì Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor ‚Äì Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter‚Äôs License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 ‚Äì License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter‚Äôs License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter‚Äôs License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter‚Äôs License You apply.\n\n\n\nSection 4 ‚Äì Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 ‚Äì Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 ‚Äì Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 ‚Äì Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 ‚Äì Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the ‚ÄúLicensor.‚Äù The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark ‚ÄúCreative Commons‚Äù or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "modules/getting-started.html",
    "href": "modules/getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "All of our work for this course will be done in the R language. Please download and install the most recent version of R from the Comprehensive R Archive Network (CRAN).\nRStudio is an integrated development environment (IDE) develop by a company named Posit. We will do all of our code editing for this course in RStudio. Please be sure to download and install the most recent version of R Studio RStudio.\nWe are going to be using a number of R packages throughout the course. One essential set of packages are those that comprise the Tidyverse, but especially readr, dplyr, ggplot2 and tidyr. You can install the entire Tidyverse collection of packages by typing install.packages(\"tidyverse\") in your console. We will talk about these packages in detail as we go through the course, but have a look at this basic description now to gain some basic familiarity."
  },
  {
    "objectID": "modules/getting-started.html#rstudio",
    "href": "modules/getting-started.html#rstudio",
    "title": "Getting Started",
    "section": "RStudio",
    "text": "RStudio\n\nRStudio is an integrated development environment (IDE) develop by a company named Posit."
  },
  {
    "objectID": "modules/getting-started.html#quarto",
    "href": "modules/getting-started.html#quarto",
    "title": "Getting Started",
    "section": "Quarto",
    "text": "Quarto\n\nOnce you have R, R Studio and Quarto installed, you are ready to start integrating text and code with Quarto. Quarto is an open source publishing platform that enables you to integrate text with code. If you have used R Markdown before then Quarto will look familiar to you because Quarto is the next generation of R Markdown.\nRStudio comes with a version of Quarto already installed, but it can be useful to install the most recent version separately and because doing so will allow you to use Quarto with another IDE like VS Code. You can install the most recent version of Quarto by visiting this page and selecting the version for your operating system.\nNow take a little time to create a Quarto project in R Studio and make sure everything is working properly. But before you get started, create a new folder(directory) for this course on your computer somewhere. Once that is done, go to File > New Project. Then select Quarto Project and name the project something like ‚Äútest-project‚Äù in the Directory name field. Next, select Browse and navigate to the folder that you created for this course. Select Create Project.\nYou will notice that in your new project folder there is a file with an .Rproj extension. The .Rproj file is what tells RStudio which files are associated with the project and it obviates the need to set the working directory. It also makes it possible to share the folder with anyone who is running R and RStudio and have them run your code without having to set a working directory. This is what we refer to as a project-based workflow and we will use it for every assignment in this class.\nNow try rendering the document with the Render toggle button. By default, Quarto renders an .html file that it will open in a browser and save to your project folder.\nNext we want to try rendering a .pdf document. To do this, we have to install tinytex, a lightweight version of LaTeX. To do this, go to the Terminal and type quarto install tinytex. Now, change the format from html to pdf by inserting format: pdf in the YAML header. Then render the document again. A .pdf document should open up.\nNow take a few minutes and try changing more of the code in the YAML header. You can try changing the title, adding a subtitle (subtitle:) or changing the execution options. By default, Quarto uses the visual editor but behind the scenes it is using Markdown. Try and edit some text using the toggle buttons available in the visual editor and then switch to Source to view the underlying Markdown code. Play with the R code chunks embedded in the document or try adding new code chunks.\nYou may already have some experience writing in Markdown, which is a lightweight markup language that enables you to format plaintext files. If you have not used Markdown, or if your memory is hazy, don‚Äôt worry: it is really easy to learn. Have a look at this Markdown cheat sheet and try to familiarize yourself with its basic syntax. Finally, take some time to get familiar with the Guide and Reference sections of the Quarto website. Then take a look at the gallery so that you can get an idea of the kinds of things you can produce with Quarto."
  },
  {
    "objectID": "modules/getting-started.html#github",
    "href": "modules/getting-started.html#github",
    "title": "Getting Started",
    "section": "GitHub",
    "text": "GitHub\n\nGitHub is a platform for hosting version control repositories. In this course we will learn to use GitHub to store, manage and collaborate on code.\nOne central concept you want to be familiar with is a repository or ‚Äúrepo‚Äù for short. Repos are essentially folders where code can be stored and then accessed and changed by multiple users. All of the assignments for this course will be managed in repos.\nGitHub repos are managed using a version control system named Git. Git allows developers to make and track changes to the code stored in the repo. Git also enables users to create branches to work on the code without affecting the main codebase and then merge those changes back into the main branch when they are ready.\nThe first thing you are going to want to do is to register a GitHub account. From there, you want to install Git and initiate Git using the usethis package.\nNext, you need to generate a personal access token (PAT) and set your credentials with the gitcreds package.\nNow, you can create a GitHub repo and clone it to your computer in RStudio. There a number of ways to clone a repo, but the recommended method for this course involves creating a new project in RStudio and selecting ‚ÄúVersion Control‚Äù for the method (instead of ‚ÄúNew Directory‚Äù as we did before). From there, select ‚ÄúGit‚Äù, copy the URL from the green ‚ÄúCode‚Äù tab in the GitHub repo, and paste it into ‚ÄúRepository URL‚Äù field. Next, select the directory where you want the repository to be created and click ‚Äúcreate project.‚Äù"
  },
  {
    "objectID": "modules/getting-started.html#github-classroom",
    "href": "modules/getting-started.html#github-classroom",
    "title": "Getting Started",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\n\n\nGive a brief overview of GitHub Classroom and how to use it.\nPerhaps have students download a mock assignment to illustrate how it works."
  },
  {
    "objectID": "modules/module-1.1.html",
    "href": "modules/module-1.1.html",
    "title": "Module 1.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall R, R Studio and the Tidyverse collection of packages if you have not done so already (see getting started)\nInstall the janitor package (install.packages(\"janitor\"))\nHave a look at the documentation for readr, dplyr, tidyr and janitor\nFamiliarize yourself with the readr, dplyr and tidyr cheatsheets\nCreate a new directory/folder in your project folder called ‚Äúdata‚Äù where you can store .csv files\nStart a new quarto project called ‚Äúmodules‚Äù and generate a quarto document named ‚Äúmodule-1.1.qmd‚Äù inside of it so that you can code along with me"
  },
  {
    "objectID": "modules/module-1.1.html#reading-data-from-an-excel-file",
    "href": "modules/module-1.1.html#reading-data-from-an-excel-file",
    "title": "Module 1.1",
    "section": "Reading data from an excel file",
    "text": "Reading data from an excel file"
  },
  {
    "objectID": "modules/module-1.1.html#reading-data-from-a-.csv-file",
    "href": "modules/module-1.1.html#reading-data-from-a-.csv-file",
    "title": "Module 1.1",
    "section": "Reading data from a .csv file",
    "text": "Reading data from a .csv file\n\nOur first task for this module is going to be to simply read some data in from a .csv file. ‚Äúcsv‚Äù stands for ‚Äúcomma separated values‚Äù and so when we are talking about a .csv file we are just saying that the values in the file are delimited by commas. We could also imagine data being delimited by tabs, semicolons or spaces. But the most common kind of flat file we are going to encounter is a .csv file.\nTo read the data from a .csv file, we are going to use the readr package. So we will first load that package along with dplyr so that we can view the data with dplyr‚Äôs glimpse function.\n\nlibrary(readr)\nlibrary(dplyr)\n\nNow we can go ahead and use the readr\ndemdata <- read_csv(‚Äúdata/demdata.csv‚Äù)"
  },
  {
    "objectID": "modules/module-1.1.html#reading-data-from-an-api",
    "href": "modules/module-1.1.html#reading-data-from-an-api",
    "title": "Module 1.1",
    "section": "Reading data from an API",
    "text": "Reading data from an API"
  },
  {
    "objectID": "modules/module-1.1.html#assignment",
    "href": "modules/module-1.1.html#assignment",
    "title": "Module 1.1",
    "section": "Assignment",
    "text": "Assignment"
  },
  {
    "objectID": "modules/module-1.1.html#overview",
    "href": "modules/module-1.1.html#overview",
    "title": "Module 1.1",
    "section": "Overview",
    "text": "Overview\nIn this module, we are going to work with a ‚Äúflat file‚Äù (.csv) that we will download from the World Bank‚Äôs Data Bank. We are going to encounter many problems with these data that we will rectify using various R packages that I will introduce along the way. The idea is to take this file in its current state and transform it into a tidy dataset where each column represents a variable, each row represents an observation, and each cell represents a single value."
  },
  {
    "objectID": "modules/module-1.1.html#step-1-download-data-from-the-world-bank",
    "href": "modules/module-1.1.html#step-1-download-data-from-the-world-bank",
    "title": "Module 1.1",
    "section": "Step 1: Download data from the World Bank",
    "text": "Step 1: Download data from the World Bank\n\nGo to the World Development Indicators portal at the World Bank‚Äôs Data Bank.\nUnder Countries, select the Countries tab and then select the little check mark ‚òëÔ∏è to select all of the countries. Be sure to select the Countries tab first, though, or you will also be downloading aggregate data for regions and groups of countries.\nNext, under Series, search for ‚Äúlabor force participation‚Äù and find labor force participation rates for women ages 15-64 (ILO modeled estimates). Check that series.\nNow go to Time and select the years from the last 50 years. Click Apply Changes, go to Download Options and download as a .csv file. Place the .csv file in the data directory that you created for this module. Save it as ‚Äúmessy_wb_data.csv‚Äù or something like that."
  },
  {
    "objectID": "modules/module-1.1.html#step-2-read-the-wb-.csv-file",
    "href": "modules/module-1.1.html#step-2-read-the-wb-.csv-file",
    "title": "Module 1.1",
    "section": "Step 2: Read the WB .csv file",
    "text": "Step 2: Read the WB .csv file\n\nNow we are going to read this messy World Bank data into R using the read_csv() function from the readr package. readr is a collection of functions that parses data from a flat file into a tibble, the modern Tidyverse version of a data frame. Afater we have read the data into R, we are going to have a look at it with the glimpse() function from the dplyr package.\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhile comma delimited files are the most common kind of flat file, readr includes functions for parsing files with a wide range of delimiters including tabs (read_tsv()), semicolons (read_csv2()) and white spaces (read_table()). There is also a Tidyverse package for reading in Excel files called readxl.\n\n\n\n\nlibrary(readr)\nlibrary(dplyr)\n\nwb_data_messy <- read_csv(\"data/messy_wb_data.csv\")\n\nglimpse(wb_data_messy)\n\nRows: 222\nColumns: 54\n$ `Country Name`  <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"American Samoa\",‚Ä¶\n$ `Country Code`  <chr> \"AFG\", \"ALB\", \"DZA\", \"ASM\", \"AND\", \"AGO\", \"ATG\", \"ARG\"‚Ä¶\n$ `Series Name`   <chr> \"Labor force participation rate, female (% of female p‚Ä¶\n$ `Series Code`   <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI‚Ä¶\n$ `1972 [YR1972]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1973 [YR1973]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1974 [YR1974]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1975 [YR1975]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1976 [YR1976]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1977 [YR1977]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1978 [YR1978]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1979 [YR1979]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1980 [YR1980]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1981 [YR1981]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1982 [YR1982]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1983 [YR1983]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1984 [YR1984]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1985 [YR1985]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1986 [YR1986]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1987 [YR1987]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1988 [YR1988]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1989 [YR1989]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1990 [YR1990]` <chr> \"15.83\", \"60.63\", \"12.31\", \"..\", \"..\", \"76.73\", \"..\", ‚Ä¶\n$ `1991 [YR1991]` <chr> \"15.89\", \"65.54\", \"12.33\", \"..\", \"..\", \"76.69\", \"..\", ‚Ä¶\n$ `1992 [YR1992]` <chr> \"15.92\", \"66.56\", \"12.37\", \"..\", \"..\", \"76.66\", \"..\", ‚Ä¶\n$ `1993 [YR1993]` <chr> \"15.91\", \"65.01\", \"12.41\", \"..\", \"..\", \"76.68\", \"..\", ‚Ä¶\n$ `1994 [YR1994]` <chr> \"15.88\", \"63.64\", \"12.47\", \"..\", \"..\", \"76.64\", \"..\", ‚Ä¶\n$ `1995 [YR1995]` <chr> \"15.92\", \"61.59\", \"12.56\", \"..\", \"..\", \"76.57\", \"..\", ‚Ä¶\n$ `1996 [YR1996]` <chr> \"15.75\", \"60.28\", \"12.64\", \"..\", \"..\", \"76.55\", \"..\", ‚Ä¶\n$ `1997 [YR1997]` <chr> \"15.59\", \"61.91\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1998 [YR1998]` <chr> \"15.47\", \"60.62\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1999 [YR1999]` <chr> \"15.4\", \"58.87\", \"12.63\", \"..\", \"..\", \"76.51\", \"..\", \"‚Ä¶\n$ `2000 [YR2000]` <chr> \"15.35\", \"57.89\", \"12.71\", \"..\", \"..\", \"76.49\", \"..\", ‚Ä¶\n$ `2001 [YR2001]` <chr> \"15.5\", \"56.71\", \"12.85\", \"..\", \"..\", \"76.48\", \"..\", \"‚Ä¶\n$ `2002 [YR2002]` <chr> \"15.7\", \"56.06\", \"13.02\", \"..\", \"..\", \"76.44\", \"..\", \"‚Ä¶\n$ `2003 [YR2003]` <chr> \"15.92\", \"55.3\", \"13.24\", \"..\", \"..\", \"76.41\", \"..\", \"‚Ä¶\n$ `2004 [YR2004]` <chr> \"16.13\", \"54.57\", \"13.5\", \"..\", \"..\", \"76.38\", \"..\", \"‚Ä¶\n$ `2005 [YR2005]` <chr> \"16.33\", \"53.88\", \"13.79\", \"..\", \"..\", \"76.36\", \"..\", ‚Ä¶\n$ `2006 [YR2006]` <chr> \"16.12\", \"53.43\", \"14.12\", \"..\", \"..\", \"76.39\", \"..\", ‚Ä¶\n$ `2007 [YR2007]` <chr> \"15.91\", \"53.07\", \"14.47\", \"..\", \"..\", \"76.42\", \"..\", ‚Ä¶\n$ `2008 [YR2008]` <chr> \"15.74\", \"52.78\", \"14.87\", \"..\", \"..\", \"76.46\", \"..\", ‚Ä¶\n$ `2009 [YR2009]` <chr> \"15.65\", \"51.57\", \"15.31\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `2010 [YR2010]` <chr> \"15.65\", \"52.75\", \"15.49\", \"..\", \"..\", \"76.59\", \"..\", ‚Ä¶\n$ `2011 [YR2011]` <chr> \"16\", \"60.59\", \"16.45\", \"..\", \"..\", \"76.67\", \"..\", \"55‚Ä¶\n$ `2012 [YR2012]` <chr> \"16.44\", \"55.1\", \"17.48\", \"..\", \"..\", \"76.73\", \"..\", \"‚Ä¶\n$ `2013 [YR2013]` <chr> \"17.42\", \"50.58\", \"18.29\", \"..\", \"..\", \"76.79\", \"..\", ‚Ä¶\n$ `2014 [YR2014]` <chr> \"18.46\", \"50.18\", \"16.68\", \"..\", \"..\", \"76.83\", \"..\", ‚Ä¶\n$ `2015 [YR2015]` <chr> \"19.55\", \"54.05\", \"17.5\", \"..\", \"..\", \"76.87\", \"..\", \"‚Ä¶\n$ `2016 [YR2016]` <chr> \"20.7\", \"56.4\", \"18.33\", \"..\", \"..\", \"76.9\", \"..\", \"56‚Ä¶\n$ `2017 [YR2017]` <chr> \"21.91\", \"55.54\", \"19.19\", \"..\", \"..\", \"76.91\", \"..\", ‚Ä¶\n$ `2018 [YR2018]` <chr> \"22.32\", \"59.12\", \"18.95\", \"..\", \"..\", \"76.9\", \"..\", \"‚Ä¶\n$ `2019 [YR2019]` <chr> \"22.74\", \"61.46\", \"18.7\", \"..\", \"..\", \"76.88\", \"..\", \"‚Ä¶\n$ `2020 [YR2020]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `2021 [YR2021]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n\n\nglimpse() shows us a list of the columns in the along with their type (e.g.¬†character, double, etc.) and a few rows‚Äô worth of data."
  },
  {
    "objectID": "modules/module-1.1.html#step-3-reshape-the-data",
    "href": "modules/module-1.1.html#step-3-reshape-the-data",
    "title": "Module 1.1",
    "section": "Step 3: Reshape the data",
    "text": "Step 3: Reshape the data\n\nThere are a few things about the data here that make it messy. First, in order for the data to be tidy, we want each column to represent a variable and each row to represent an observation.\nBut here we see the reverse: the data are in wide form, meaning that each column represents a year and each row represents a country. This entails that each row represents multiple observations in that we have data for multiple years for each row.\nTo rectify this, we need to reshape the data from wide form to long form. For this, we need the pivot_longer() function from the tidyr package.\nThe pivot_longer() function takes three basic arguments:\n\ncols - which columns you want to pivot\nnames_to - what you want the column with the transposed data to be called\nvalues_to - what you want the column with the values from the transposed data to be called\n\nIn our case, we want to reshape all of the year columns and have the years represented in the rows. We want the newly created column to be called ‚Äúyear‚Äù and the values are going to represent the data on female labor force participation we downloaded (flfp).\n\nlibrary(tidyr)\n\nwb_data <- wb_data_messy |> \n  pivot_longer(\n    cols = `1972 [YR1972]`: `2021 [YR2021]`, \n    names_to = \"year\", \n    values_to = \"flfp\"\n  ) \n\nglimpse(wb_data)\n\nRows: 11,100\nColumns: 6\n$ `Country Name` <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist‚Ä¶\n$ `Country Code` <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",‚Ä¶\n$ `Series Name`  <chr> \"Labor force participation rate, female (% of female po‚Ä¶\n$ `Series Code`  <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.‚Ä¶\n$ year           <chr> \"1972 [YR1972]\", \"1973 [YR1973]\", \"1974 [YR1974]\", \"197‚Ä¶\n$ flfp           <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"‚Ä¶\n\n\n\n\n\n\n\n\nThe Pipe Operator\n\n\n\nFor our pivot-longer() call we used R‚Äôs native pipe operator. Pipes tell R to do something to the object that they are attached to. In this case, we are telling R to apply pivot_longer() to wb_data. The alternative way of writing this code would be to include the data as the first argument in the function, e.g.¬†pivot_longer(wb_data, cols = ..., names_to = ... , values_to = ...). As you will see, pipe operators enable us to string together multiple functions in a convenient way to transform our data.\n\n\n\n\n\n\n\n\nSpaces in Variable Names\n\n\n\nNotice that when we specify the years in our pivot_longer() call we encapsulate them in backticks (``). This is because the years, as they were imported from the WDI dataset, have spaces in them. Typically we want to avoid this scenario by writing our variable names in snake_case."
  },
  {
    "objectID": "modules/module-1.1.html#the-pipe-operator",
    "href": "modules/module-1.1.html#the-pipe-operator",
    "title": "Module 1.1",
    "section": "The Pipe Operator",
    "text": "The Pipe Operator\nFor our pivot-longer() call we are going to use R‚Äôs native pipe operator. Pipes tell R to do something to the object that they are attached to. In this case, we are telling R to apply pivot_longer() to wb_data. The alternative way of writing this code would be to include the data as the first argument in the function, e.g.¬†pivot_longer(wb_data, cols = ..., names_to = ... , values_to = ...). As you will see, pipe operators enable us to string together multiple functions in a convenient way to transform our data."
  },
  {
    "objectID": "modules/module-1.2.html",
    "href": "modules/module-1.2.html",
    "title": "Module 1.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall the devtools package. Type install.packages(\"devtools\") in your console. You will need this to install the vdemdata package becaue it is not on the CRAN Network.\nInstall the vdemdata package from GitHub. Type devtools::install_github(\"vdeminstitute/vdemdata\") in your console.\nInstall the wbstats and countrycode packages:\n\n\npkg_list <- c(\"wbstats\", \"countrycode\") # create a list of packages\ninstall.packages(pkg_list) # install the packages\n\n\nHave a look at the vignettes for wbstats and the countrycode documentation\nGenerate a quarto document named ‚Äúmodule-1.2.qmd‚Äù in your modules project folder so that you can code along with me"
  },
  {
    "objectID": "modules/module-1.2.html#overview",
    "href": "modules/module-1.2.html#overview",
    "title": "Module 1.2",
    "section": "Overview",
    "text": "Overview\nIn this module working, we are going to be working with data from APIs instead of flat files. As we saw in the last lesson, importing and wrangling data from flat files can be a messy process. So when clean data are available for download, we want to be able to take advantage of that. Luckily there are some pretty good R packages that allow us to extract data from open source APIs. We are going to be working with two of those in this module (wbstats and vdemdata) and some others later in the course.\nAlong the way, we are going to continue to extend our data wrangling skills. We will learn some new functions in dplyr and janitor that will help us get our data into a usable form for analysis. We are also going to cover in depth some common data science workflows, including filtering observations, selecting variables, merging two data sets, summarizing data for different groups, and sorting data based on column values.\nThe end goal is to have a nice dataset with a combination of World Bank and V-Dem Institute data that we can use to illustrate the relationship between the economy, democracy and women‚Äôs empowerment."
  },
  {
    "objectID": "modules/module-1.2.html#wrangle-wb-data",
    "href": "modules/module-1.2.html#wrangle-wb-data",
    "title": "Module 1.2",
    "section": "Wrangle WB data",
    "text": "Wrangle WB data\nPicking up where we left off‚Ä¶ but let‚Äôs add one more variable‚Ä¶and use lubridate to specify the most recent date.\n\nlibrary(wbstats) \nlibrary(dplyr)\nlibrary(janitor)\n\nindicators <- c(flfp = \"SL.TLF.CACT.FE.ZS\", women_rep = \"SG.GEN.PARL.ZS\")\n\nwomen_emp <- wb_data(indicators, mrv = 50) |> \n  select(!iso2c) |> \n  rename(year = date) |> \n    mutate(\n    flfp = round_to_fraction(flfp, denominator = 100), \n    women_rep = round_to_fraction(women_rep, denominator = 100)\n  )\n\nglimpse(women_emp)\n\nRows: 6,944\nColumns: 5\n$ iso3c     <chr> \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW‚Ä¶\n$ country   <chr> \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba‚Ä¶\n$ year      <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, ‚Ä¶\n$ women_rep <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ flfp      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#filter-observations-select-and-create-new-variables",
    "href": "modules/module-1.2.html#filter-observations-select-and-create-new-variables",
    "title": "Module 1.2",
    "section": "Filter observations, select and create new variables",
    "text": "Filter observations, select and create new variables\n\nThe next thing we want to talk about is how to filter observations and to select new variables. We also delve more into the topic of how to create new variables. To illustrate these concepts, we are going to be working with the V-Dem Dataset. The V-Dem offers an R package for downloading its data called vdemdata.\nvdemdata is perfect for illustrating the filter() and select() verbs because its main function for downloading the data (vdem) does not take any arguments (it simply downloads the whole dataset). So you have to use R functions to narrow down the variables and years you want to work with.\nWhile V-Dem has wealth of indicators related to democracy, we are going to focus on the most famous one called the ‚Äúpolyarchy‚Äù score. We are also going to download data on per capita GDP and create some indicator variables for region that we will use later on when we summarize the data. Along with those variables, we also want to retain country_name, year and country_id for the purposes of merging these data with our World Bank data.\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhile V-Dem has a variable look-up tool (find_var), it does not provide very much information on the variables that the search function returns. Therefore, if you want to use this package for your own research, I highly recommend just going to the V-Dem codebook and manually grabbing the codes for the indicators that you want to use in your analysis.\n\n\n\nIn addition to filtering out years and selecting variables, let‚Äôs also create a region coding to facilitate our analysis later on. We will do this by piping in a mutate() call where we use the case_match() function to change the region from a numeric variable to a string. This will come in handy when we go to visualize the data in future lessons.\nWe will store our new data as an object called democracy.\n\nlibrary(vdemdata) # to download V-Dem data\nlibrary(dplyr)\n\ndemocracy <- vdem |> # download the V-Dem dataset\n  filter(year >= 1990)  |> # filter out years less than 1990\n  select(                  # select (and rename) these variables\n    country = country_name,     # the name before the = sign is the new name  \n    vdem_ctry_id = country_id,  # the name after the = sign is the old name\n    year, \n    polyarchy = v2x_polyarchy, \n    gdp_pc = e_gdppc, \n    region = e_regionpol_6C\n    ) |>\n  mutate(\n    region = case_match(region, # replace the values in region with country names\n                     1 ~ \"Eastern Europe\", # the number on the left of the = sign is the V-Dem region code\n                     2 ~ \"Latin America\", # we are changing the number to the country name on the right \n                     3 ~ \"Middle East\",   # of the equals sign\n                     4 ~ \"Africa\", \n                     5 ~ \"The West\", \n                     6 ~ \"Asia\")\n  )\n\nglimpse(democracy)\n\nRows: 5,667\nColumns: 6\n$ country      <chr> \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico‚Ä¶\n$ vdem_ctry_id <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ year         <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199‚Ä¶\n$ polyarchy    <dbl> 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0‚Ä¶\n$ gdp_pc       <dbl> 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1‚Ä¶\n$ region       <chr> \"Latin America\", \"Latin America\", \"Latin America\", \"Latin‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#add-country-code-to-democracy-tibble",
    "href": "modules/module-1.2.html#add-country-code-to-democracy-tibble",
    "title": "Module 1.2",
    "section": "Add country code to democracy tibble",
    "text": "Add country code to democracy tibble\n\nlibrary(countrycode)\n\ndemocracy <- democracy |> \n  mutate(iso3c = countrycode(vdem_ctry_id, \"vdem\", \"wb\"))  |> \n  relocate(iso3c, .after = vdem_ctry_id)\n\nglimpse(democracy)\n\nRows: 8,182\nColumns: 7\n$ country      <chr> \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico‚Ä¶\n$ vdem_ctry_id <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ iso3c        <chr> \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"‚Ä¶\n$ year         <dbl> 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 198‚Ä¶\n$ polyarchy    <dbl> 0.252, 0.252, 0.259, 0.274, 0.297, 0.298, 0.302, 0.304, 0‚Ä¶\n$ gdp_pc       <dbl> 9.189, 9.480, 9.673, 9.914, 10.434, 11.146, 11.865, 12.32‚Ä¶\n$ region       <chr> \"Latin America\", \"Latin America\", \"Latin America\", \"Latin‚Ä¶\n\n#filter(democracy, is.na(iso3c))"
  },
  {
    "objectID": "modules/module-1.2.html#merge-two-datasets",
    "href": "modules/module-1.2.html#merge-two-datasets",
    "title": "Module 1.2",
    "section": "Merge two datasets",
    "text": "Merge two datasets\n\nNow that we have a common country code, we can join the two data sets. There are many different types of joins. First there is a distinction between mutating joins, which add observations from one dataset to another, and filtering joins, which filter out variables based on their presence or absence in another dataset. Here we are going to be focused on mutating joins.\nThere are four kinds of mutating joins we can do in dplyr. An inner_join() keeps only the observations that are common in both datasets that you want to merge. A full_join() does the opposite. It keeps all of the observations present in both datasets regardless of whether or not they have a match. A left_join() keeps all of the observations in dataset \\(x\\) and only the matching observations in dataset \\(y\\). A right_join() does the same thing, but instead keeps all of the observations from dataset \\(y\\) and only matching observations from dataset \\(x\\).\nWe are going to use left_join() to merge our two datasets. left_join() takes three essential arguments: \\(x\\); \\(y\\); and \\(by\\) which identifies the column that we want to join on. For this exercise, the \\(x\\) dataset is going to be the democracy dataset, the \\(y\\) dataset is the women empowerment dataset, and we want to join on both the ‚Äúiso3c‚Äù and ‚Äúyear‚Äù columns.\nWhen dplyr does a join, it renames any duplicate columns with suffixes like .x or .y. In our data, country is a duplicate column across the democracy and women‚Äôs empowerment datasets. So dplyr renames these country.x and country.y. It doesn‚Äôt really matter which one we keep, so let‚Äôs just rename country.x to country and filter out country.y using select().\nWe can can pipe all of these functions together and store the resulting data frame in a new object called dem_women. Let‚Äôs also save these data as a .csv file for future use with write_csv(). The first argument for write_csv() is the name of the data frame or tibble that we want to save. The second argument is the path and name of the file that we want to save it to.\n\nlibrary(readr)\n\ndem_women <- left_join(democracy, women_emp, by = c(\"iso3c\", \"year\")) |> \n  rename(country = country.x) |> \n  select(!country.y)\n\nwrite_csv(dem_women, \"data/dem_women.csv\")\n\nglimpse(dem_women)  \n\nRows: 5,667\nColumns: 9\n$ country      <chr> \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico‚Ä¶\n$ vdem_ctry_id <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ iso3c        <chr> \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"‚Ä¶\n$ year         <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199‚Ä¶\n$ polyarchy    <dbl> 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0‚Ä¶\n$ gdp_pc       <dbl> 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1‚Ä¶\n$ region       <chr> \"Latin America\", \"Latin America\", \"Latin America\", \"Latin‚Ä¶\n$ women_rep    <dbl> NA, NA, NA, NA, NA, NA, NA, 14.20, 17.40, 18.20, 16.00, 1‚Ä¶\n$ flfp         <dbl> 33.94, 34.24, 35.01, 35.85, 36.38, 37.62, 37.69, 39.65, 3‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#group-summarize-and-arrange-summarize-by-region",
    "href": "modules/module-1.2.html#group-summarize-and-arrange-summarize-by-region",
    "title": "Module 1.2",
    "section": "Group, summarize and arrange (summarize by region)",
    "text": "Group, summarize and arrange (summarize by region)\nCould this one be done with webr?\n\ndem_summary <- dem_women |> \n  group_by(region)  |> \n  summarize(\n    polyarchy = mean(polyarchy, na.rm = TRUE),\n    gdp_pc = mean(gdp_pc, na.rm = TRUE), \n    flfp = mean(flfp, na.rm = TRUE), \n    women_rep = mean(women_rep, na.rm = TRUE)\n  ) |> \n  arrange(desc(polyarchy)) \n\ndem_summary\n\n# A tibble: 6 √ó 5\n  region         polyarchy gdp_pc  flfp women_rep\n  <chr>              <dbl>  <dbl> <dbl>     <dbl>\n1 The West           0.873  37.9   52.8     27.8 \n2 Latin America      0.641   9.61  48.0     20.9 \n3 Eastern Europe     0.538  12.2   51.4     17.6 \n4 Asia               0.408   9.75  50.3     14.3 \n5 Africa             0.393   4.41  56.7     17.2 \n6 Middle East        0.249  21.1   26.5      9.95\n\n#filter(dem_women, is.na(region))"
  },
  {
    "objectID": "modules/module-1.1.html#step-4-fix-year-and-change-variables-to-numeric",
    "href": "modules/module-1.1.html#step-4-fix-year-and-change-variables-to-numeric",
    "title": "Module 1.1",
    "section": "Step 4: Fix year and change variables to numeric",
    "text": "Step 4: Fix year and change variables to numeric\n\nNow that our data are transposed, we can start to work on some other key issues. Notice that the year is stored in the weird way in which it was imported‚Äìas a character (or string) with both the year and the year in brackets, e.g.¬†1972 [YR1972]. Notice that flfp is also stored as a character whereas it should be numeric.\nTo fix this, we will use the mutate() and mutate_at() functions from dplyr. mutate() is used to transform variables and to create new ones while mutate_at() allow us to transform multiple columns at once.\nFirst we call mutate() along with substring() to truncate the year variable to only include the first four characters of the string. Then we call mutate_all() along with as.numeric to transform year and flfp to numeric variables.\n\nwb_data <- wb_data |> \n  mutate(year = substring(year, 1, 4)) |> \n  mutate_at(c(\"year\", \"flfp\"), as.numeric)\n\nglimpse(wb_data)\n\nRows: 11,100\nColumns: 6\n$ `Country Name` <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist‚Ä¶\n$ `Country Code` <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",‚Ä¶\n$ `Series Name`  <chr> \"Labor force participation rate, female (% of female po‚Ä¶\n$ `Series Code`  <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.‚Ä¶\n$ year           <dbl> 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1‚Ä¶\n$ flfp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶"
  },
  {
    "objectID": "modules/module-1.1.html#step-5-clean-the-variable-names",
    "href": "modules/module-1.1.html#step-5-clean-the-variable-names",
    "title": "Module 1.1",
    "section": "Step 5: Clean the variable names",
    "text": "Step 5: Clean the variable names\n\nThe last thing we are going to do is to fix the variable names. Specifically, we want to remove the spaces from the remaining variables and conver them from title case to snake case. To do this, we will use the clean_names() function from the janitor package.\nAs a final step, we can export our clean data to a new .csv file with the write.csv() function from readr.\n\nlibrary(janitor)\n\nwb_data_clean <- wb_data |>  \n  clean_names() \n\nwrite_csv(wb_data_clean, \"data/wb_data_clean.csv\")\n\nglimpse(wb_data_clean)\n\nRows: 11,100\nColumns: 6\n$ country_name <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan‚Ä¶\n$ country_code <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"‚Ä¶\n$ series_name  <chr> \"Labor force participation rate, female (% of female popu‚Ä¶\n$ series_code  <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE‚Ä¶\n$ year         <dbl> 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 198‚Ä¶\n$ flfp         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶"
  },
  {
    "objectID": "modules/module-1.1.html#step-2-read-the-.csv-file",
    "href": "modules/module-1.1.html#step-2-read-the-.csv-file",
    "title": "Module 1.1",
    "section": "Step 2: Read the .csv file",
    "text": "Step 2: Read the .csv file\n\nNow we are going to read this messy World Bank data into R using the read_csv() function from the readr package. readr is a collection of functions that parses data from a flat file into a tibble, the modern Tidyverse version of a data frame. After we have read the data into R, we are going to have a look at it with the glimpse() function from the dplyr package.\nglimpse() shows us a list of the columns in the along with their type (e.g.¬†character, double, etc.) and a few rows‚Äô worth of data.\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhile comma delimited files are the most common kind of flat file, readr includes functions for parsing files with a wide range of delimiters including tabs (read_tsv()), semicolons (read_csv2()) and white spaces (read_table()). There is also a Tidyverse package for reading in Excel files called readxl.\n\n\n\n\nlibrary(readr)\nlibrary(dplyr)\n\nwb_data_messy <- read_csv(\"data/messy_wb_data.csv\")\n\nglimpse(wb_data_messy)\n\nRows: 222\nColumns: 54\n$ `Country Name`  <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"American Samoa\",‚Ä¶\n$ `Country Code`  <chr> \"AFG\", \"ALB\", \"DZA\", \"ASM\", \"AND\", \"AGO\", \"ATG\", \"ARG\"‚Ä¶\n$ `Series Name`   <chr> \"Labor force participation rate, female (% of female p‚Ä¶\n$ `Series Code`   <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI‚Ä¶\n$ `1972 [YR1972]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1973 [YR1973]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1974 [YR1974]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1975 [YR1975]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1976 [YR1976]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1977 [YR1977]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1978 [YR1978]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1979 [YR1979]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1980 [YR1980]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1981 [YR1981]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1982 [YR1982]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1983 [YR1983]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1984 [YR1984]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1985 [YR1985]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1986 [YR1986]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1987 [YR1987]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1988 [YR1988]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1989 [YR1989]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1990 [YR1990]` <chr> \"15.83\", \"60.63\", \"12.31\", \"..\", \"..\", \"76.73\", \"..\", ‚Ä¶\n$ `1991 [YR1991]` <chr> \"15.89\", \"65.54\", \"12.33\", \"..\", \"..\", \"76.69\", \"..\", ‚Ä¶\n$ `1992 [YR1992]` <chr> \"15.92\", \"66.56\", \"12.37\", \"..\", \"..\", \"76.66\", \"..\", ‚Ä¶\n$ `1993 [YR1993]` <chr> \"15.91\", \"65.01\", \"12.41\", \"..\", \"..\", \"76.68\", \"..\", ‚Ä¶\n$ `1994 [YR1994]` <chr> \"15.88\", \"63.64\", \"12.47\", \"..\", \"..\", \"76.64\", \"..\", ‚Ä¶\n$ `1995 [YR1995]` <chr> \"15.92\", \"61.59\", \"12.56\", \"..\", \"..\", \"76.57\", \"..\", ‚Ä¶\n$ `1996 [YR1996]` <chr> \"15.75\", \"60.28\", \"12.64\", \"..\", \"..\", \"76.55\", \"..\", ‚Ä¶\n$ `1997 [YR1997]` <chr> \"15.59\", \"61.91\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1998 [YR1998]` <chr> \"15.47\", \"60.62\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1999 [YR1999]` <chr> \"15.4\", \"58.87\", \"12.63\", \"..\", \"..\", \"76.51\", \"..\", \"‚Ä¶\n$ `2000 [YR2000]` <chr> \"15.35\", \"57.89\", \"12.71\", \"..\", \"..\", \"76.49\", \"..\", ‚Ä¶\n$ `2001 [YR2001]` <chr> \"15.5\", \"56.71\", \"12.85\", \"..\", \"..\", \"76.48\", \"..\", \"‚Ä¶\n$ `2002 [YR2002]` <chr> \"15.7\", \"56.06\", \"13.02\", \"..\", \"..\", \"76.44\", \"..\", \"‚Ä¶\n$ `2003 [YR2003]` <chr> \"15.92\", \"55.3\", \"13.24\", \"..\", \"..\", \"76.41\", \"..\", \"‚Ä¶\n$ `2004 [YR2004]` <chr> \"16.13\", \"54.57\", \"13.5\", \"..\", \"..\", \"76.38\", \"..\", \"‚Ä¶\n$ `2005 [YR2005]` <chr> \"16.33\", \"53.88\", \"13.79\", \"..\", \"..\", \"76.36\", \"..\", ‚Ä¶\n$ `2006 [YR2006]` <chr> \"16.12\", \"53.43\", \"14.12\", \"..\", \"..\", \"76.39\", \"..\", ‚Ä¶\n$ `2007 [YR2007]` <chr> \"15.91\", \"53.07\", \"14.47\", \"..\", \"..\", \"76.42\", \"..\", ‚Ä¶\n$ `2008 [YR2008]` <chr> \"15.74\", \"52.78\", \"14.87\", \"..\", \"..\", \"76.46\", \"..\", ‚Ä¶\n$ `2009 [YR2009]` <chr> \"15.65\", \"51.57\", \"15.31\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `2010 [YR2010]` <chr> \"15.65\", \"52.75\", \"15.49\", \"..\", \"..\", \"76.59\", \"..\", ‚Ä¶\n$ `2011 [YR2011]` <chr> \"16\", \"60.59\", \"16.45\", \"..\", \"..\", \"76.67\", \"..\", \"55‚Ä¶\n$ `2012 [YR2012]` <chr> \"16.44\", \"55.1\", \"17.48\", \"..\", \"..\", \"76.73\", \"..\", \"‚Ä¶\n$ `2013 [YR2013]` <chr> \"17.42\", \"50.58\", \"18.29\", \"..\", \"..\", \"76.79\", \"..\", ‚Ä¶\n$ `2014 [YR2014]` <chr> \"18.46\", \"50.18\", \"16.68\", \"..\", \"..\", \"76.83\", \"..\", ‚Ä¶\n$ `2015 [YR2015]` <chr> \"19.55\", \"54.05\", \"17.5\", \"..\", \"..\", \"76.87\", \"..\", \"‚Ä¶\n$ `2016 [YR2016]` <chr> \"20.7\", \"56.4\", \"18.33\", \"..\", \"..\", \"76.9\", \"..\", \"56‚Ä¶\n$ `2017 [YR2017]` <chr> \"21.91\", \"55.54\", \"19.19\", \"..\", \"..\", \"76.91\", \"..\", ‚Ä¶\n$ `2018 [YR2018]` <chr> \"22.32\", \"59.12\", \"18.95\", \"..\", \"..\", \"76.9\", \"..\", \"‚Ä¶\n$ `2019 [YR2019]` <chr> \"22.74\", \"61.46\", \"18.7\", \"..\", \"..\", \"76.88\", \"..\", \"‚Ä¶\n$ `2020 [YR2020]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `2021 [YR2021]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#downloading-data-from-an-api",
    "href": "modules/module-1.2.html#downloading-data-from-an-api",
    "title": "Module 1.2",
    "section": "Downloading data from an API",
    "text": "Downloading data from an API\n\nYou will no doubt remember the messy data that we downloaded from the World Bank‚Äôs website in module 1.1. Usually it is much easier to download data from an API as opposed to wrangling it from a .csv file. In this example, I want to illustrate that for you by having you download the same data that we worked with in the last module using the wbstats package.\nFirst we are going to load wbstats along with dplyr and janitor. The wb_data() function is the one we need to download the data from the World Bank‚Äôs API. wb_data() requires to main sets of arguments: a list of indicators that we want to use and the period for which we want to download data. The period can can be entered as two separate arguments (e.g.¬†start_date and end_date). But for this exercise we will specify the number of years we want to download using mrv which stands for ‚Äúmost recent value.‚Äù\nIn addition to female labor force participation, let‚Äôs also grab the percentage of seats in parliament held by women. We will store that list of objects in a vector called women_emp to signify that these indicators are related to women‚Äôs empowerment. We will try to download 50 years of data for these two variables.\n\n\n\n\n\n\nNote\n\n\n\nIf you want to search World Bank data for additional indicators, you can use the wb_search() function. For example, if we wanted to find all of the indicators associated with female labor force participation, we could run:\n\nflfp_indicators <- wb_search(\"female labor force\") # store the list of indicators\n\nprint(flfp_indicators, n=26) # view the indicators\n\nTry searching for some indicators related to a topic you are interested in and see what you get!\n\n\nWhile we are calling wb_data we will go ahead and pipe some additional functions from dplyr and janitor to clean it up. First, we will use select() to eliminate the iso2c variable, which we won‚Äôt be needing. Then, we will rename date to year. Then we will use a combination of mutate and round_to_fraction() to round the data to the nearest hundredth.\nWe will pipe all of these functions together and store the resulting data frame in a new object called women_emp.\n\nlibrary(wbstats) # for downloading WB data\nlibrary(dplyr) # for selecting, renaming and mutating\nlibrary(janitor) # for rounding\n\nindicators <- c(\"flfp\" = \"SL.TLF.CACT.FE.ZS\", \"women_rep\" = \"SG.GEN.PARL.ZS\") # store indicators\n  \nwomen_emp <- wb_data(indicators, mrv = 50) |> # download indicator data for last 50 yrs\n  select(!iso2c) |> # drop the iso2c code which we won't be using\n  rename(year = date) |> # rename date to year \n  mutate(\n    flfp = round_to_fraction(flfp, denominator = 100), # round to nearest 100th\n    women_rep = round_to_fraction(women_rep, denominator = 100) \n  )\n\nglimpse(women_emp) # view the data\n\nRows: 6,944\nColumns: 5\n$ iso3c     <chr> \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW‚Ä¶\n$ country   <chr> \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba‚Ä¶\n$ year      <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, ‚Ä¶\n$ women_rep <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ flfp      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n\n\nNow we have some pretty tidy World Bank data related to women‚Äôs empowerment without having to do too much work. I am sure you would agree that this is a much more straightforward process than downloading the data and then importing the data as a flat file!\nOne thing that becomes very clear here is that wb_data() did not download any data before 1990. It automatically filtered out the years for which all countries had no data. The fact there were no data before 1990 for any of the countries is easily missed when we were simply importing it from a .csv file."
  },
  {
    "objectID": "modules/module-1.2.html#add-country-code-to-democracy-data-frame",
    "href": "modules/module-1.2.html#add-country-code-to-democracy-data-frame",
    "title": "Module 1.2",
    "section": "Add country code to democracy data frame",
    "text": "Add country code to democracy data frame\n\nlibrary(countrycode)\n\ndemocracy <- democracy |> \n  mutate(iso3c = countrycode(vdem_ctry_id, \"vdem\", \"wb\"))  |> \n  relocate(iso3c, .after = vdem_ctry_id)\n\nglimpse(democracy)\n\nRows: 5,667\nColumns: 7\n$ country      <chr> \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico‚Ä¶\n$ vdem_ctry_id <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ iso3c        <chr> \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"‚Ä¶\n$ year         <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199‚Ä¶\n$ polyarchy    <dbl> 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0‚Ä¶\n$ gdp_pc       <dbl> 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1‚Ä¶\n$ region       <chr> \"Latin America\", \"Latin America\", \"Latin America\", \"Latin‚Ä¶\n\n#filter(democracy, is.na(iso3c))"
  },
  {
    "objectID": "modules/module-1.1.html#downloading-world-bank-data-into-a-flat-file",
    "href": "modules/module-1.1.html#downloading-world-bank-data-into-a-flat-file",
    "title": "Module 1.1",
    "section": "Downloading World Bank data into a flat file",
    "text": "Downloading World Bank data into a flat file\n\nGo to the World Development Indicators portal at the World Bank‚Äôs Data Bank.\nUnder Countries, select the Countries tab and then select the little check mark ‚òëÔ∏è to select all of the countries. Be sure to select the Countries tab first, though, or you will also be downloading aggregate data for regions and groups of countries.\nNext, under Series, search for ‚Äúlabor force participation‚Äù and find labor force participation rates for women ages 15-64 (ILO modeled estimates). Check that series.\nNow go to Time and select the years from the last 50 years. Click Apply Changes, go to Download Options and download as a .csv file. Place the .csv file in the data directory that you created for this module. Save it as ‚Äúmessy_wb_data.csv‚Äù or something like that."
  },
  {
    "objectID": "modules/module-1.1.html#reading-data-from-a-flat-file",
    "href": "modules/module-1.1.html#reading-data-from-a-flat-file",
    "title": "Module 1.1",
    "section": "Reading data from a flat file",
    "text": "Reading data from a flat file\n\nNow we are going to read this messy World Bank data into R using the read_csv() function from the readr package. readr is a collection of functions that parses data from a flat file into a tibble, the modern Tidyverse version of a data frame. After we have read the data into R, we are going to have a look at it with the glimpse() function from the dplyr package.\nglimpse() shows us a list of the columns in the along with their type (e.g.¬†character, double, etc.) and a few rows‚Äô worth of data.\n\n\n\n\n\n\nNote\n\n\n\nWhile comma delimited files are the most common kind of flat file, readr includes functions for parsing files with a wide range of delimiters including tabs (read_tsv()), semicolons (read_csv2()) and white spaces (read_table()). There is also a Tidyverse package for reading in Excel files called readxl.\n\n\n\n# load packages\n\nlibrary(readr) \nlibrary(dplyr) \n\n# read data from csv file into an object called \"wb_data_messy\"\n\nwb_data_messy <- read_csv(\"data/messy_wb_data.csv\")\n\n# view the data\n\nglimpse(wb_data_messy)\n\nRows: 222\nColumns: 54\n$ `Country Name`  <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"American Samoa\",‚Ä¶\n$ `Country Code`  <chr> \"AFG\", \"ALB\", \"DZA\", \"ASM\", \"AND\", \"AGO\", \"ATG\", \"ARG\"‚Ä¶\n$ `Series Name`   <chr> \"Labor force participation rate, female (% of female p‚Ä¶\n$ `Series Code`   <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI‚Ä¶\n$ `1972 [YR1972]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1973 [YR1973]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1974 [YR1974]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1975 [YR1975]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1976 [YR1976]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1977 [YR1977]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1978 [YR1978]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1979 [YR1979]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1980 [YR1980]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1981 [YR1981]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1982 [YR1982]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1983 [YR1983]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1984 [YR1984]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1985 [YR1985]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1986 [YR1986]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1987 [YR1987]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1988 [YR1988]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1989 [YR1989]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1990 [YR1990]` <chr> \"15.83\", \"60.63\", \"12.31\", \"..\", \"..\", \"76.73\", \"..\", ‚Ä¶\n$ `1991 [YR1991]` <chr> \"15.89\", \"65.54\", \"12.33\", \"..\", \"..\", \"76.69\", \"..\", ‚Ä¶\n$ `1992 [YR1992]` <chr> \"15.92\", \"66.56\", \"12.37\", \"..\", \"..\", \"76.66\", \"..\", ‚Ä¶\n$ `1993 [YR1993]` <chr> \"15.91\", \"65.01\", \"12.41\", \"..\", \"..\", \"76.68\", \"..\", ‚Ä¶\n$ `1994 [YR1994]` <chr> \"15.88\", \"63.64\", \"12.47\", \"..\", \"..\", \"76.64\", \"..\", ‚Ä¶\n$ `1995 [YR1995]` <chr> \"15.92\", \"61.59\", \"12.56\", \"..\", \"..\", \"76.57\", \"..\", ‚Ä¶\n$ `1996 [YR1996]` <chr> \"15.75\", \"60.28\", \"12.64\", \"..\", \"..\", \"76.55\", \"..\", ‚Ä¶\n$ `1997 [YR1997]` <chr> \"15.59\", \"61.91\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1998 [YR1998]` <chr> \"15.47\", \"60.62\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1999 [YR1999]` <chr> \"15.4\", \"58.87\", \"12.63\", \"..\", \"..\", \"76.51\", \"..\", \"‚Ä¶\n$ `2000 [YR2000]` <chr> \"15.35\", \"57.89\", \"12.71\", \"..\", \"..\", \"76.49\", \"..\", ‚Ä¶\n$ `2001 [YR2001]` <chr> \"15.5\", \"56.71\", \"12.85\", \"..\", \"..\", \"76.48\", \"..\", \"‚Ä¶\n$ `2002 [YR2002]` <chr> \"15.7\", \"56.06\", \"13.02\", \"..\", \"..\", \"76.44\", \"..\", \"‚Ä¶\n$ `2003 [YR2003]` <chr> \"15.92\", \"55.3\", \"13.24\", \"..\", \"..\", \"76.41\", \"..\", \"‚Ä¶\n$ `2004 [YR2004]` <chr> \"16.13\", \"54.57\", \"13.5\", \"..\", \"..\", \"76.38\", \"..\", \"‚Ä¶\n$ `2005 [YR2005]` <chr> \"16.33\", \"53.88\", \"13.79\", \"..\", \"..\", \"76.36\", \"..\", ‚Ä¶\n$ `2006 [YR2006]` <chr> \"16.12\", \"53.43\", \"14.12\", \"..\", \"..\", \"76.39\", \"..\", ‚Ä¶\n$ `2007 [YR2007]` <chr> \"15.91\", \"53.07\", \"14.47\", \"..\", \"..\", \"76.42\", \"..\", ‚Ä¶\n$ `2008 [YR2008]` <chr> \"15.74\", \"52.78\", \"14.87\", \"..\", \"..\", \"76.46\", \"..\", ‚Ä¶\n$ `2009 [YR2009]` <chr> \"15.65\", \"51.57\", \"15.31\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `2010 [YR2010]` <chr> \"15.65\", \"52.75\", \"15.49\", \"..\", \"..\", \"76.59\", \"..\", ‚Ä¶\n$ `2011 [YR2011]` <chr> \"16\", \"60.59\", \"16.45\", \"..\", \"..\", \"76.67\", \"..\", \"55‚Ä¶\n$ `2012 [YR2012]` <chr> \"16.44\", \"55.1\", \"17.48\", \"..\", \"..\", \"76.73\", \"..\", \"‚Ä¶\n$ `2013 [YR2013]` <chr> \"17.42\", \"50.58\", \"18.29\", \"..\", \"..\", \"76.79\", \"..\", ‚Ä¶\n$ `2014 [YR2014]` <chr> \"18.46\", \"50.18\", \"16.68\", \"..\", \"..\", \"76.83\", \"..\", ‚Ä¶\n$ `2015 [YR2015]` <chr> \"19.55\", \"54.05\", \"17.5\", \"..\", \"..\", \"76.87\", \"..\", \"‚Ä¶\n$ `2016 [YR2016]` <chr> \"20.7\", \"56.4\", \"18.33\", \"..\", \"..\", \"76.9\", \"..\", \"56‚Ä¶\n$ `2017 [YR2017]` <chr> \"21.91\", \"55.54\", \"19.19\", \"..\", \"..\", \"76.91\", \"..\", ‚Ä¶\n$ `2018 [YR2018]` <chr> \"22.32\", \"59.12\", \"18.95\", \"..\", \"..\", \"76.9\", \"..\", \"‚Ä¶\n$ `2019 [YR2019]` <chr> \"22.74\", \"61.46\", \"18.7\", \"..\", \"..\", \"76.88\", \"..\", \"‚Ä¶\n$ `2020 [YR2020]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `2021 [YR2021]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶"
  },
  {
    "objectID": "modules/module-1.1.html#reshaping-data",
    "href": "modules/module-1.1.html#reshaping-data",
    "title": "Module 1.1",
    "section": "Reshaping data",
    "text": "Reshaping data\n\nThere are a few things about the data here that make it messy. First, in order for the data to be tidy, we want each column to represent a variable and each row to represent an observation.\nBut here we see the reverse: the data are in wide form, meaning that each column represents a year and each row represents a country. This entails that each row represents multiple observations in that we have data for multiple years for each row.\nTo rectify this, we need to reshape the data from wide form to long form. For this, we need the pivot_longer() function from the tidyr package.\nThe pivot_longer() function takes three basic arguments:\n\ncols - which columns you want to pivot\nnames_to - what you want the column with the transposed data to be called\nvalues_to - what you want the column with the values from the transposed data to be called\n\nIn our case, we want to reshape all of the year columns and have the years represented in the rows. We want the newly created column to be called ‚Äúyear‚Äù and the values are going to represent the data on female labor force participation we downloaded (flfp).\n\n# load tidyr\n\nlibrary(tidyr)\n\nwb_data <- wb_data_messy |> # take wb_data_messy, and put it in wb_data, but first...\n  pivot_longer(             # pivot the data from wide to long form\n    cols = `1972 [YR1972]`: `2021 [YR2021]`, # columns to pivot (will create two columns)\n    names_to = \"year\", # name the first column \"year\" (tells us what year the data is for)\n    values_to = \"flfp\" # name the second column \"flfp\" (contains values for each year)\n  ) \n\n# view the data\n\nglimpse(wb_data)\n\nRows: 11,100\nColumns: 6\n$ `Country Name` <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist‚Ä¶\n$ `Country Code` <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",‚Ä¶\n$ `Series Name`  <chr> \"Labor force participation rate, female (% of female po‚Ä¶\n$ `Series Code`  <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.‚Ä¶\n$ year           <chr> \"1972 [YR1972]\", \"1973 [YR1973]\", \"1974 [YR1974]\", \"197‚Ä¶\n$ flfp           <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"‚Ä¶\n\n\n\n\n\n\n\n\nThe Pipe Operator\n\n\n\nFor our pivot-longer() call we used R‚Äôs native pipe operator, e.g.¬†|>. Pipes tell R to do something to the object that they are attached to. In this case, we are telling R to apply pivot_longer() to wb_data. The alternative way of writing this code would be to include the data as the first argument in the function, e.g.¬†pivot_longer(wb_data, cols = ..., names_to = ... , values_to = ...). As you will see, pipe operators enable us to string together multiple functions in a convenient way to transform our data.\n\n\n\n\n\n\n\n\nSpaces in Variable Names\n\n\n\nNotice that when we specify the years in our pivot_longer() call we encapsulate them in backticks (``). This is because the years, as they were imported from the WDI dataset, have spaces in them. Typically we want to avoid this scenario by writing our variable names in snake_case."
  },
  {
    "objectID": "modules/module-1.1.html#truncating-strings-and-changing-variable-types",
    "href": "modules/module-1.1.html#truncating-strings-and-changing-variable-types",
    "title": "Module 1.1",
    "section": "Truncating strings and changing variable types",
    "text": "Truncating strings and changing variable types\n\nNow that our data are transposed, we can start to work on some other key issues. Notice that the year is stored in the weird way in which it was imported‚Äìas a character (or string) with both the year and the year in brackets, e.g.¬†1972 [YR1972]. Notice that flfp is also stored as a character whereas it should be numeric.\nTo fix this, we will use the mutate() and mutate_at() functions from dplyr. mutate() is used to transform variables and to create new ones while mutate_at() allow us to transform multiple columns at once.\nFirst we call mutate() along with substring() to truncate the year variable to only include the first four characters of the string. Then we call mutate_all() along with as.numeric to transform year and flfp to numeric variables.\n\nwb_data <- wb_data |> # replace wb_data with a modified version of the dataframe \n  mutate(year = substring(year, 1, 4)) |> # truncate year, keep first four characters of the string\n  mutate_at(c(\"year\", \"flfp\"), as.numeric) # change year and flfp to numeric\n\n# view data\n\nglimpse(wb_data)\n\nRows: 11,100\nColumns: 6\n$ `Country Name` <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist‚Ä¶\n$ `Country Code` <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",‚Ä¶\n$ `Series Name`  <chr> \"Labor force participation rate, female (% of female po‚Ä¶\n$ `Series Code`  <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.‚Ä¶\n$ year           <dbl> 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1‚Ä¶\n$ flfp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶"
  },
  {
    "objectID": "modules/module-1.1.html#cleaning-variable-names",
    "href": "modules/module-1.1.html#cleaning-variable-names",
    "title": "Module 1.1",
    "section": "Cleaning variable names",
    "text": "Cleaning variable names\n\nThe last thing we are going to do is to fix the variable names. Specifically, we want to remove the spaces from the remaining variables and conver them from title case to snake case. To do this, we will use the clean_names() function from the janitor package.\nAs a final step, we can export our clean data to a new .csv file with the write.csv() function from readr.\n\n# load janitor\n\nlibrary(janitor)\n\n# apply clean_names() to wb_data, store in new data frame called wb_data_clean\n\nwb_data_clean <- wb_data |>  \n  clean_names() \n\n# write wb_data_clean to a csv file\n\nwrite_csv(wb_data_clean, \"data/wb_data_clean.csv\")\n\n# view data\n\nglimpse(wb_data_clean)\n\nRows: 11,100\nColumns: 6\n$ country_name <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan‚Ä¶\n$ country_code <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"‚Ä¶\n$ series_name  <chr> \"Labor force participation rate, female (% of female popu‚Ä¶\n$ series_code  <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE‚Ä¶\n$ year         <dbl> 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 198‚Ä¶\n$ flfp         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#add-country-codes-to-a-dataframe",
    "href": "modules/module-1.2.html#add-country-codes-to-a-dataframe",
    "title": "Module 1.2",
    "section": "Add country codes to a dataframe",
    "text": "Add country codes to a dataframe\n\nlibrary(countrycode)\n\ndemocracy <- democracy |> \n  mutate(iso3c = countrycode(vdem_ctry_id, \"vdem\", \"wb\"))  |> \n  relocate(iso3c, .after = vdem_ctry_id)\n\n#filter(democracy, is.na(iso3c))\n\nglimpse(democracy)\n\nRows: 5,667\nColumns: 7\n$ country      <chr> \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico‚Ä¶\n$ vdem_ctry_id <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ iso3c        <chr> \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"‚Ä¶\n$ year         <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199‚Ä¶\n$ polyarchy    <dbl> 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0‚Ä¶\n$ gdp_pc       <dbl> 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1‚Ä¶\n$ region       <chr> \"Latin America\", \"Latin America\", \"Latin America\", \"Latin‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#add-country-codes-to-a-data-frame",
    "href": "modules/module-1.2.html#add-country-codes-to-a-data-frame",
    "title": "Module 1.2",
    "section": "Add country codes to a data frame",
    "text": "Add country codes to a data frame\n\nOne common problem scholars face when they want to analyze country-level data is the fact that datasets use different country codes. This can make it challenging to combine datasets, thus limiting the potential scope of our analysis. Lucikly, there is a wonderful package called countrycode that can help to solve this problem.\nThe countrycode() function creates a new country code variable in our dataset that matches the country code variable of the second dataset that we are trying to merge it to. countrycode() takes three arguments: sourcevar; origin; and destination. sourcevar identifies the name of the column that you want to transform, origin is the coding system that you want to translate from, and destination is the coding system that you want to translate to.\nIn this next step of our analysis, we are going to join the data the World Bank and V-Dem data that we wrangled into a single dataset. To do that we need a common country code. The way we are going to do this is to create a new country code variable in the democracy dataset that matches the one in the women‚Äôs empowerment dataset.\nLet‚Äôs create a new version of our democracy dataset where we add a variable called iso3c. We will call mutate() to create the variable and wrap the countrycode() call inside of that. The sourcevar that we want to transform is the vdem_ctry_id, the origin code is ‚Äúvdem‚Äù, and the destination code is ‚Äúwb‚Äù.\nWe are also going to pipe in a relocate() call which simply moves the new iso3c column from the end of the data frame (where R automically drops it) so that it sits right next to vdem_ctry_cd. This is not essential but it is always good to keep our data frames looking nice and neat!.\n\nlibrary(countrycode)\n\ndemocracy <- democracy |> \n  mutate(iso3c = countrycode(sourcevar = vdem_ctry_id, origin = \"vdem\", destination = \"wb\"))  |> \n  relocate(iso3c, .after = vdem_ctry_id)\n\n#filter(democracy, is.na(iso3c))\n\nglimpse(democracy)\n\nRows: 5,667\nColumns: 7\n$ country      <chr> \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico‚Ä¶\n$ vdem_ctry_id <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ iso3c        <chr> \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"‚Ä¶\n$ year         <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199‚Ä¶\n$ polyarchy    <dbl> 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0‚Ä¶\n$ gdp_pc       <dbl> 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1‚Ä¶\n$ region       <chr> \"Latin America\", \"Latin America\", \"Latin America\", \"Latin‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#group-summarize-and-arrange",
    "href": "modules/module-1.2.html#group-summarize-and-arrange",
    "title": "Module 1.2",
    "section": "Group, summarize and arrange",
    "text": "Group, summarize and arrange\n\nNow that we have completed all of the wrangling, let‚Äôs do something with it. A common sequence in data science is group by(), summarize() and arrange(). First, we group the data by certain value or category. Then we summarize it by applying a function like min(), max(), mean(), median() or sd(). Finally, we order the data according to column values.\nLet‚Äôs go ahead and apply our three new verbs to the dem_women data frame and store the resulting new data frame in an object called dem_summary. We will group the data by region, take the mean of each variable, and sort the data in descending order based on the regions‚Äô polyarchy scores. Then we will print the object to view its contents. Along the way, we let‚Äôs also export the data to a .csv file for future use.\n\n\n\n\n\n\nNote\n\n\n\n\n\nTo print an object in R, we can either use the print() function or just execute the name of the object. Oftentimes it is simpler to just execute the name of the object.\n\n\n\n\ndem_summary <- dem_women |> \n  group_by(region)  |> \n  summarize(\n    polyarchy = mean(polyarchy, na.rm = TRUE),\n    gdp_pc = mean(gdp_pc, na.rm = TRUE), \n    flfp = mean(flfp, na.rm = TRUE), \n    women_rep = mean(women_rep, na.rm = TRUE)\n  ) |> \n  arrange(desc(polyarchy)) \n\nwrite_csv(dem_summary, \"data/dem_summary.csv\")"
  },
  {
    "objectID": "zzz.html",
    "href": "zzz.html",
    "title": "Additional Dependencies",
    "section": "",
    "text": "/modules/webr-serviceworker.js\n/modules/webr-worker.js"
  },
  {
    "objectID": "modules/module-2.1.html",
    "href": "modules/module-2.1.html",
    "title": "Module 2.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall the scales package (install.packages(\"scales\"))\nHave a look at the documentation for ggplot2\nFamiliarize yourself with the ggplot2 cheatseet\nGenerate a quarto document named ‚Äúmodule-2.1.qmd‚Äù so that you can code along with me\n\nIf you have installed the Tidyverse, then you should already have the packages for this model, including ggplot2. You can go ahead and load ggplot2 along with readr and dplyr.\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nNote that you could also load these three packages by running library(tidyverse). However, it is good to be intentional about which packages we are loading as we are learning them."
  },
  {
    "objectID": "modules/module-2.1.html#bar-charts",
    "href": "modules/module-2.1.html#bar-charts",
    "title": "Module 2.1",
    "section": "Bar charts",
    "text": "Bar charts\n\nLet‚Äôs get started with our first visualization‚Äìa basic bar chart. Bar charts are good for comparing data across cases. Our aim here is going to be to summarize levels of democracy across different regions like we did in the last lesson, but this time we will illustrate the differences with a chart.\nWe will start by loading in the dem_summary.csv file that we made in the last lesson. Next we will do our first ggplot() call. The ggplot() function takes two arguments: data and mapping. data refers to the data frame that includes the variables we want to visualize and mapping refers to the aesthetics mappings for the visualization. The aesthetics mappings are themselves presented in a quoting function aes() that defines the x and y values of the plot along with other aesthetic values like fill, color and linetype. We will focus on x and y values here and return to these additional aesthetic values later.\nAfter our ggplot() call, we can add a series of additional functions to define our visualization following a + sign. The most important group are the geoms which will define the basic type of plot we want to make. In this case, we are calling geom_col() for our histogram and specifying that the fill color should be ‚Äústeelblue.‚Äù\nFrom there we will further customize our visualization with the labs() function to provide a title, axis labels and a caption.\n\ndem_summary <- read_csv(\"data/dem_summary.csv\")\n\nggplot(dem_summary, aes(x = region, y = polyarchy)) +\n  geom_col(fill = \"steelblue\") + \n  labs(\n    x = \"Region\", \n    y = \"Avg. Polyarchy Score\", \n    title = \"Democracy by region, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )\n\n\n\n\nThis looks pretty good but frequently we would want the bars of our bar chart to be sorted in order of the values being displayed. Let‚Äôs go ahead and add the reorder() function to our aes() call so that we are reordering the bars based on descending values of the average polyarchy score.\n\nggplot(dem_summary, aes(x = reorder(region, -polyarchy), y = polyarchy)) +\n  geom_col(fill = \"steelblue\") + \n  labs(\n    x = \"Region\", \n    y = \"Avg. Polyarchy Score\", \n    title = \"Democracy by region, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )"
  },
  {
    "objectID": "modules/module-2.1.html#histograms",
    "href": "modules/module-2.1.html#histograms",
    "title": "Module 2.1",
    "section": "Histograms",
    "text": "Histograms\n\nNow let‚Äôs do another ggplot() call to make a histogram. We use histograms when we want to show how our data are distributed.\nWe‚Äôll start by reading in the dem_women.csv file from our previous lesson. From there, we call ggplot(), specifying the polyarchy score on x-axis. But this time we change the geom to geom_histogram(). We also change the title and axis labels to reflect the fact that we are plotting the number of cases falling in each bin.\n\n\n\n\n\n\nNote\n\n\n\nNote that we leave the y-axis blank for the histogram because ggplot will automatically know to plot the number of units in each bin on the y-axis.\n\n\n\ndem_women_2015 <- read_csv(\"data/dem_women.csv\") |> \n  filter(year == 2015) \n\nggplot(dem_women_2015, aes(x = polyarchy)) +\n  geom_histogram(fill = \"steelblue\") + \n  labs(\n    x = \"Polyarchy Score, 2015\", \n    y = \"Count\",\n    title = \"Distribution of democracy, 2015\", \n    caption = \"Source: V-Dem Institute\"\n    )"
  },
  {
    "objectID": "modules/module-2.1.html#line-charts",
    "href": "modules/module-2.1.html#line-charts",
    "title": "Module 2.1",
    "section": "Line charts",
    "text": "Line charts\n\nNow let‚Äôs create a line chart. Line charts are usually the best option when we want to illustrate trends in our data. For this visualization, we will try to illustrate Samuel Huntington‚Äôs waves of democracy by showing how countries representing each of the three waves. The U.S. represents the first wave, Japan the second wave starting with the allied victory in WWII, and Portugal represents the first country to transition in the third wave.\nFirst, let‚Äôs grab the relevant data using vdemdata and dplyr. We are going to be downloading the polyarchy measure for the U.S., Japan and Portugal as far back as the data are available. So first we will select country name, year and the polyarchy schore and then we will filter the data based on the three country names. We are saving these data in an object called dem_waves_ctrs.\n\nlibrary(vdemdata)\n\ndem_waves_ctrs <- vdem |>\n  select(\n    country = country_name,     \n    year, \n    polyarchy = v2x_polyarchy, \n  ) |>\n  filter(\n    country %in% c(\"United States of America\", \n                   \"Japan\", \n                   \"Portugal\")\n    )\n\n#write_csv(dem_waves_ctrs, \"data/dem_waves_ctrs.csv\")\n\nNext, we are going to do our ggplot() call. The data will be the dem_waves_ctrs object that we just created. For the aesthetics mapping, we will put the year on the x-axis and the polyarchy score on the y-axis. We will also specify color in the aes() call so that we can color the lines by region.\nTo get a line chart, we have to specify geom_line(). Then within the geom_line() function we will set the linewidth equal to ` so that the lines are a bit more visible.\nFinally, we will add a labs() call as with the previous visualizations. But in addition to title, axis labels and a caption, we will also add color = \"Country\" to change the label of the legend to ‚ÄúColor‚Äù with a capital ‚ÄúC.‚Äù\n\nggplot(dem_waves_ctrs, aes(x = year, y = polyarchy, color = country)) +\n  geom_line(linewidth = 1) + \n  labs(\n    x = \"Year\", \n    y = \"Polyarchy Score\", \n    title = 'Democracy in countries representing three different \"waves\"', \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\"\n  )"
  },
  {
    "objectID": "modules/module-2.1.html#scatter-plots",
    "href": "modules/module-2.1.html#scatter-plots",
    "title": "Module 2.1",
    "section": "Scatter plots",
    "text": "Scatter plots\n\nThe last thing we are going to do in this lesson is to create a scatter plot. We use scatter plots in order to illustrate how two variables relate to each other (or not). In this example, we are going to illustrating modernization theory, which predicts a positive relationship between wealth and democracy, while also incorporating levels of women‚Äôs representation into our analysis.\nWe are going to start with the dem_women.csv file we created in Module 1.2. We will then group the data by country and calculate the mean for each variable. Note that in the group_by() call we also include region because we will want to keep it so that we can color our points by region. Let‚Äôs also save this data frame as a .csv file for later use.\n\ndem_summary_ctry <- read_csv(\"data/dem_women.csv\") |>\n  group_by(country, region) |>\n  summarize(\n    polyarchy = mean(polyarchy, na.rm = TRUE),\n    gdp_pc = mean(gdp_pc, na.rm = TRUE), \n    flfp = mean(flfp, na.rm = TRUE), \n    women_rep = mean(women_rep, na.rm = TRUE)\n  )\n\nwrite_csv(dem_summary_ctry, \"data/dem_summary_ctry.csv\")\n\nNow let‚Äôs create our first scatter plot. Our ggplot() call looks similar to previous ones except for a few things. First we are calling geom_point() for our geom. But also notice that our aesthetics mapping includes four dimenstions: x, y, color and size. So here we are telling ggplot2 that we want wealth on the x-axis, the polyarchy score on the y-axis, to color the points based on region, and to vary the size of the points in relation to the level of women‚Äôs representation.\nOne last thing we want to do is to put our x-axis on a log scale and change the labels to reflect their dollar values. For the log scale, we can use the scale_x_log10() function and for the labels we can use the label_number() function from the scales package. We set the prefix to ‚Äú$‚Äù and the suffix to ‚Äúk‚Äù so that each number on the x-axis starts with a dollar sign and ends with ‚Äúk‚Äù denoting ‚Äúthousands.‚Äù\n\n\n\n\n\n\nNote\n\n\n\nWe will encounter other useful scales functions including label_dollar() and label_percent() in future lessons.\nNotice that in this example we introduce the scales package by including it as a prefix to the label_number() function, e.g.¬†scales::label_number(prefix = \"$\", suffix = \"k\"). This allows us to use the package without having to load it, e.g.¬†library(scales). It also has the benefit of generating a list of auto-complete suggestions for the many available functions in the scales package.\n\n\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy, color = region, size = women_rep)) + \n  geom_point() +\n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Region\",\n    size = \"Women Reps\"\n    )\n\n\n\n\nThe plot does a good job of illustrating the basic point of modernization theory in that we do see the positive correlation between wealth and democracy. But we also see that there are some outliers and that a lot of the outlier countries are concentrated in the Middle East.\nWe also see that the distribution of women‚Äôs representation is somewhat orthogonal to wealth and democracy. Most wealthy western countries have high levels of women‚Äôs representation, but so do a lot of low- and middle-income countries in Africa, Asia and Latin America.\n\nAdding a trend line\nWe can definitely see a relationship between wealth and democracy in the scatter plot, but how strong is it? One way to find out is to add a trend line. Let‚Äôs do this by adding another geom, geom_smooth(), and specifying a linear model with the argument method = \"lm\" We acn also set the linewidth of the trend line to 1 so that the line is more visible.\nIf we want to add a single trend while also maintaining the coloring by region, then we have to reconfigure the ggplot() call a bit. Specifically, we will want to move color = region to a separate aes() call in the geom_point() function, e.g.¬†geom_point(aes(color = region)). If we don‚Äôt do this we will get separate trend lines for each region (try it and see!).\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy)) + \n  geom_point(aes(color = region)) + \n  geom_smooth(method = \"lm\", linewidth = 1) + \n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Region\"\n    )"
  },
  {
    "objectID": "exercises/exercise-1.2.html",
    "href": "exercises/exercise-1.2.html",
    "title": "Exercise 1.2",
    "section": "",
    "text": "Loading webR..."
  },
  {
    "objectID": "exercises/exercise-1.2.html#questions",
    "href": "exercises/exercise-1.2.html#questions",
    "title": "Exercise 1.2",
    "section": "Questions",
    "text": "Questions\n\nTry summarizing the data with a different function for one or more of the variables.\n\n\nWhat is the median value of polyarchy for The West?\nWhat is the max value of gdp_pc for Eastern Europe?\nWhat is the standard deviation of flfp for Africa?\nWhat is the interquartile range of women_rep for the Middle East?\n\n\nNow try grouping by country instead of region.\n\n\nWhat is the median value of polyarchy for Sweden?\nWhat is the max value of gdp_pc New Zealand?\nWhat is the standard deviation of flfp for Spain?\nWhat is the interquartile range of women_rep for Germany?\n\n\nSort countries in descending order based on the mean value of gdp_pc (instead of polyarchy). Which country ranks first based on this sorting?\nNow try sorting countries in ascending order based on the median value of women_rep (hint: delete ‚Äúdesc‚Äù from the arrange() call). Which countries rank ‚Äúhighest‚Äù in this sorting?"
  },
  {
    "objectID": "exercises/zzz.html",
    "href": "exercises/zzz.html",
    "title": "Additional Dependencies",
    "section": "",
    "text": "/exercises/webr-serviceworker.js\n/exercises/webr-worker.js"
  },
  {
    "objectID": "modules/module-2.2.html",
    "href": "modules/module-2.2.html",
    "title": "Module 2.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall plotly (install.packages(\"plotly\")) and have a look at the documentation\nInstall (colorBlindness Guide) install.packages(\"colorBlindness\") and read this vignette\nGenerate a quarto document named ‚Äúmodule-2.2.qmd‚Äù in your ‚Äúmodules‚Äù project folder so that you can code along with me\nIn your quarto document, run these code chunks and familiarize yourself the data frames that they generate\n\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(wbstats)\nlibrary(countrycode)\n\nindicators = c(flfp = \"SL.TLF.CACT.FE.ZS\", gdp_pc = \"NY.GDP.PCAP.KD\") # define indicators\n\n## Regional levels of FLFP for column chart \n\nflfp_gdp_regions <- \n  wb_data(\"SL.TLF.CACT.FE.ZS\", country = \"regions_only\", mrnev = 1) |> \n  rename(\n    region = country,\n    year = date,\n    flfp = SL.TLF.CACT.FE.ZS\n  ) |> \n  select(region, iso3c, year, flfp)\n  \nflfp_gdp_regions\n\n# A tibble: 7 √ó 4\n  region                     iso3c  year  flfp\n  <chr>                      <chr> <dbl> <dbl>\n1 East Asia & Pacific        EAS    2021  58.9\n2 Europe & Central Asia      ECS    2021  51.6\n3 Latin America & Caribbean  LCN    2021  49.8\n4 Middle East & North Africa MEA    2021  18.2\n5 North America              NAC    2021  56.1\n6 South Asia                 SAS    2021  24.8\n7 Sub-Saharan Africa         SSF    2021  60.4\n\n## Cross-section of data on FLFP and GDP per capita for scatter plot\n\nflfp_gdp <- wb_data(indicators, mrnev = 1) |> # download most recent non-missing value of indicators\n    left_join(select(wb_countries(), c(iso3c, region)), by = \"iso3c\")  # add regions from countrycode()\n\nglimpse(flfp_gdp)\n\nRows: 224\nColumns: 7\n$ iso2c   <chr> \"AW\", \"AF\", \"AF\", \"AO\", \"AL\", \"AD\", \"AE\", \"AR\", \"AM\", \"AS\", \"A‚Ä¶\n$ iso3c   <chr> \"ABW\", \"AFG\", \"AFG\", \"AGO\", \"ALB\", \"AND\", \"ARE\", \"ARG\", \"ARM\",‚Ä¶\n$ country <chr> \"Aruba\", \"Afghanistan\", \"Afghanistan\", \"Angola\", \"Albania\", \"A‚Ä¶\n$ date    <dbl> 2021, 2020, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 20‚Ä¶\n$ gdp_pc  <dbl> 30271.8335, NA, 426.0300, 2299.6406, 4830.5963, 36839.8762, 42‚Ä¶\n$ flfp    <dbl> NA, 16.463, NA, 74.464, 51.653, NA, 52.789, 50.283, 57.779, NA‚Ä¶\n$ region  <chr> \"Latin America & Caribbean\", \"South Asia\", \"South Asia\", \"Sub-‚Ä¶\n\n## Time series data on regional trends in FLFP for line chart\n\nflfp_ts <- wb_data(\"SL.TLF.CACT.FE.ZS\", country = \"regions_only\", start_date = 1990, end_date = 2022) |> \n  rename(\n    region = country,\n    year = date,\n    flfp = SL.TLF.CACT.FE.ZS\n  ) |> \n  select(region, iso3c, year, flfp)\n  \nglimpse(flfp_ts)\n\nRows: 224\nColumns: 4\n$ region <chr> \"East Asia & Pacific\", \"East Asia & Pacific\", \"East Asia & Paci‚Ä¶\n$ iso3c  <chr> \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", ‚Ä¶\n$ year   <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 200‚Ä¶\n$ flfp   <dbl> 66.32925, 66.12070, 66.00342, 65.68375, 65.65046, 65.50232, 65.‚Ä¶"
  },
  {
    "objectID": "modules/module-2.2.html#overview",
    "href": "modules/module-2.2.html#overview",
    "title": "Module 2.2",
    "section": "Overview",
    "text": "Overview\nDiscuss some basic principles of design like no more than four lines, arranging bar charts in descending order, etc. Link to a relevant guide."
  },
  {
    "objectID": "modules/module-2.2.html#themes",
    "href": "modules/module-2.2.html#themes",
    "title": "Module 2.2",
    "section": "Themes",
    "text": "Themes\n\nggplot themes\n\nwealth_flfp + scale_color_viridis_d(option = \"plasma\") + theme_dark()\n\n\n\n\n\nflfp_region + scale_fill_brewer(palette = \"YlGn\") + theme_minimal()"
  },
  {
    "objectID": "modules/module-2.2.html#color-schemes",
    "href": "modules/module-2.2.html#color-schemes",
    "title": "Module 2.2",
    "section": "Color Schemes",
    "text": "Color Schemes\n\nHere mention the accessibility checker tools in Windows and OS. Use line chart we did in module 2.1 as an example. At the end of the lesson, ask students to fix it as an exercise.\n\ndem_waves_ctrs <- read_csv(\"data/dem_waves_ctrs.csv\")\n\ndem_waves_chart <- ggplot(dem_waves_ctrs, aes(x = year, y = polyarchy, color = country)) +\n  geom_line(linewidth = 1) + \n  labs(\n    x = \"Year\", \n    y = \"Polyarchy Score\", \n    title = 'Democracy in countries representing three different \"waves\"', \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\"\n  )\n\ndem_waves_chart\n\n\n\n\ncolorBlindness Guide\n\nlibrary(colorBlindness)\n\ncvdPlot(dem_waves_chart)\n\n\n\n\n\nCreate your own colorblind friendly color scheme\n scale_color_manual()\n\ncb_palette <- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nflfp_region <- ggplot(flfp_gdp_regions, aes(x = reorder(iso3c, -flfp), y = flfp, fill = region)) +\n  geom_col() + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(\n    x = \"Region\", \n    y = \"Avg. Female Labor Force Participation\", \n    title = \"Levels of female labor force participation by region\", \n    fill = \"Region\",\n    caption = \"Source: World Bank\"\n    ) \n\nflfp_region + scale_fill_manual(values = cb_palette)\n\n\n\n\n\nflfp_region <- flfp_region + scale_fill_manual(values = cb_palette)\n\ncvdPlot(flfp_region)\n\n\n\n\n\n\nUse Viridis\nviridis()\n\nflfp_region + scale_fill_viridis_d()\n\n\n\n\n\nflfp_region <- flfp_region + scale_fill_viridis_d()\n\ncvdPlot(flfp_region)\n\n\n\n\n\n\nUse R color brewer\ncolor brewer palette selector tool\nShow how it works with YlGn but does not work with with BlGn\n\nflfp_region + scale_fill_brewer(palette = \"YlGn\") # try with BrBG\n\n\n\n\n\nflfp_region <- flfp_region + scale_fill_brewer(palette = \"YlGn\")\n\ncvdPlot(flfp_region)"
  },
  {
    "objectID": "modules/module-2.2.html#annotations",
    "href": "modules/module-2.2.html#annotations",
    "title": "Module 2.2",
    "section": "Annotations",
    "text": "Annotations\n\n\nwealth_flfp <- wealth_flfp + scale_color_viridis_d(option = \"plasma\") + theme_minimal()\n\nwealth_flfp + annotate(\"text\", x = 90000, y = 75, label = \"Wealthy\") + \n  annotate(\"text\", x = 1000, y = 80, label = \"Low income\") +\n  annotate(\"text\", x = 10000, y = 20, label = \"Middle income\")\n\n\n\n\n\nflfp_line <- flfp_line + scale_color_viridis_d() \n\nflfp_line + geom_hline(yintercept=52, linetype=\"dashed\", color = \"red\", size = 1) +\n  annotate(\"text\", x = 1995, y = 55, label = \"Global average\")\n\n\n\n\n\nflfp_line <- flfp_line + scale_color_viridis_d() \n\nflfp_line + geom_vline(xintercept=2020, linetype = \"dashed\", size = 1) +\n  annotate(\"text\", x = 2017, y = 35, label = \"Pandemic\")"
  },
  {
    "objectID": "modules/module-2.2.html#interactivity",
    "href": "modules/module-2.2.html#interactivity",
    "title": "Module 2.2",
    "section": "Interactivity",
    "text": "Interactivity\n\nplotly ggplotly\n\nlibrary(plotly)\n\nggplotly(flfp_line)\n\n\n\n\n\nIn this next one, if you don‚Äôt control the tool tip it looks bad\n\nflfp_region <- flfp_region + scale_fill_brewer(palette = \"YlGn\") + theme_minimal()\n\nggplotly(flfp_region, tooltip = c(\"region\", \"flfp\")) # controlling the tooltip output\n\n\n\n\n\nneed to include aes(label = country) to view country in tool tip. How to add notes and other stuff with layout(annotations = list()).\n\nlibrary(plotly)\n\nwealth_flfp <- ggplot(flfp_gdp, aes(x = gdp_pc, y = flfp)) + \n  geom_point(aes(color = region)) + \n  geom_smooth(method = \"loess\", linewidth = 1) +  \n  scale_x_log10(labels = scales::label_dollar()) + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) + \n  labs(\n    x= \"GDP per Capita\", \n    y = \"Female Labor Force Participation\", \n    title = \"Wealth and female labor force participation\", \n    caption = \"Source: World Bank Development Indicators\", # will not show up!\n    color = \"Region\" \n    ) + \n  scale_color_viridis_d(option = \"plasma\") +\n  theme_minimal() +\n  aes(label = country)  # need so ggplot retains label for plotly\n\nggplotly(wealth_flfp, tooltip = c(\"country\", \"flfp\", \"gdp_pc\")) |> \n  \n  layout(annotations = list(text = \"Source: World Bank Development Indicators\",  \n                            font = list(size = 10), showarrow = FALSE,\n                            xref = 'paper', x = 1.1, xanchor = 'right', xshift = 0,\n                            yref = 'paper', y = -.1, yanchor = 'auto', yshift = 0)) |> \n  # add web address\n  layout(annotations = list(text = \"www.dataviz-gwu.rocks\", \n                            font = list(size = 10, color = 'grey'), showarrow = FALSE,\n                            xref = 'paper', x = .5, xanchor = 'center', xshift = 0,\n                            yref = 'paper', y = 1, yanchor = 'top', yshift = 0))"
  },
  {
    "objectID": "modules/module-2.1.html#overview",
    "href": "modules/module-2.1.html#overview",
    "title": "Module 2.1",
    "section": "Overview",
    "text": "Overview\nLast week we learned how to gather and wrangle data. This week we are going to start visualizing it with the ggplot2. We will learn how to make bar charts, histographs, line charts and scatter plots.\nAlong the way we are going to be talking about the ‚Äúgrammar of graphics‚Äù that ggplot2 is based on. The ‚Äúgg‚Äù in ggplot stands for ‚Äúgrammar of graphics.‚Äù The grammar of graphics is a layered approach to constructing graphs based on a book by Leland Wilkinson.\nThe idea is that each visualization you make is going to contain cerain elements. You will start with some data. Then you will incorporate some ‚Äúaesthetics‚Äù which you can think of as the dimensions of the visualization (x-axis, y-axis and color, size or shapes for additional dimensions). Next you identify a geometric obejct that you want to use such as a bar, a line or a point. From there you can customize various elements of the plot like the title and axis scales and labels."
  },
  {
    "objectID": "modules/module-2.2.html#scale-color-for-scatterplots-an-line-charts",
    "href": "modules/module-2.2.html#scale-color-for-scatterplots-an-line-charts",
    "title": "Module 2.2",
    "section": "Scale color for scatterplots an line charts",
    "text": "Scale color for scatterplots an line charts\n\nwealth_flfp <- ggplot(flfp_gdp, aes(x = gdp_pc, y = flfp)) + # plot gdp_pc vs flfp, store in wealth_flfp \n  geom_point(aes(color = region)) + # add an aesthetic to color points by region\n  geom_smooth(method = \"loess\", linewidth = 1) +  # make the line a loess curve\n  scale_x_log10(labels = scales::label_dollar()) + # stretch x- axis, add '$' format\n  scale_y_continuous(labels = scales::label_percent(scale = 1)) + # add % label to y-axis\n  labs(\n    x= \"GDP per Capita\", # x-axis title\n    y = \"Female Labor Force Participation\", # y-axis title\n    title = \"Wealth and female labor force participation\", # plot title\n    caption = \"Source: World Bank Development Indicators\", # caption\n    color = \"Region\" # legend title\n    )\n\nwealth_flfp + scale_color_viridis_d(option = \"plasma\")\n\n\n\n\n\nflfp_line <- ggplot(flfp_ts, aes(x = year, y = flfp, color = region)) +\n  geom_line(linewidth = 1) + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(\n    x = \"Year\", \n    y = \"Female Labor Force Participation\", \n    title = \"Regional trends in female labor force participation\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\"\n  )\n\nflfp_line + scale_color_brewer(palette = \"RdYlBu\")"
  },
  {
    "objectID": "modules/module-3.1.html",
    "href": "modules/module-3.1.html",
    "title": "Module 3.1",
    "section": "",
    "text": "Optional: install magick and underlying file system to remove whitespace around maps\n\n\n# create a hook to crop maps as recommended by pmassicotte\n# must have `magick` and its dependencies installed\n\nknitr::knit_hooks$set(crop = knitr::hook_pdfcrop)"
  },
  {
    "objectID": "modules/module-3.1.html#make-a-map-with-geom_sf",
    "href": "modules/module-3.1.html#make-a-map-with-geom_sf",
    "title": "Module 3.1",
    "section": "Make a map with geom_sf()",
    "text": "Make a map with geom_sf()\n\nlibrary(ggplot2)\n\nggplot(data = world_map_df) +\n  geom_sf(aes(fill = as.factor(income_grp))) + \n  labs(title = \"World Bank country income categories\")"
  },
  {
    "objectID": "modules/module-3.1.html#beautify-your-map",
    "href": "modules/module-3.1.html#beautify-your-map",
    "title": "Module 3.1",
    "section": "Beautify your map",
    "text": "Beautify your map\n\nlibrary(ggthemes)\n\nggplot(data = world_map_df) +\n  geom_sf(aes(fill = as.factor(income_grp))) + \n  labs(\n    title = \"World Bank country income categories\",\n    fill = \"Category\"\n    ) +\n    theme_map() + \n    scale_fill_viridis_d()"
  },
  {
    "objectID": "modules/module-3.1.html#merging-rnaturalearth-with-other-data",
    "href": "modules/module-3.1.html#merging-rnaturalearth-with-other-data",
    "title": "Module 3.1",
    "section": "Merging rnaturalearth with other data",
    "text": "Merging rnaturalearth with other data\nWe are going to use iso2c to do the merge\n\nlibrary(wbstats)\n\noil_rents_df <- wb_data(c(oil_rents_gdp = \"NY.GDP.PETR.RT.ZS\"), mrnev = 1) \n\nrents_map_df <- left_join(world_map_df, oil_rents_df, join_by(iso_a2 == iso2c))\n\nrents_map_df |>\n  select(last_col(5):last_col()) |> #select last 5 columns of df\n  glimpse() \n\nRows: 232\nColumns: 6\n$ date          <dbl> 2020, 2020, 2018, 2020, 2014, NA, 2020, 2020, 2020, 2020‚Ä¶\n$ oil_rents_gdp <dbl> 0.0000000, 0.0000000, 4.5313107, 0.6775696, 11.3636580, ‚Ä¶\n$ obs_status    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ footnote      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ last_updated  <date> 2023-03-01, 2023-03-01, 2023-03-01, 2023-03-01, 2023-03‚Ä¶\n$ geometry      <MULTIPOLYGON [¬∞]> MULTIPOLYGON (((31.28789 -2..., MULTIPOLYGO‚Ä¶\n\n\n\nggplot(data = rents_map_df) +\n  geom_sf(aes(fill = oil_rents_gdp)) + # change var\n  labs(\n    title = \"Oil rents as a % of GDP\", # change title\n    subtitle = \"(Most recent available data)\", # add subtitle\n    fill = \"Percent\", # change legend title\n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(\n    legend.position = \"right\", \n    plot.title = element_text(face = \"bold\") #,\n    #legend.title = element_text(size = 8),\n    #legend.text = element_text(size = 6)\n    ) +\n  scale_fill_viridis_c( # chg from discrete (_d) to continuous (_c)\n      option = \"magma\", #  chg to magma theme\n      labels = scales::label_percent(scale = 1) # add % label for legend\n      )"
  },
  {
    "objectID": "modules/module-3.1.html#same-thing-in-one-long-pipe",
    "href": "modules/module-3.1.html#same-thing-in-one-long-pipe",
    "title": "Module 3.1",
    "section": "same thing in one long pipe",
    "text": "same thing in one long pipe\n\nchange indicator to illustrate ease of making map when code is finished, maybe build an exercise based on that\n\n\nne_countries(scale = \"medium\", returnclass = \"sf\") |> \n  left_join(\n    wb_data(\n      c(oil_rents_gdp = \"NY.GDP.PETR.RT.ZS\"), \n      mrnev = 1\n    ),\n    join_by(iso_a2 == iso2c)\n  ) |> \n  filter(iso_a3 != \"ATA\") |>  # remove Antarctica\n  ggplot(aes(fill = oil_rents_gdp)) +\n  geom_sf() +\n  labs(\n    title = \"Oil rents as a % of GDP\", # change title\n    subtitle = \"(Most recent available data)\", # add subtitle\n    fill = \"Category\", # change legend title\n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(legend.position=\"right\") +\n  scale_fill_viridis_c( # chg from discrete (_d) to continuous (_c)\n    option = \"magma\", #  chg to magma theme\n    labels = scales::label_percent(scale = 1) # add percent label for legend\n    )"
  },
  {
    "objectID": "modules/module-4.2.html",
    "href": "modules/module-4.2.html",
    "title": "Module 4.2",
    "section": "",
    "text": "Use {peacesciencer}, teach broom, regression table package of some sort and coeffplots."
  },
  {
    "objectID": "modules/module-3.1.html#build-your-map-in-one-long-pipe-sequence",
    "href": "modules/module-3.1.html#build-your-map-in-one-long-pipe-sequence",
    "title": "Module 3.1",
    "section": "Build your map in one long pipe sequence",
    "text": "Build your map in one long pipe sequence\n\nchange indicator to illustrate ease of making map when code is finished, maybe build an exercise based on that\n\n\nne_countries(scale = \"medium\", returnclass = \"sf\") |> \n  left_join(\n    wb_data(c(oil_rents_gdp = \"NY.GDP.PETR.RT.ZS\"), mrnev = 1),\n    join_by(iso_a2 == iso2c)\n  ) |> \n  filter(iso_a3 != \"ATA\") |>  # remove Antarctica\n  ggplot(aes(fill = oil_rents_gdp)) +\n  geom_sf() +\n  labs(\n    title = \"Oil rents as a % of GDP\", # change title\n    subtitle = \"(Most recent available data)\", # add subtitle\n    fill = \"Category\", # change legend title\n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(legend.position=\"right\") +\n  scale_fill_viridis_c( # chg from discrete (_d) to continuous (_c)\n    option = \"magma\", #  chg to magma theme\n    labels = scales::label_percent(scale = 1) # add percent label for legend\n    )"
  },
  {
    "objectID": "modules/module-3.2.html",
    "href": "modules/module-3.2.html",
    "title": "Module 3.2",
    "section": "",
    "text": "Install states package. install.packages(\"states\")\nInstall the [leaflet package(http://rstudio.github.io/leaflet/). install.packages(\"leaflet\")\nInstall simple features\nInstall html tools\n\n\nlibrary(states)\n\nsfind(\"Yemen\")[1:6]\n\n    list ccode code3c                   country_name      start        end\n169   GW   678    YEM Yemen (Arab Republic of Yemen) 1918-10-30 9999-12-31\n170   GW   680    YPR    Yemen, People's Republic of 1967-11-30 1990-05-21\n428  COW   678    YAR            Yemen Arab Republic 1926-09-02 1990-05-21\n429  COW   679    YEM                          Yemen 1990-05-22 9999-12-31\n430  COW   680    YPR        Yemen People's Republic 1967-11-30 1990-05-21\n\n\nTell them where you got the data from but don‚Äôt make them download it.\nPrimer on country codes\nUCDP codebook\n\nlibrary(dplyr)\nlibrary(readr)\n\nged_data <- read_csv(\"data/GEDEvent_v22_1_sm.csv\") ## slimmed version\n\nged_yemen_21 <- ged_data |> \n  filter(\n    country_id == 678, #gw country code\n    year == 2021, \n    where_prec < 3, # keep if certain where event occurred\n    event_clarity == 1, # keep if event reporting is clear\n      ) |> \n  mutate(deaths = deaths_a + deaths_b + deaths_civilians + deaths_unknown) |> \n  select(event_id = id, \n         date = date_start,\n         gov_deaths = deaths_a, \n         rebel_deaths = deaths_b, \n         civilian_deaths = deaths_civilians, \n         deaths, \n         where_coordinates,\n         latitude, \n         longitude) |>\n  sf::st_as_sf(coords = c(\"longitude\", \"latitude\")) \n\nglimpse(ged_yemen_21)\n\nRows: 555\nColumns: 8\n$ event_id          <dbl> 410593, 410601, 415966, 419510, 423037, 414170, 3780‚Ä¶\n$ date              <dttm> 2021-04-29, 2021-06-01, 2021-09-29, 2021-10-04, 202‚Ä¶\n$ gov_deaths        <dbl> 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ rebel_deaths      <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ civilian_deaths   <dbl> 0, 0, 0, 0, 0, 1, 6, 1, 1, 1, 1, 1, 1, 1, 5, 1, 0, 2‚Ä¶\n$ deaths            <dbl> 2, 1, 1, 1, 2, 1, 6, 1, 1, 1, 1, 1, 1, 1, 5, 1, 0, 2‚Ä¶\n$ where_coordinates <chr> \"≈¢iyƒÅb town\", \"≈¢iyƒÅb town\", \"RadƒÅ‚Äò town\", \"Dammaj vi‚Ä¶\n$ geometry          <POINT> POINT (45.46916 14.14912), POINT (45.46916 14.1491‚Ä¶"
  },
  {
    "objectID": "modules/module-3.2.html#plot-an-event",
    "href": "modules/module-3.2.html#plot-an-event",
    "title": "Module 3.2",
    "section": "Plot an event",
    "text": "Plot an event\n\nlibrary(leaflet)\n\nsyria_map <- leaflet() %>%\n  addTiles() %>%  # Add default OpenStreetMap map tiles\n  addMarkers(lng = 45.46916, lat = 14.14912, label = \"First conflict event\")\n\nsyria_map"
  },
  {
    "objectID": "modules/module-3.2.html#plot-some-events-from-the-dataframe",
    "href": "modules/module-3.2.html#plot-some-events-from-the-dataframe",
    "title": "Module 3.2",
    "section": "Plot some events from the dataframe",
    "text": "Plot some events from the dataframe\nScroll to the bottom of this page for an explanation of the ~ notation.\n\nleaflet(data = ged_yemen_21[ged_yemen_21$date < \"2021-03-01\", ]) |> # Jan and Feb  \n  addTiles() |> \n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |> # Sana'a coordinates\n  addMarkers(\n    popup = ~as.character(deaths), # here ~ means \n    label = ~where_coordinates\n    )"
  },
  {
    "objectID": "modules/module-3.2.html#use-an-awesome-icon",
    "href": "modules/module-3.2.html#use-an-awesome-icon",
    "title": "Module 3.2",
    "section": "Use an awesome icon",
    "text": "Use an awesome icon\nLibraries include glyphicons, font awesome and ionicons.\n\nicon <- awesomeIcons(\n  icon = \"ios-close\",\n  iconColor = \"black\",\n  markerColor = \"red\", \n  library = \"ion\" # other options include font awesome and ionicons\n)\n\nleaflet(data = ged_yemen_21[ged_yemen_21$date < \"2021-03-01\", ]) |> # Jan and Feb  \n  addTiles() |> \n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |> # Sana'a coordinates\n  addAwesomeMarkers(\n    icon = icon, \n    popup = ~as.character(deaths), \n    label = ~where_coordinates\n    )"
  },
  {
    "objectID": "modules/module-3.2.html#change-content-of-popup",
    "href": "modules/module-3.2.html#change-content-of-popup",
    "title": "Module 3.2",
    "section": "Change content of popup",
    "text": "Change content of popup\n\nged_yemen_21$popup_text <- sprintf(\n      \"Date: %s <br> \n       Total Deaths: %.0f <br> \n       Govt. Deaths: %.0f <br> \n       Rebel Deaths: %.0f <br> \n       Civilian Death: %.0f <br>\",\n      ged_yemen_21$date, \n      ged_yemen_21$deaths, \n      ged_yemen_21$gov_deaths, \n      ged_yemen_21$rebel_deaths,\n      ged_yemen_21$civilian_deaths\n    ) |> lapply(htmltools::HTML)\n\nleaflet(data = ged_yemen_21[ged_yemen_21$date < \"2021-03-01\", ]) |> # Jan and Feb  \n  addTiles() |> \n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |> # Sana'a coordinates\n  addAwesomeMarkers(\n    icon = icon, \n    popup = ~popup_text, \n    label = ~where_coordinates\n    )\n\n\n\n\n\nNow e can check the labels.\n\nged_yemen_21 |>\n  filter(where_coordinates == \"Marib Dam\")\n\nSimple feature collection with 1 feature and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 45.24417 ymin: 15.39639 xmax: 45.24417 ymax: 15.39639\nCRS:           NA\n# A tibble: 1 √ó 9\n  event_id date                gov_deaths rebel_deaths civilian_deaths deaths\n*    <dbl> <dttm>                   <dbl>        <dbl>           <dbl>  <dbl>\n1   385602 2021-02-26 00:00:00         34           27               0     61\n# ‚Ñπ 3 more variables: where_coordinates <chr>, geometry <POINT>,\n#   popup_text <list>"
  },
  {
    "objectID": "modules/module-3.2.html#using-basemaps",
    "href": "modules/module-3.2.html#using-basemaps",
    "title": "Module 3.2",
    "section": "Using basemaps",
    "text": "Using basemaps\navailable basemaps\n\nleaflet(data = ged_yemen_21[ged_yemen_21$date < \"2021-03-01\", ]) |> # Jan and Feb  \n  addProviderTiles(\"OpenTopoMap\") |> # include name of provider here\n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |> # Sana'a coordinates\n  addAwesomeMarkers(\n    icon = icon, \n    popup = ~popup_text, \n    label = ~where_coordinates\n    )\n\n\n\n\n\nNow we can see a bit more about the topography, which could be useful for conflict analysis."
  },
  {
    "objectID": "modules/module-3.1.html#grabbing-country-shapes-from-rnaturalearth",
    "href": "modules/module-3.1.html#grabbing-country-shapes-from-rnaturalearth",
    "title": "Module 3.1",
    "section": "Grabbing country shapes from rnaturalearth",
    "text": "Grabbing country shapes from rnaturalearth\n\nlibrary(rnaturalearth)\nlibrary(dplyr)\n\nworld_map_df <- ne_countries(scale = \"medium\", returnclass = \"sf\") |> \n    filter(iso_a3 != \"ATA\") # remove Antarctica\n\n#world_map_df |>\n  # select and view first 10 columns\n  #select(1:10) |> \n  #glimpse()\n\nworld_map_df |>\n  select(geometry) # view contents of last column of df (geometry)\n\nSimple feature collection with 232 features and 0 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -58.49229 xmax: 180 ymax: 83.59961\nCRS:           +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\nFirst 10 features:\n                         geometry\n1  MULTIPOLYGON (((31.28789 -2...\n2  MULTIPOLYGON (((30.39609 -1...\n3  MULTIPOLYGON (((53.08564 16...\n4  MULTIPOLYGON (((104.064 10....\n5  MULTIPOLYGON (((-60.82119 9...\n6  MULTIPOLYGON (((12.43916 41...\n7  MULTIPOLYGON (((166.7458 -1...\n8  MULTIPOLYGON (((70.94678 42...\n9  MULTIPOLYGON (((-53.37061 -...\n10 MULTIPOLYGON (((162.9832 5...."
  },
  {
    "objectID": "modules/module-3.1.html#turn-your-map-into-a-function",
    "href": "modules/module-3.1.html#turn-your-map-into-a-function",
    "title": "Module 3.1",
    "section": "Turn your map into a function",
    "text": "Turn your map into a function\n\nsave this code as an R. script\n\n\nlibrary(rnaturalearth)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(wbstats)\n\ncreate_map <- function(var_id, title, legend_title, theme, direction){\n\nne_countries(scale = \"medium\", returnclass = \"sf\") |> \n  left_join(\n    wb_data(var_id, mrnev = 1), # change variable id\n    join_by(iso_a2 == iso2c)\n  ) |> \n  filter(iso_a3 != \"ATA\") |>  \n  ggplot() + \n  geom_sf(aes(fill = eval(parse(text=var_id)))) + # remove quotes\n  labs(\n    title =  title, # change title\n    fill = legend_title, # change legend title\n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n  ) +\n  scale_fill_viridis_c( \n    option = \"magma\", #  chg theme\n    direction = direction # change direction of scale\n    )\n}\n\ncreate_map(var_id = \"SL.TLF.CACT.FE.ZS\", \n           title= \"Female Labor Force Participation\", \n           legend_title = \"FLFP %\", \n           theme = \"inferno\", \n           direction = -1)"
  },
  {
    "objectID": "modules/module-3.1.html#use-r-file-as-a-source-in-another-document",
    "href": "modules/module-3.1.html#use-r-file-as-a-source-in-another-document",
    "title": "Module 3.1",
    "section": "Use R file as a ‚Äúsource‚Äù in another document",
    "text": "Use R file as a ‚Äúsource‚Äù in another document\n\nsource(\"functions/wb-maps.R\", local = knitr::knit_global())\n\nNow I write some text here and then I want to show map, so I call the create_map() function that we just made. Let‚Äôs say I want to show a different indicator with a different theme, maybe GDP per capita. Let‚Äôs search for it using the wb_search() tool:\n\nwb_search(\"GDP per capita\") \n\n# A tibble: 24 √ó 3\n   indicator_id       indicator                                   indicator_desc\n   <chr>              <chr>                                       <chr>         \n 1 5.51.01.10.gdp     Per capita GDP growth                       GDP per capit‚Ä¶\n 2 6.0.GDPpc_constant GDP per capita, PPP (constant 2011 interna‚Ä¶ GDP per capit‚Ä¶\n 3 NV.AGR.PCAP.KD.ZG  Real agricultural GDP per capita growth ra‚Ä¶ The growth ra‚Ä¶\n 4 NY.GDP.PCAP.CD     GDP per capita (current US$)                GDP per capit‚Ä¶\n 5 NY.GDP.PCAP.CN     GDP per capita (current LCU)                GDP per capit‚Ä¶\n 6 NY.GDP.PCAP.KD     GDP per capita (constant 2010 US$)          GDP per capit‚Ä¶\n 7 NY.GDP.PCAP.KD.ZG  GDP per capita growth (annual %)            Annual percen‚Ä¶\n 8 NY.GDP.PCAP.KN     GDP per capita (constant LCU)               GDP per capit‚Ä¶\n 9 NY.GDP.PCAP.PP.CD  GDP per capita, PPP (current international‚Ä¶ This indicato‚Ä¶\n10 NY.GDP.PCAP.PP.KD  GDP per capita, PPP (constant 2017 interna‚Ä¶ GDP per capit‚Ä¶\n# ‚Ñπ 14 more rows\n\n\n(Note: For an exercise, you could have students use ChatGPT to create a map function and then tweak it to make it work. You could also have them try using a color brewer them instead of viridis).\nNow let‚Äôs map GDP in constant 2017 international dollars (‚ÄúNY.GDP.PCAP.PP.KD‚Äù) with the mako theme:\n\ncreate_map(var_id = \"NY.GDP.PCAP.PP.KD\", \n           title= \"GDP per capita (constant 2017 internatioal $)\", \n           legend_title = \"Geary-Khamis $\", \n           theme = \"mako\", \n           direction = -1)"
  },
  {
    "objectID": "modules/module-2.2.html#scaling-for-scatterplots-an-line-charts",
    "href": "modules/module-2.2.html#scaling-for-scatterplots-an-line-charts",
    "title": "Module 2.2",
    "section": "Scaling for scatterplots an line charts",
    "text": "Scaling for scatterplots an line charts\nUse ‚Äúscale_color‚Äù instead of ‚Äúscale_fill‚Äù for line charts and scatter plots, e.g.¬†scale_color_manual(), scale_color_viridis_d(), scale_color_brewer.\n\nwealth_flfp <- ggplot(flfp_gdp, aes(x = gdp_pc, y = flfp)) + # plot gdp_pc vs flfp, store in wealth_flfp \n  geom_point(aes(color = region)) + # add an aesthetic to color points by region\n  geom_smooth(method = \"loess\", linewidth = 1) +  # make the line a loess curve\n  scale_x_log10(labels = scales::label_dollar()) + # stretch x- axis, add '$' format\n  scale_y_continuous(labels = scales::label_percent(scale = 1)) + # add % label to y-axis\n  labs(\n    x= \"GDP per Capita\", # x-axis title\n    y = \"Female Labor Force Participation\", # y-axis title\n    title = \"Wealth and female labor force participation\", # plot title\n    caption = \"Source: World Bank Development Indicators\", # caption\n    color = \"Region\" # legend title\n    )\n\nwealth_flfp + scale_color_viridis_d(option = \"plasma\")\n\n\n\n\n\nflfp_line <- ggplot(flfp_ts, aes(x = year, y = flfp, color = region)) +\n  geom_line(linewidth = 1) + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(\n    x = \"Year\", \n    y = \"Female Labor Force Participation\", \n    title = \"Regional trends in female labor force participation\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\"\n  )\n\nflfp_line + scale_color_brewer(palette = \"YlOrRd\")"
  },
  {
    "objectID": "modules/module-2.2.html#interactivity-1",
    "href": "modules/module-2.2.html#interactivity-1",
    "title": "Module 2.2",
    "section": "Interactivity",
    "text": "Interactivity\n\nlibrary(plotly)\n\nwealth_flfp <- ggplot(flfp_gdp, aes(x = gdp_pc, y = flfp)) + \n  geom_point(aes(color = region)) + \n  geom_smooth(method = \"loess\", linewidth = 1) +  \n  scale_x_log10(labels = scales::label_dollar()) + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) + \n  labs(\n    x= \"GDP per Capita\", \n    y = \"Female Labor Force Participation\", \n    title = \"Wealth and female labor force participation\", \n    caption = \"Source: World Bank Development Indicators\", # will not show up!\n    color = \"Region\" \n    ) + \n  scale_color_viridis_d(option = \"plasma\") +\n  theme_minimal() +\n  aes(label = country)  # need so ggplot retains label for plotly\n\nggplotly(wealth_flfp, tooltip = c(\"country\", \"flfp\", \"gdp_pc\")) |> \n  \n  layout(annotations = list(text = \"Source: World Bank Development Indicators\",  \n                            font = list(size = 10), showarrow = FALSE,\n                            xref = 'paper', x = 1.1, xanchor = 'right', xshift = 0,\n                            yref = 'paper', y = -.1, yanchor = 'auto', yshift = 0)) |> \n  # add web address\n  layout(annotations = list(text = \"www.dataviz-gwu.rocks\", \n                            font = list(size = 10, color = 'grey'), showarrow = FALSE,\n                            xref = 'paper', x = .5, xanchor = 'center', xshift = 0,\n                            yref = 'paper', y = 1, yanchor = 'top', yshift = 0))"
  },
  {
    "objectID": "modules/module-4.1.html",
    "href": "modules/module-4.1.html",
    "title": "Module 4.1",
    "section": "",
    "text": "get a us census api key\ninstall tidycensus, install.packages(\"tidycensus\")\n\ntidy census basic usage\nacs table info\n\nlibrary(tidycensus)\ncensus_api_key = my_api_key # enter your census api key here in quotes\n\nView and use the search function in the viewer. Search for ‚Äúhousehold income.‚Äù\n\nv21 <- load_variables(2021, \"acs5\", cache = TRUE)\n\n#View(v21)\n\n\nlibrary(stringr)\nlibrary(dplyr)\n\nquintiles <- get_acs(geography = \"state\", \n                      variables = c(q1 = \"B19081_001\",\n                                    q2 = \"B19081_002\",\n                                    q3 = \"B19081_003\",\n                                    q4 = \"B19081_004\",\n                                    q5 = \"B19081_005\",\n                                    top5 = \"B19081_006\"),\n                      year = 2021,\n                      output = \"wide\") |>\n                      select(\n                        !ends_with(\"m\"), # eliminate margin of error\n                        -GEOID) |> # eliminate geo id\n                      rename(name = NAME) |>\n                      rename_with(~str_remove(., 'E'))\n    \n\nglimpse(quintiles)\n\nRows: 52\nColumns: 7\n$ name <chr> \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colora‚Ä¶\n$ q1   <dbl> 11602, 19344, 15486, 12076, 17433, 18963, 17417, 17052, 12971, 14‚Ä¶\n$ q2   <dbl> 31928, 51030, 40774, 31051, 49234, 49711, 48870, 44638, 51060, 37‚Ä¶\n$ q3   <dbl> 55270, 81169, 66384, 52280, 84658, 80679, 84042, 73187, 94478, 62‚Ä¶\n$ q4   <dbl> 88640, 122652, 102299, 82811, 134560, 123359, 133488, 111915, 157‚Ä¶\n$ q5   <dbl> 193311, 242097, 223521, 188510, 309857, 264516, 319533, 238612, 3‚Ä¶\n$ top5 <dbl> 336788, 394694, 395620, 344470, 555007, 466181, 602707, 420859, 6‚Ä¶"
  },
  {
    "objectID": "modules/module-4.1.html#explore-the-data",
    "href": "modules/module-4.1.html#explore-the-data",
    "title": "Module 4.1",
    "section": "Explore the data",
    "text": "Explore the data\nUse slice to explore data and select some cases.\nWhere do the wealthiest people live?\n\nlibrary(kableExtra)\n\ntop_10 <- quintiles |>\n  slice_max(top5, n = 10)\n\nkable(top_10)\n\n\n\n \n  \n    name \n    q1 \n    q2 \n    q3 \n    q4 \n    q5 \n    top5 \n  \n \n\n  \n    District of Columbia \n    12971 \n    51060 \n    94478 \n    157803 \n    375792 \n    670768 \n  \n  \n    Connecticut \n    17417 \n    48870 \n    84042 \n    133488 \n    319533 \n    602707 \n  \n  \n    New York \n    14054 \n    42220 \n    75647 \n    123318 \n    302676 \n    574063 \n  \n  \n    New Jersey \n    18458 \n    52339 \n    90337 \n    142858 \n    319140 \n    562886 \n  \n  \n    Massachusetts \n    16812 \n    50519 \n    89602 \n    142491 \n    316447 \n    558616 \n  \n  \n    California \n    17433 \n    49234 \n    84658 \n    134560 \n    309857 \n    555007 \n  \n  \n    Maryland \n    19946 \n    55165 \n    91725 \n    140353 \n    293979 \n    503597 \n  \n  \n    Washington \n    19367 \n    50803 \n    82817 \n    127003 \n    277165 \n    487950 \n  \n  \n    Virginia \n    17922 \n    48359 \n    81072 \n    127411 \n    280299 \n    486006 \n  \n  \n    Illinois \n    15102 \n    42688 \n    72900 \n    114531 \n    258373 \n    466713 \n  \n\n\n\n\n\nWhat states have the lowest incomes?\n\nlibrary(kableExtra)\n\nbottom_10 <- quintiles |>\n  slice_min(q1, n = 10)\n\nkable(bottom_10)\n\n\n\n \n  \n    name \n    q1 \n    q2 \n    q3 \n    q4 \n    q5 \n    top5 \n  \n \n\n  \n    Puerto Rico \n    2906 \n    12144 \n    22163 \n    38397 \n    99043 \n    187234 \n  \n  \n    Mississippi \n    10096 \n    27963 \n    49418 \n    80125 \n    175581 \n    308523 \n  \n  \n    Louisiana \n    10371 \n    29781 \n    53925 \n    89536 \n    201514 \n    357026 \n  \n  \n    New Mexico \n    11058 \n    31274 \n    54295 \n    86905 \n    188282 \n    323568 \n  \n  \n    West Virginia \n    11120 \n    29606 \n    51038 \n    81393 \n    174019 \n    299882 \n  \n  \n    Alabama \n    11602 \n    31928 \n    55270 \n    88640 \n    193311 \n    336788 \n  \n  \n    Kentucky \n    11846 \n    32616 \n    55838 \n    88089 \n    194168 \n    350411 \n  \n  \n    Arkansas \n    12076 \n    31051 \n    52280 \n    82811 \n    188510 \n    344470 \n  \n  \n    South Carolina \n    12680 \n    34881 \n    58665 \n    92118 \n    207367 \n    374427 \n  \n  \n    District of Columbia \n    12971 \n    51060 \n    94478 \n    157803 \n    375792 \n    670768 \n  \n\n\n\n\n\nMaybe instead of the following, I could select a stratified random sample of states within each tier.\n\nlibrary(dplyr)\n\n# lowest \nstate_min = quintiles |> \n  slice_min(q1) |>\n  select(name) |>\n  pull() # convert from tibble to vector\n\n# highest\nstate_max = quintiles |> \n  slice_max(top5) |>\n  select(name) |>\n  pull()\n\n# randomly select five more\n\nfive_more = quintiles |>\n  slice_sample(n = 5) |>\n  select(name) |>\n  pull()\n\nstates <- c(state_min, state_max, five_more)\n\nstates\n\n[1] \"Puerto Rico\"          \"District of Columbia\" \"Washington\"          \n[4] \"Idaho\"                \"North Dakota\"         \"Nebraska\"            \n[7] \"Kansas\"              \n\n\n\nstates_data <- quintiles |>\n  filter(name %in% states) |> \n  arrange(desc(top5))\n\nkable(states_data)\n\n\n\n \n  \n    name \n    q1 \n    q2 \n    q3 \n    q4 \n    q5 \n    top5 \n  \n \n\n  \n    District of Columbia \n    12971 \n    51060 \n    94478 \n    157803 \n    375792 \n    670768 \n  \n  \n    Washington \n    19367 \n    50803 \n    82817 \n    127003 \n    277165 \n    487950 \n  \n  \n    Kansas \n    15817 \n    40065 \n    64780 \n    99380 \n    215122 \n    383038 \n  \n  \n    North Dakota \n    15507 \n    41406 \n    68558 \n    104602 \n    217143 \n    380261 \n  \n  \n    Nebraska \n    16506 \n    41590 \n    66977 \n    100910 \n    213091 \n    378679 \n  \n  \n    Idaho \n    16450 \n    40433 \n    63643 \n    95316 \n    203042 \n    360622 \n  \n  \n    Puerto Rico \n    2906 \n    12144 \n    22163 \n    38397 \n    99043 \n    187234"
  },
  {
    "objectID": "modules/module-4.1.html#gt-table",
    "href": "modules/module-4.1.html#gt-table",
    "title": "Module 4.1",
    "section": "GT Table",
    "text": "GT Table\ngt gt reference\n\nlibrary(gt)\n\ngt(states_data) |> \n  tab_header(\n    title = \"Mean Household Income of Quintiles, 2021\",\n    subtitle = \"Seven Representative U.S. States\"\n  ) |> \n  cols_label(\n    name = \"\",\n    q1 = \"lowest\",\n    q2 = \"second\",\n    q3 = \"third\",\n    q4 = \"fourth\",\n    q5 = \"fifth\",\n    top5 = \"top 5%\"\n  ) |> \n  fmt_currency(\n    columns = c(q1, q2, q3, q4, q5, top5),\n    currency = \"USD\", \n    use_subunits = FALSE\n  ) |>\n  # note that you can use markdown (md) to format the source note for html documents\n  tab_source_note(source_note = md(\"**Source**: US Census Bureau, American Community Survey\"))\n\n\n\n\n\n  \n    \n      Mean Household Income of Quintiles, 2021\n    \n    \n      Seven Representative U.S. States\n    \n  \n  \n    \n      \n      lowest\n      second\n      third\n      fourth\n      fifth\n      top 5%\n    \n  \n  \n    District of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\n    New Jersey\n$18,458\n$52,339\n$90,337\n$142,858\n$319,140\n$562,886\n    Utah\n$21,105\n$51,272\n$79,517\n$116,016\n$239,149\n$421,379\n    Wisconsin\n$16,787\n$41,986\n$67,417\n$101,424\n$211,049\n$371,015\n    Montana\n$14,811\n$36,927\n$60,644\n$93,340\n$205,462\n$370,234\n    West Virginia\n$11,120\n$29,606\n$51,038\n$81,393\n$174,019\n$299,882\n    Puerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\n  \n  \n    \n      Source: US Census Bureau, American Community Survey"
  },
  {
    "objectID": "modules/module-4.1.html#plot-confidence-intervals",
    "href": "modules/module-4.1.html#plot-confidence-intervals",
    "title": "Module 4.1",
    "section": "Plot confidence intervals",
    "text": "Plot confidence intervals\nUse median income as example here"
  },
  {
    "objectID": "modules/module-5.1.html#setup",
    "href": "modules/module-5.1.html#setup",
    "title": "Module 5.1",
    "section": "Setup",
    "text": "Setup\n\n# load packages\nlibrary(shiny)\nlibrary(readr)\nlibrary(ggplot2)\n\n# read in data, create a vector of variable names\ndem_data &lt;- read_csv(\"dem_data.csv\")\n\n# create list of named values for the input selection\nvars &lt;- c(\"Democracy\" = \"polyarchy\",\n          \"Clientelism\" = \"clientelism\",\n          \"Corruption\" = \"corruption\",\n          \"Women's Empowerment\" = \"womens_emp\",\n          \"Wealth\" = \"gdp_pc\",\n          \"Infant Mortality\" = \"inf_mort\",\n          \"Life Expectancy\" = \"life_exp\", \n          \"Education\" = \"education\")"
  },
  {
    "objectID": "modules/module-5.1.html#scatter-plot-app",
    "href": "modules/module-5.1.html#scatter-plot-app",
    "title": "Module 5.1",
    "section": "Scatter plot app",
    "text": "Scatter plot app"
  },
  {
    "objectID": "modules/module-5.1.html#ui",
    "href": "modules/module-5.1.html#ui",
    "title": "Module 5.1",
    "section": "ui",
    "text": "ui\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n\n    # Application title\n    titlePanel(\"Democracy and Development\"),\n\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n      sidebarPanel(\n        selectInput('xcol', 'X Variable', vars),\n        selectInput('ycol', 'Y Variable', vars, selected = vars[[6]])\n      ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"scatterplot\")\n        )\n    )\n)"
  },
  {
    "objectID": "modules/module-5.1.html#server",
    "href": "modules/module-5.1.html#server",
    "title": "Module 5.1",
    "section": "Server",
    "text": "Server\n\n# Define server logic required to draw a scatter plot\nserver &lt;- function(input, output, session) {\n  \n  # Combine the selected variables into a new data frame\n\n  \n  # Render the plot\n  output$scatterplot &lt;- renderPlot({\n    \n    selectedData &lt;- dem_data[, c(input$xcol, input$ycol, \"region\")]\n    \n    ggplot(selectedData(), aes_string(x = input$xcol, y = input$ycol)) +\n      geom_point(aes(color = region)) +\n      geom_smooth(method = \"loess\") +\n      scale_color_viridis_d(option = \"plasma\") +\n      theme_minimal() +\n      labs(\n        x =  names(vars[which(vars == input$xcol)]),\n        y =  names(vars[which(vars == input$ycol)]),\n        caption = \"Source: V-Dem Institute\", # caption\n        color = \"Region\" # legend title\n      )\n  })\n}"
  },
  {
    "objectID": "modules/module-5.1.html#call-to-shiny-app",
    "href": "modules/module-5.1.html#call-to-shiny-app",
    "title": "Module 5.1",
    "section": "Call to Shiny app",
    "text": "Call to Shiny app\n\n# See above for the definitions of ui and server\nui &lt;- ...\n\nserver &lt;- ...\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "modules/module-4.1.html#gt-tables",
    "href": "modules/module-4.1.html#gt-tables",
    "title": "Module 4.1",
    "section": "gt tables",
    "text": "gt tables\ngt gt reference\n\nlibrary(gt)\n\ngt(states_data) |> \n  tab_header(\n    title = \"Mean Household Income of Quintiles, 2021\",\n    subtitle = \"Seven Representative U.S. States\"\n  ) |> \n  cols_label(\n    name = \"\",\n    q1 = \"lowest\",\n    q2 = \"second\",\n    q3 = \"third\",\n    q4 = \"fourth\",\n    q5 = \"fifth\",\n    top5 = \"top 5%\"\n  ) |> \n  fmt_currency(\n    columns = c(q1, q2, q3, q4, q5, top5),\n    currency = \"USD\", \n    use_subunits = FALSE\n  ) |>\n  # note that you can use markdown (md) to format the source note for html documents\n  tab_source_note(source_note = md(\"**Source**: US Census Bureau, American Community Survey\"))\n\n\n\n\n\n  \n    \n      Mean Household Income of Quintiles, 2021\n    \n    \n      Seven Representative U.S. States\n    \n  \n  \n    \n      \n      lowest\n      second\n      third\n      fourth\n      fifth\n      top 5%\n    \n  \n  \n    District of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\n    Washington\n$19,367\n$50,803\n$82,817\n$127,003\n$277,165\n$487,950\n    Kansas\n$15,817\n$40,065\n$64,780\n$99,380\n$215,122\n$383,038\n    North Dakota\n$15,507\n$41,406\n$68,558\n$104,602\n$217,143\n$380,261\n    Nebraska\n$16,506\n$41,590\n$66,977\n$100,910\n$213,091\n$378,679\n    Idaho\n$16,450\n$40,433\n$63,643\n$95,316\n$203,042\n$360,622\n    Puerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\n  \n  \n    \n      Source: US Census Bureau, American Community Survey"
  },
  {
    "objectID": "modules/module-4.1.html#plot-confidence-intervals-of-estimates",
    "href": "modules/module-4.1.html#plot-confidence-intervals-of-estimates",
    "title": "Module 4.1",
    "section": "Plot confidence intervals of estimates",
    "text": "Plot confidence intervals of estimates\nUse median income as example here"
  },
  {
    "objectID": "modules/module-2.1.html#prework",
    "href": "modules/module-2.1.html#prework",
    "title": "Module 2.1",
    "section": "",
    "text": "library(vdemdata)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/module-5.1.knit.html#setup",
    "href": "modules/module-5.1.knit.html#setup",
    "title": "Module 5.1",
    "section": "Setup",
    "text": "Setup\n\n# load packages\nlibrary(shiny)\nlibrary(readr)\nlibrary(ggplot2)\n\n# read in data, create a vector of variable names\ndem_data <- read_csv(\"dem_data.csv\")\n\n# create list of named values for the input selection\nvars <- c(\"Democracy\" = \"polyarchy\",\n          \"Clientelism\" = \"clientelism\",\n          \"Corruption\" = \"corruption\",\n          \"Women's Empowerment\" = \"womens_emp\",\n          \"Wealth\" = \"gdp_pc\",\n          \"Infant Mortality\" = \"inf_mort\",\n          \"Life Expectancy\" = \"life_exp\", \n          \"Education\" = \"education\")"
  },
  {
    "objectID": "modules/module-5.1.knit.html#ui",
    "href": "modules/module-5.1.knit.html#ui",
    "title": "Module 5.1",
    "section": "ui",
    "text": "ui\n\n# Define UI for application that draws a histogram\nui <- fluidPage(\n\n    # Application title\n    titlePanel(\"Democracy and Development\"),\n\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n      sidebarPanel(\n        selectInput('xcol', 'X Variable', vars),\n        selectInput('ycol', 'Y Variable', vars, selected = vars[[6]])\n      ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"scatterplot\")\n        )\n    )\n)"
  },
  {
    "objectID": "modules/module-5.1.knit.html#server",
    "href": "modules/module-5.1.knit.html#server",
    "title": "Module 5.1",
    "section": "Server",
    "text": "Server\n\n# Define server logic required to draw a scatter plot\nserver <- function(input, output, session) {\n  \n  # Combine the selected variables into a new data frame\n\n  \n  # Render the plot\n  output$scatterplot <- renderPlot({\n    \n    selectedData <- dem_data[, c(input$xcol, input$ycol, \"region\")]\n    \n    ggplot(selectedData(), aes_string(x = input$xcol, y = input$ycol)) +\n      geom_point(aes(color = region)) +\n      geom_smooth(method = \"loess\") +\n      scale_color_viridis_d(option = \"plasma\") +\n      theme_minimal() +\n      labs(\n        x =  names(vars[which(vars == input$xcol)]),\n        y =  names(vars[which(vars == input$ycol)]),\n        caption = \"Source: V-Dem Institute\", # caption\n        color = \"Region\" # legend title\n      )\n  })\n}"
  },
  {
    "objectID": "modules/module-5.1.knit.html#call-to-shiny-app",
    "href": "modules/module-5.1.knit.html#call-to-shiny-app",
    "title": "Module 5.1",
    "section": "Call to Shiny app",
    "text": "Call to Shiny app\n\n# See above for the definitions of ui and server\nui <- ...\n\nserver <- ...\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "modules/module-2.1.html#facet-wrapping",
    "href": "modules/module-2.1.html#facet-wrapping",
    "title": "Module 2.1",
    "section": "Facet wrapping",
    "text": "Facet wrapping\nNow let‚Äôs imagine that we really interested in drilling down into the ‚Äúheterogeneous effects‚Äù of wealth on democracy by region. In other words, we want to see more clearly how wealth is related to democracy in some regions but not others. For this, we can use facet_wrap() to get a separate chart for each region rather than just shading the points by region. Inside of facet_wrap() we identify region as the variable that we want to use to separate the plots, e.g.¬†facet_wrap(~region). Notice how we have to include a tilde (~) here.\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", linewidth = 1) + \n  facet_wrap(~ region) +\n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )\n\n\n\n\nHere we can clearly see a relationship between wealth and democracy in all of the countries except for the Middle East and Africa. We could speculate that the lack of a relationship in the Middle East could be evidence of an oil curse dynamic whereas perhaps the lack of a relationship in Africa is due to weak institutions.\nThe relationship between wealth and democracy in the West would be apparent, but it is obscured by the fact that western countries because the high wealth and polyarchy values result in extreme bunching in the northwest quadrant of the graph. To deal with this issue, we could add the scales = \"free\" argument to our plot.\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", linewidth = 1) + \n  facet_wrap(~ region, scales = \"free\") +\n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )\n\n\n\n\nBut notice there is a bit of a tradeoff here. With the scales = free option set, we now have separate axes for each of the plots. This is less of a clean look than having common x and y axes.\n\nLabeling points\nNow let‚Äôs try drilling down into one of the regions to get a better sense of what countries are driving the relationship. To do this, we can filter our data set for a region that we are interested in and then add country labels to the points in the scatter plot. Here we are going to filter for ‚ÄúAsia‚Äù and we will ad a geom_text() call to add country labels. In the geom_text() call we include arguments for size and vjust to adjust the size and vertical location of the labels relative to the points.\n\ndem_summary_ctry |> \n  filter(region == \"Asia\") |>\n  ggplot(aes(x = gdp_pc, y = polyarchy)) + \n    geom_point() + \n    geom_text(aes(label = country), size = 2, vjust = 2) +\n    geom_smooth(method = \"lm\", linewidth = 1) +\n    scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n      labs(\n        x= \"GDP Per Capita\", \n        y = \"Polyarchy Score\",\n        title = \"Wealth and democracy in Asia, 1990 - present\", \n        caption = \"Source: V-Dem Institute\"\n        )"
  },
  {
    "objectID": "modules/module-2.2.html#scaling-for-scatterplots-and-line-charts",
    "href": "modules/module-2.2.html#scaling-for-scatterplots-and-line-charts",
    "title": "Module 2.2",
    "section": "Scaling for scatterplots and line charts",
    "text": "Scaling for scatterplots and line charts\n\nUse ‚Äúscale_color‚Äù instead of ‚Äúscale_fill‚Äù for line charts and scatter plots, e.g.¬†scale_color_manual(), scale_color_viridis_d(), scale_color_brewer.\n\nwealth_flfp <- ggplot(flfp_gdp, aes(x = gdp_pc, y = flfp)) + # plot gdp_pc vs flfp, store in wealth_flfp \n  geom_point(aes(color = region)) + # add an aesthetic to color points by region\n  geom_smooth(method = \"loess\", linewidth = 1) +  # make the line a loess curve\n  scale_x_log10(labels = scales::label_dollar()) + # stretch x- axis, add '$' format\n  scale_y_continuous(labels = scales::label_percent(scale = 1)) + # add % label to y-axis\n  labs(\n    x= \"GDP per Capita\", # x-axis title\n    y = \"Female Labor Force Participation\", # y-axis title\n    title = \"Wealth and female labor force participation\", # plot title\n    caption = \"Source: World Bank Development Indicators\", # caption\n    color = \"Region\" # legend title\n    )\n\nwealth_flfp + scale_color_viridis_d(option = \"plasma\")\n\n\n\n\n\nflfp_line <- ggplot(flfp_ts, aes(x = year, y = flfp, color = region)) +\n  geom_line(linewidth = 1) + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(\n    x = \"Year\", \n    y = \"Female Labor Force Participation\", \n    title = \"Regional trends in female labor force participation\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\"\n  )\n\nflfp_line + scale_color_brewer(palette = \"YlOrRd\")"
  }
]