[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Microsoft 365\nüîó on GW IT‚Äôs Microsoft 365 Page\n\n\nTableau\nüîó on Tableau Trial\n\n\nLecture Recordings\nüîó on Blackboard\n\n\nProf T‚Äôs Zoom Office\nüîó on Zoom\n\n\nOffice Hours Appointments\nüîó on Calendly"
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Support",
    "section": "",
    "text": "Writing Center GW‚Äôs Writing Center cultivates confident writers in the University community by facilitating collaborative, critical, and inclusive conversations at all stages of the writing process. Working alongside peer mentors, writers develop strategies to write independently in academic and public settings. Appointments can be booked online here.\nAcademic Commons Academic Commons provides tutoring and other academic support resources to students in many courses. Students can schedule virtual one-on-one appointments or attend virtual drop-in sessions. Students may schedule an appointment, review the tutoring schedule, access other academic support resources, or obtain assistance here."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Support",
    "section": "",
    "text": "Writing Center GW‚Äôs Writing Center cultivates confident writers in the University community by facilitating collaborative, critical, and inclusive conversations at all stages of the writing process. Working alongside peer mentors, writers develop strategies to write independently in academic and public settings. Appointments can be booked online here.\nAcademic Commons Academic Commons provides tutoring and other academic support resources to students in many courses. Students can schedule virtual one-on-one appointments or attend virtual drop-in sessions. Students may schedule an appointment, review the tutoring schedule, access other academic support resources, or obtain assistance here."
  },
  {
    "objectID": "course-support.html#support-for-students-outside-the-classroom",
    "href": "course-support.html#support-for-students-outside-the-classroom",
    "title": "Support",
    "section": "Support for students outside the classroom",
    "text": "Support for students outside the classroom\nDisability Support Services (DSS) 202-994-8250 Any student who may need an accommodation based on the potential impact of a disability should contact Disability Support Services to establish eligibility and to coordinate reasonable accommodations.\nCounseling and Psychological Services 202-994-5300 GW‚Äôs Colonial Health Center offers counseling and psychological services, supporting mental health and personal development by collaborating directly with students to overcome challenges and difficulties that may interfere with academic, emotional, and personal success.\nGW aims to create a community that cares for each other.The CARE Team fosters this goal by creating a pathway through which students who may need additional support can be identified and referred to the most appropriate services. Through the CARE Team, students are given the support they need to persist and succeed at GW and beyond.\nSafety and Security:\n\nIn an emergency: call GWPD 202-994-6111 or 911.\nFor situation-specific actions: review the Emergency Response Handbook\nStay informed: safety.gwu.edu/stay-informed"
  },
  {
    "objectID": "exercises/exercise-1.2.html",
    "href": "exercises/exercise-1.2.html",
    "title": "Exercise 1.2",
    "section": "",
    "text": "Loading webR..."
  },
  {
    "objectID": "exercises/exercise-1.2.html#code",
    "href": "exercises/exercise-1.2.html#code",
    "title": "Exercise 1.2",
    "section": "",
    "text": "Loading webR..."
  },
  {
    "objectID": "exercises/exercise-1.2.html#questions",
    "href": "exercises/exercise-1.2.html#questions",
    "title": "Exercise 1.2",
    "section": "Questions",
    "text": "Questions\n\nTry summarizing the data with a different function for one or more of the variables.\n\n\nWhat is the median value of polyarchy for The West?\nWhat is the max value of gdp_pc for Eastern Europe?\nWhat is the standard deviation of flfp for Africa?\nWhat is the interquartile range of women_rep for the Middle East?\n\n\nNow try grouping by country instead of region.\n\n\nWhat is the median value of polyarchy for Sweden?\nWhat is the max value of gdp_pc New Zealand?\nWhat is the standard deviation of flfp for Spain?\nWhat is the interquartile range of women_rep for Germany?\n\n\nSort countries in descending order based on the mean value of gdp_pc (instead of the median value of polyarchy). Which country ranks first based on this sorting?\nNow try sorting countries in ascending order based on the median value of women_rep (hint: delete ‚Äúdesc‚Äù from the arrange() call). Which country ranks at the ‚Äútop‚Äù of the list?"
  },
  {
    "objectID": "exercises/zzz.html",
    "href": "exercises/zzz.html",
    "title": "Additional Dependencies",
    "section": "",
    "text": "/exercises/webr-serviceworker.js\n/exercises/webr-worker.js"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This page displays an outline of the topics, content, and assignments for the term. Each module starts on a Monday. There are no assignments due on Sundays.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModule\n\n\n\n\nDate\n\n\n\n\nSkills\n\n\n\n\nPackages\n\n\n\n\nFunctions\n\n\n\n\nReadings\n\n\n\n\nVideos\n\n\n\n\nAssignments\n\n\n\n\n\n\n\n\n1.1\n\n\n\n\nr advdate(mon,0)\n\n\n\n\nRead data from flat files into R\n\n\n\n\nreadr\n\n\n\n\nread_csv(), glimpse()\n\n\n\n\nr4ds, 8.1 & 8.2\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(tues,0)\n\n\n\n\nReshape data\n\n\n\n\ntidyr\n\n\n\n\npivot_longer()\n\n\n\n\nr4ds, 6.1 - 6.3\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(wed,0)\n\n\n\n\nClean data\n\n\n\n\ndplyr, janitor , readr\n\n\n\n\nmutate_at(), clean_names() , write_csv()\n\n\n\n\nNorris\n\n\n\n\n\n\n\n\n\n\n1.2\n\n\n\n\nr advdate(thur,0)\n\n\n\n\nDownload data from an API, filter observations, select and create variables\n\n\n\n\nwbstats, vdemdata, dplyr\n\n\n\n\nwbstats(), vdem,\n\n\nfilter() , select(), mutate()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(fri,0)\n\n\n\n\nMerge data frames\n\n\n\n\ncountrycode, dplyr\n\n\n\n\ncountry_code(), left_join()\n\n\n\n\nr4ds, 20.3\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(sat,0)\n\n\n\n\nGroup, summarize and arrange data\n\n\n\n\ndplyr\n\n\n\n\ngroup_by(), summarize(), arrange()\n\n\n\n\nr4ds, 4.5\n\n\n\n\n\n\n\n\n\n\n2.1\n\n\n\n\nr advdate(mon,1)\n\n\n\n\nThe grammar of graphics and ggplot2\n\n\n\n\nBasics of ggplot2 syntax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 1)\n\n\n\n\nBar charts and line charts\n\n\n\n\nCreate bar charts, line charts and shaded area charts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 1)\n\n\n\n\nScatter plots and linear models\n\n\n\n\nGroup points using shapes or colors; add fitted lines to data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2\n\n\n\n\nr advdate(thur, 1)\n\n\n\n\nThemes and annotations\n\n\n\n\nAdd text, labels, annotations and lines to your graphs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 1)\n\n\n\n\nInteractivity\n\n\n\n\nMake visualizations interactive with plotly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 1)\n\n\n\n\nClarity and accessibility\n\n\n\n\nMake sure everyone can read your graphs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.1\n\n\n\n\nr advdate(mon, 2)\n\n\n\n\nWorld Bank databases\n\n\n\n\nDownload World Bank with wbstats\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 2)\n\n\n\n\nCreate a world map\n\n\n\n\nBasics of sf and rnaturalearth packages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 2)\n\n\n\n\nMapping data\n\n\n\n\nJoin WB data to polygons and map\n\n\n\n\nSomething related to ethics here?\n\n\n\n\n\n\n\n\n\n\n\n\n3.2\n\n\n\n\nr advdate(thur, 2)\n\n\n\n\nThe leaflet package\n\n\n\n\nMake an OpenStreetMap with markers or popups\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 2)\n\n\n\n\nMap state-level data\n\n\n\n\nCreate choropleth with colorBin() and addPolygons() functions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 2)\n\n\n\n\nMap interactivity\n\n\n\n\nAdd interactive labels to state choropleth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1\n\n\n\n\nr advdate(mon, 3)\n\n\n\n\nThe wid-r-tool package\n\n\n\n\nUse the download_wid() function to download wealth/income shares\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 3)\n\n\n\n\nReshaping data I\n\n\n\n\nTransform data to wide format with pivot_wider()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 3)\n\n\n\n\nReshaping data II\n\n\n\n\nTransform data to long format with pivot_longer()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2\n\n\n\n\nr advdate(thur, 3)\n\n\n\n\nThe grammar of tables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 3)\n\n\n\n\nMake a table of income shares\n\n\n\n\nFormat data with fmt_percent()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 3)\n\n\n\n\nModify parts of table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1\n\n\n\n\nr advdate(mon, 4)\n\n\n\n\nWhat is a Shiny app?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 4)\n\n\n\n\nThe ui and server objects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 4)\n\n\n\n\nYour first Shiny app\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2\n\n\n\n\nr advdate(thur, 4)\n\n\n\n\nThe fredr package\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 4)\n\n\n\n\nIndicator graphing app, Part I\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 4)\n\n\n\n\nIndicator graphing app, Part II\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.1\n\n\n\n\nr advdate(mon, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(tues, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(wed, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.2\n\n\n\n\nr advdate(thur, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(fri, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr advdate(sat, 5)"
  },
  {
    "objectID": "instructor.html",
    "href": "instructor.html",
    "title": "Instructor",
    "section": "",
    "text": "Emmanuel Teitelbaum is an associate professor of political science and international affairs at the The George Washington University His research and writing explore how class conflict and compromise intersect with democracy and development. He also has a strong interest in labor standards and understanding how labor unions, nonprofit organizations, consumers and corporations can help to promote them.\nAt GW, Professor Teitelbaum teaches courses on comparative politics, comparative political economy and South Asia. He is on faculty in the Department of Political Science and the Elliott School of International Affairs and am affiliated with the Sigur Center for Asian Studies as well as the Institute for International Economic Policy."
  },
  {
    "objectID": "instructor.html#office-hours",
    "href": "instructor.html#office-hours",
    "title": "Instructor",
    "section": "Office hours",
    "text": "Office hours\nProfessor Teitelbaum‚Äôs office hours are on Tuesdays and Thursdays from 4:00 p.m. to 5:00 p.m. Please sign up for a slot (or two) on his Calendly page. He is available for consultation virtually on Zoom or in his office at 411 Monroe Hall (2115 G. ST NW)."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (‚ÄúPublic License‚Äù). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 ‚Äì Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter‚Äôs License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 ‚Äì Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor ‚Äì Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor ‚Äì Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter‚Äôs License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 ‚Äì License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter‚Äôs License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter‚Äôs License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter‚Äôs License You apply.\n\n\n\nSection 4 ‚Äì Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 ‚Äì Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 ‚Äì Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 ‚Äì Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 ‚Äì Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the ‚ÄúLicensor.‚Äù The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark ‚ÄúCreative Commons‚Äù or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "modules/getting-started.html",
    "href": "modules/getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "All of our work for this course will be done in the R language. Please download and install the most recent version of R from the Comprehensive R Archive Network (CRAN).\nRStudio is an integrated development environment (IDE) develop by a company named Posit. We will do all of our code editing for this course in RStudio. Please be sure to download and install the most recent version of R Studio RStudio.\nWe are going to be using a number of R packages throughout the course. One essential set of packages are those that comprise the Tidyverse, but especially readr, dplyr, ggplot2 and tidyr. You can install the entire Tidyverse collection of packages by typing install.packages(\"tidyverse\") in your console. We will talk about these packages in detail as we go through the course, but have a look at this basic description now to gain some basic familiarity."
  },
  {
    "objectID": "modules/getting-started.html#sec-rstudio-setup",
    "href": "modules/getting-started.html#sec-rstudio-setup",
    "title": "Getting Started",
    "section": "",
    "text": "All of our work for this course will be done in the R language. Please download and install the most recent version of R from the Comprehensive R Archive Network (CRAN).\nRStudio is an integrated development environment (IDE) develop by a company named Posit. We will do all of our code editing for this course in RStudio. Please be sure to download and install the most recent version of R Studio RStudio.\nWe are going to be using a number of R packages throughout the course. One essential set of packages are those that comprise the Tidyverse, but especially readr, dplyr, ggplot2 and tidyr. You can install the entire Tidyverse collection of packages by typing install.packages(\"tidyverse\") in your console. We will talk about these packages in detail as we go through the course, but have a look at this basic description now to gain some basic familiarity."
  },
  {
    "objectID": "modules/getting-started.html#quarto",
    "href": "modules/getting-started.html#quarto",
    "title": "Getting Started",
    "section": "Quarto",
    "text": "Quarto\n\nOnce you have R, R Studio and Quarto installed, you are ready to start integrating text and code with Quarto. Quarto is an open source publishing platform that enables you to integrate text with code. If you have used R Markdown before then Quarto will look familiar to you because Quarto is the next generation of R Markdown.\nRStudio comes with a version of Quarto already installed, but it can be useful to install the most recent version separately and because doing so will allow you to use Quarto with another IDE like VS Code. You can install the most recent version of Quarto by visiting this page and selecting the version for your operating system.\nNow take a little time to create a Quarto project in R Studio and make sure everything is working properly. But before you get started, create a new folder(directory) for this course on your computer somewhere. Once that is done, go to File &gt; New Project. Then select Quarto Project and name the project something like ‚Äútest-project‚Äù in the Directory name field. Next, select Browse and navigate to the folder that you created for this course. Select Create Project.\nYou will notice that in your new project folder there is a file with an .Rproj extension. The .Rproj file is what tells RStudio which files are associated with the project and it obviates the need to set the working directory. It also makes it possible to share the folder with anyone who is running R and RStudio and have them run your code without having to set a working directory. This is what we refer to as a project-based workflow and we will use it for every assignment in this class.\nNow try rendering the document with the Render toggle button. By default, Quarto renders an .html file that it will open in a browser and save to your project folder.\nNext we want to try rendering a .pdf document. To do this, we have to install tinytex, a lightweight version of LaTeX. To do this, go to the Terminal and type quarto install tinytex. Now, change the format from html to pdf by inserting format: pdf in the YAML header. Then render the document again. A .pdf document should open up.\nNow take a few minutes and try changing more of the code in the YAML header. You can try changing the title, adding a subtitle (subtitle:) or changing the execution options. By default, Quarto uses the visual editor but behind the scenes it is using Markdown. Try and edit some text using the toggle buttons available in the visual editor and then switch to Source to view the underlying Markdown code. Play with the R code chunks embedded in the document or try adding new code chunks.\nYou may already have some experience writing in Markdown, which is a lightweight markup language that enables you to format plaintext files. If you have not used Markdown, or if your memory is hazy, don‚Äôt worry: it is really easy to learn. Have a look at this Markdown cheat sheet and try to familiarize yourself with its basic syntax. Finally, take some time to get familiar with the Guide and Reference sections of the Quarto website. Then take a look at the gallery so that you can get an idea of the kinds of things you can produce with Quarto."
  },
  {
    "objectID": "modules/getting-started.html#github",
    "href": "modules/getting-started.html#github",
    "title": "Getting Started",
    "section": "GitHub",
    "text": "GitHub\n\nGitHub is a platform for hosting version control repositories. In this course we will learn to use GitHub to store, manage and collaborate on code.\nOne central concept you want to be familiar with is a repository or ‚Äúrepo‚Äù for short. Repos are essentially folders where code can be stored and then accessed and changed by multiple users. All of the assignments for this course will be managed in repos.\nGitHub repos are managed using a version control system named Git. Git allows developers to make and track changes to the code stored in the repo. Git also enables users to create branches to work on the code without affecting the main codebase and then merge those changes back into the main branch when they are ready.\nThe first thing you are going to want to do is to register a GitHub account. From there, you want to install Git and initiate Git using the usethis package.\nNext, you need to generate a personal access token (PAT) and set your credentials with the gitcreds package.\nNow, you can create a GitHub repo and clone it to your computer in RStudio. There a number of ways to clone a repo, but the recommended method for this course involves creating a new project in RStudio and selecting ‚ÄúVersion Control‚Äù for the method (instead of ‚ÄúNew Directory‚Äù as we did before). From there, select ‚ÄúGit‚Äù, copy the URL from the green ‚ÄúCode‚Äù tab in the GitHub repo, and paste it into ‚ÄúRepository URL‚Äù field. Next, select the directory where you want the repository to be created and click ‚Äúcreate project.‚Äù"
  },
  {
    "objectID": "modules/getting-started.html#github-classroom",
    "href": "modules/getting-started.html#github-classroom",
    "title": "Getting Started",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\n\n\nGive a brief overview of GitHub Classroom and how to use it.\nPerhaps have students download a mock assignment to illustrate how it works."
  },
  {
    "objectID": "modules/module-1.1.html",
    "href": "modules/module-1.1.html",
    "title": "Module 1.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall R, R Studio and the Tidyverse collection of packages if you have not done so already (see getting started)\nInstall the janitor package (install.packages(\"janitor\"))\nHave a look at the documentation for readr, dplyr, tidyr and janitor\nFamiliarize yourself with the readr, dplyr and tidyr cheatsheets\nCreate a new directory/folder in your project folder called ‚Äúdata‚Äù where you can store .csv files\nStart a new quarto project called ‚Äúmodules‚Äù and generate a quarto document named ‚Äúmodule-1.1.qmd‚Äù inside of it so that you can code along with me"
  },
  {
    "objectID": "modules/module-1.1.html#overview",
    "href": "modules/module-1.1.html#overview",
    "title": "Module 1.1",
    "section": "Overview",
    "text": "Overview\nIn this module, we are going to work with a ‚Äúflat file‚Äù (.csv) that we will download from the World Bank‚Äôs Data Bank. We are going to encounter many problems with these data that we will rectify using various R packages that I will introduce along the way. The idea is to take this file in its current state and transform it into a tidy dataset where each column represents a variable, each row represents an observation, and each cell represents a single value."
  },
  {
    "objectID": "modules/module-1.1.html#downloading-world-bank-data-into-a-flat-file",
    "href": "modules/module-1.1.html#downloading-world-bank-data-into-a-flat-file",
    "title": "Module 1.1",
    "section": "Downloading World Bank data into a flat file",
    "text": "Downloading World Bank data into a flat file\n\nGo to the World Development Indicators portal at the World Bank‚Äôs Data Bank.\nUnder Countries, select the Countries tab and then select the little check mark ‚òëÔ∏è to select all of the countries. Be sure to select the Countries tab first, though, or you will also be downloading aggregate data for regions and groups of countries.\nNext, under Series, search for ‚Äúlabor force participation‚Äù and find labor force participation rates for women ages 15-64 (ILO modeled estimates). Check that series.\nNow go to Time and select the years from the last 50 years. Click Apply Changes, go to Download Options and download as a .csv file. Place the .csv file in the data directory that you created for this module. Save it as ‚Äúmessy_wb_data.csv‚Äù or something like that."
  },
  {
    "objectID": "modules/module-1.1.html#reading-data-from-a-flat-file",
    "href": "modules/module-1.1.html#reading-data-from-a-flat-file",
    "title": "Module 1.1",
    "section": "Reading data from a flat file",
    "text": "Reading data from a flat file\n\nNow we are going to read this messy World Bank data into R using the read_csv() function from the readr package. readr is a collection of functions that parses data from a flat file into a tibble, the modern Tidyverse version of a data frame. After we have read the data into R, we are going to have a look at it with the glimpse() function from the dplyr package.\nglimpse() shows us a list of the columns in the along with their type (e.g.¬†character, double, etc.) and a few rows‚Äô worth of data.\n\n\n\n\n\n\nNote\n\n\n\nWhile comma delimited files are the most common kind of flat file, readr includes functions for parsing files with a wide range of delimiters including tabs (read_tsv()), semicolons (read_csv2()) and white spaces (read_table()). There is also a Tidyverse package for reading in Excel files called readxl.\n\n\n\n# Load packages\nlibrary(readr) \nlibrary(dplyr) \n\n# Read data from csv file into an object called \"wb_data_messy\"\nwb_data_messy &lt;- read_csv(\"data/messy_wb_data.csv\")\n\n# View the data\nglimpse(wb_data_messy)\n\nRows: 222\nColumns: 54\n$ `Country Name`  &lt;chr&gt; \"Afghanistan\", \"Albania\", \"Algeria\", \"American Samoa\",‚Ä¶\n$ `Country Code`  &lt;chr&gt; \"AFG\", \"ALB\", \"DZA\", \"ASM\", \"AND\", \"AGO\", \"ATG\", \"ARG\"‚Ä¶\n$ `Series Name`   &lt;chr&gt; \"Labor force participation rate, female (% of female p‚Ä¶\n$ `Series Code`   &lt;chr&gt; \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI‚Ä¶\n$ `1972 [YR1972]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1973 [YR1973]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1974 [YR1974]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1975 [YR1975]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1976 [YR1976]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1977 [YR1977]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1978 [YR1978]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1979 [YR1979]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1980 [YR1980]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1981 [YR1981]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1982 [YR1982]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1983 [YR1983]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1984 [YR1984]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1985 [YR1985]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1986 [YR1986]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1987 [YR1987]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1988 [YR1988]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1989 [YR1989]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1990 [YR1990]` &lt;chr&gt; \"15.83\", \"60.63\", \"12.31\", \"..\", \"..\", \"76.73\", \"..\", ‚Ä¶\n$ `1991 [YR1991]` &lt;chr&gt; \"15.89\", \"65.54\", \"12.33\", \"..\", \"..\", \"76.69\", \"..\", ‚Ä¶\n$ `1992 [YR1992]` &lt;chr&gt; \"15.92\", \"66.56\", \"12.37\", \"..\", \"..\", \"76.66\", \"..\", ‚Ä¶\n$ `1993 [YR1993]` &lt;chr&gt; \"15.91\", \"65.01\", \"12.41\", \"..\", \"..\", \"76.68\", \"..\", ‚Ä¶\n$ `1994 [YR1994]` &lt;chr&gt; \"15.88\", \"63.64\", \"12.47\", \"..\", \"..\", \"76.64\", \"..\", ‚Ä¶\n$ `1995 [YR1995]` &lt;chr&gt; \"15.92\", \"61.59\", \"12.56\", \"..\", \"..\", \"76.57\", \"..\", ‚Ä¶\n$ `1996 [YR1996]` &lt;chr&gt; \"15.75\", \"60.28\", \"12.64\", \"..\", \"..\", \"76.55\", \"..\", ‚Ä¶\n$ `1997 [YR1997]` &lt;chr&gt; \"15.59\", \"61.91\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1998 [YR1998]` &lt;chr&gt; \"15.47\", \"60.62\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1999 [YR1999]` &lt;chr&gt; \"15.4\", \"58.87\", \"12.63\", \"..\", \"..\", \"76.51\", \"..\", \"‚Ä¶\n$ `2000 [YR2000]` &lt;chr&gt; \"15.35\", \"57.89\", \"12.71\", \"..\", \"..\", \"76.49\", \"..\", ‚Ä¶\n$ `2001 [YR2001]` &lt;chr&gt; \"15.5\", \"56.71\", \"12.85\", \"..\", \"..\", \"76.48\", \"..\", \"‚Ä¶\n$ `2002 [YR2002]` &lt;chr&gt; \"15.7\", \"56.06\", \"13.02\", \"..\", \"..\", \"76.44\", \"..\", \"‚Ä¶\n$ `2003 [YR2003]` &lt;chr&gt; \"15.92\", \"55.3\", \"13.24\", \"..\", \"..\", \"76.41\", \"..\", \"‚Ä¶\n$ `2004 [YR2004]` &lt;chr&gt; \"16.13\", \"54.57\", \"13.5\", \"..\", \"..\", \"76.38\", \"..\", \"‚Ä¶\n$ `2005 [YR2005]` &lt;chr&gt; \"16.33\", \"53.88\", \"13.79\", \"..\", \"..\", \"76.36\", \"..\", ‚Ä¶\n$ `2006 [YR2006]` &lt;chr&gt; \"16.12\", \"53.43\", \"14.12\", \"..\", \"..\", \"76.39\", \"..\", ‚Ä¶\n$ `2007 [YR2007]` &lt;chr&gt; \"15.91\", \"53.07\", \"14.47\", \"..\", \"..\", \"76.42\", \"..\", ‚Ä¶\n$ `2008 [YR2008]` &lt;chr&gt; \"15.74\", \"52.78\", \"14.87\", \"..\", \"..\", \"76.46\", \"..\", ‚Ä¶\n$ `2009 [YR2009]` &lt;chr&gt; \"15.65\", \"51.57\", \"15.31\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `2010 [YR2010]` &lt;chr&gt; \"15.65\", \"52.75\", \"15.49\", \"..\", \"..\", \"76.59\", \"..\", ‚Ä¶\n$ `2011 [YR2011]` &lt;chr&gt; \"16\", \"60.59\", \"16.45\", \"..\", \"..\", \"76.67\", \"..\", \"55‚Ä¶\n$ `2012 [YR2012]` &lt;chr&gt; \"16.44\", \"55.1\", \"17.48\", \"..\", \"..\", \"76.73\", \"..\", \"‚Ä¶\n$ `2013 [YR2013]` &lt;chr&gt; \"17.42\", \"50.58\", \"18.29\", \"..\", \"..\", \"76.79\", \"..\", ‚Ä¶\n$ `2014 [YR2014]` &lt;chr&gt; \"18.46\", \"50.18\", \"16.68\", \"..\", \"..\", \"76.83\", \"..\", ‚Ä¶\n$ `2015 [YR2015]` &lt;chr&gt; \"19.55\", \"54.05\", \"17.5\", \"..\", \"..\", \"76.87\", \"..\", \"‚Ä¶\n$ `2016 [YR2016]` &lt;chr&gt; \"20.7\", \"56.4\", \"18.33\", \"..\", \"..\", \"76.9\", \"..\", \"56‚Ä¶\n$ `2017 [YR2017]` &lt;chr&gt; \"21.91\", \"55.54\", \"19.19\", \"..\", \"..\", \"76.91\", \"..\", ‚Ä¶\n$ `2018 [YR2018]` &lt;chr&gt; \"22.32\", \"59.12\", \"18.95\", \"..\", \"..\", \"76.9\", \"..\", \"‚Ä¶\n$ `2019 [YR2019]` &lt;chr&gt; \"22.74\", \"61.46\", \"18.7\", \"..\", \"..\", \"76.88\", \"..\", \"‚Ä¶\n$ `2020 [YR2020]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `2021 [YR2021]` &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶"
  },
  {
    "objectID": "modules/module-1.1.html#reshaping-data",
    "href": "modules/module-1.1.html#reshaping-data",
    "title": "Module 1.1",
    "section": "Reshaping data",
    "text": "Reshaping data\n\nThere are a few things about the data here that make it messy. First, in order for the data to be tidy, we want each column to represent a variable and each row to represent an observation.\nBut here we see the reverse: the data are in wide form, meaning that each column represents a year and each row represents a country. This entails that each row represents multiple observations in that we have data for multiple years for each row.\nTo rectify this, we need to reshape the data from wide form to long form. For this, we need the pivot_longer() function from the tidyr package.\nThe pivot_longer() function takes three basic arguments:\n\ncols - which columns you want to pivot\nnames_to - the name of the column where the old column names are going to\nvalues_to - the name of the column where the values are going to\n\nIn our case, we want to reshape all of the year columns and have the years represented in the rows. We want the newly created column to be called ‚Äúyear‚Äù and the values are going to represent the data on female labor force participation we downloaded (flfp).\n\n# Load tidyr\nlibrary(tidyr)\n\n# Reshape the data\nwb_data &lt;- wb_data_messy |&gt; # take wb_data_messy, and put it in wb_data, but first...\n  pivot_longer(             # pivot the data from wide to long form\n    cols = `1972 [YR1972]`: `2021 [YR2021]`, # columns to pivot\n    names_to = \"year\", # name the first column \"year\"\n    values_to = \"flfp\" # name the second column \"flfp\"\n  ) \n\n# View the data\nglimpse(wb_data)\n\nRows: 11,100\nColumns: 6\n$ `Country Name` &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist‚Ä¶\n$ `Country Code` &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",‚Ä¶\n$ `Series Name`  &lt;chr&gt; \"Labor force participation rate, female (% of female po‚Ä¶\n$ `Series Code`  &lt;chr&gt; \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.‚Ä¶\n$ year           &lt;chr&gt; \"1972 [YR1972]\", \"1973 [YR1973]\", \"1974 [YR1974]\", \"197‚Ä¶\n$ flfp           &lt;chr&gt; \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"‚Ä¶\n\n\n\n\n\n\n\n\nThe Pipe Operator\n\n\n\nFor our pivot-longer() call we used R‚Äôs native pipe operator, e.g.¬†|&gt;. Pipes tell R to do something to the object that they are attached to. In this case, we are telling R to apply pivot_longer() to wb_data. The alternative way of writing this code would be to include the data as the first argument in the function, e.g.¬†pivot_longer(wb_data, cols = ..., names_to = ... , values_to = ...). As you will see, pipe operators enable us to string together multiple functions in a convenient way to transform our data.\n\n\n\n\n\n\n\n\nSpaces in Variable Names\n\n\n\nNotice that when we specify the years in our pivot_longer() call we encapsulate them in backticks (``). This is because the years, as they were imported from the WDI dataset, have spaces in them. Typically we want to avoid this scenario by writing our variable names in snake_case."
  },
  {
    "objectID": "modules/module-1.1.html#truncating-strings-and-changing-variable-types",
    "href": "modules/module-1.1.html#truncating-strings-and-changing-variable-types",
    "title": "Module 1.1",
    "section": "Truncating strings and changing variable types",
    "text": "Truncating strings and changing variable types\n\nNow that our data are transposed, we can start to work on some other key issues. Notice that the year is stored in the weird way in which it was imported‚Äìas a character (or string) with both the year and the year in brackets, e.g.¬†1972 [YR1972]. Notice that flfp is also stored as a character whereas it should be numeric.\nTo fix this, we will use the mutate() and mutate_at() functions from dplyr. mutate() is used to transform variables and to create new ones while mutate_at() allow us to transform multiple columns at once.\nFirst we call mutate() along with substring() to truncate the year variable to only include the first four characters of the string. Then we call mutate_at() along with as.numeric to transform year and flfp to numeric variables.\n\n# Fix year and flfp\nwb_data &lt;- wb_data |&gt; # replace wb_data with a modified version of the dataframe \n  mutate(year = substring(year, 1, 4)) |&gt; # truncate year (keep first four characters)\n  mutate_at(c(\"year\", \"flfp\"), as.numeric) # change year and flfp to numeric\n\n# View the data\nglimpse(wb_data)\n\nRows: 11,100\nColumns: 6\n$ `Country Name` &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist‚Ä¶\n$ `Country Code` &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",‚Ä¶\n$ `Series Name`  &lt;chr&gt; \"Labor force participation rate, female (% of female po‚Ä¶\n$ `Series Code`  &lt;chr&gt; \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.‚Ä¶\n$ year           &lt;dbl&gt; 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1‚Ä¶\n$ flfp           &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶"
  },
  {
    "objectID": "modules/module-1.1.html#cleaning-variable-names",
    "href": "modules/module-1.1.html#cleaning-variable-names",
    "title": "Module 1.1",
    "section": "Cleaning variable names",
    "text": "Cleaning variable names\n\nThe last thing we are going to do is to fix the variable names. Specifically, we want to remove the spaces from the remaining variables and conver them from title case to snake case. To do this, we will use the clean_names() function from the janitor package.\nAs a final step, we can export our clean data to a new .csv file with the write.csv() function from readr.\n\n# Load janitor\nlibrary(janitor)\n\n# Apply clean_names() to wb_data, store in new data frame called wb_data_clean\nwb_data_clean &lt;- wb_data |&gt;  \n  clean_names() \n\n# Write wb_data_clean to a csv file\nwrite_csv(wb_data_clean, \"data/wb_data_clean.csv\")\n\n# View the data\nglimpse(wb_data_clean)\n\nRows: 11,100\nColumns: 6\n$ country_name &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan‚Ä¶\n$ country_code &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"‚Ä¶\n$ series_name  &lt;chr&gt; \"Labor force participation rate, female (% of female popu‚Ä¶\n$ series_code  &lt;chr&gt; \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE‚Ä¶\n$ year         &lt;dbl&gt; 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 198‚Ä¶\n$ flfp         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html",
    "href": "modules/module-1.2.html",
    "title": "Module 1.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall the devtools package. Type install.packages(\"devtools\") in your console. You will need this to install the vdemdata package becaue it is not on the CRAN Network.\nInstall the vdemdata package from GitHub. Type devtools::install_github(\"vdeminstitute/vdemdata\") in your console.\nInstall the wbstats and countrycode packages:\n\n\npkg_list &lt;- c(\"wbstats\", \"countrycode\") # create a list of packages\ninstall.packages(pkg_list) # install the packages\n\n\nHave a look at the vignettes for wbstats and the countrycode documentation\nGenerate a quarto document named ‚Äúmodule-1.2.qmd‚Äù in your modules project folder so that you can code along with me"
  },
  {
    "objectID": "modules/module-1.2.html#overview",
    "href": "modules/module-1.2.html#overview",
    "title": "Module 1.2",
    "section": "Overview",
    "text": "Overview\nIn this module working, we are going to be working with data from APIs instead of flat files. As we saw in the last lesson, importing and wrangling data from flat files can be a messy process. So when clean data are available for download, we want to be able to take advantage of that. Luckily there are some pretty good R packages that allow us to extract data from open source APIs. We are going to be working with two of those in this module (wbstats and vdemdata) and some others later in the course.\nAlong the way, we are going to continue to extend our data wrangling skills. We will learn some new functions in dplyr and janitor that will help us get our data into a usable form for analysis. We are also going to cover in depth some common data science workflows, including filtering observations, selecting variables, merging two data sets, summarizing data for different groups, and sorting data based on column values.\nThe end goal is to have a nice dataset with a combination of World Bank and V-Dem Institute data that we can use to illustrate the relationship between the economy, democracy and women‚Äôs empowerment."
  },
  {
    "objectID": "modules/module-1.2.html#downloading-data-from-an-api",
    "href": "modules/module-1.2.html#downloading-data-from-an-api",
    "title": "Module 1.2",
    "section": "Downloading data from an API",
    "text": "Downloading data from an API\n\nYou will no doubt remember the messy data that we downloaded from the World Bank‚Äôs website in module 1.1. Usually it is much easier to download data from an API as opposed to wrangling it from a .csv file. In this example, I want to illustrate that for you by having you download the same data that we worked with in the last module using the wbstats package.\nFirst we are going to load wbstats along with dplyr and janitor. The wb_data() function is the one we need to download the data from the World Bank‚Äôs API. wb_data() requires to main sets of arguments: a list of indicators that we want to use and the period for which we want to download data. The period can can be entered as two separate arguments (e.g.¬†start_date and end_date). But for this exercise we will specify the number of years we want to download using mrv which stands for ‚Äúmost recent value.‚Äù\nIn addition to female labor force participation, let‚Äôs also grab the percentage of seats in parliament held by women. We will store that list of objects in a vector called women_emp to signify that these indicators are related to women‚Äôs empowerment. We will try to download 50 years of data for these two variables.\n\n\n\n\n\n\nNote\n\n\n\nIf you want to search World Bank data for additional indicators, you can use the wb_search() function. For example, if we wanted to find all of the indicators associated with female labor force participation, we could run:\n\nflfp_indicators &lt;- wb_search(\"female labor force\") # store the list of indicators\n\nprint(flfp_indicators, n=26) # view the indicators\n\nTry searching for some indicators related to a topic you are interested in and see what you get!\n\n\nWhile we are calling wb_data we will go ahead and pipe some additional functions from dplyr and janitor to clean it up. First, we will use select() to eliminate the iso2c variable, which we won‚Äôt be needing. Then, we will rename date to year. Then we will use a combination of mutate and round_to_fraction() to round the data to the nearest hundredth.\nWe will pipe all of these functions together and store the resulting data frame in a new object called women_emp.\n\n# Load packages\nlibrary(wbstats) # for downloading WB data\nlibrary(dplyr) # for selecting, renaming and mutating\nlibrary(janitor) # for rounding\n\n# Store the list of indicators in an object\nindicators &lt;- c(\"flfp\" = \"SL.TLF.CACT.FE.ZS\", \"women_rep\" = \"SG.GEN.PARL.ZS\") \n\n# Download the data  \nwomen_emp &lt;- wb_data(indicators, mrv = 50) |&gt; # download data for last 50 yrs\n  select(!iso2c) |&gt; # drop the iso2c code which we won't be using\n  rename(year = date) |&gt; # rename date to year \n  mutate(\n    flfp = round_to_fraction(flfp, denominator = 100), # round to nearest 100th\n    women_rep = round_to_fraction(women_rep, denominator = 100) \n  )\n\n# View the data\nglimpse(women_emp) \n\nRows: 6,944\nColumns: 5\n$ iso3c     &lt;chr&gt; \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW‚Ä¶\n$ country   &lt;chr&gt; \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba‚Ä¶\n$ year      &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, ‚Ä¶\n$ women_rep &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ flfp      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n\n\nNow we have some pretty tidy World Bank data related to women‚Äôs empowerment without having to do too much work. I am sure you would agree that this is a much more straightforward process than downloading the data and then importing the data as a flat file!\nOne thing that becomes very clear here is that wb_data() did not download any data before 1990. It automatically filtered out the years for which all countries had no data. The fact there were no data before 1990 for any of the countries is easily missed when we were simply importing it from a .csv file."
  },
  {
    "objectID": "modules/module-1.2.html#filter-observations-select-and-create-new-variables",
    "href": "modules/module-1.2.html#filter-observations-select-and-create-new-variables",
    "title": "Module 1.2",
    "section": "Filter observations, select and create new variables",
    "text": "Filter observations, select and create new variables\n\nThe next thing we want to talk about is how to filter observations and to select new variables. We also delve more into the topic of how to create new variables. To illustrate these concepts, we are going to be working with the V-Dem Dataset. The V-Dem offers an R package for downloading its data called vdemdata.\nvdemdata is perfect for illustrating the filter() and select() verbs because its main function for downloading the data (vdem) does not take any arguments (it simply downloads the whole dataset). So you have to use R functions to narrow down the variables and years you want to work with.\nWhile V-Dem has wealth of indicators related to democracy, we are going to focus on the most famous one called the ‚Äúpolyarchy‚Äù score. We are also going to download data on per capita GDP and create some indicator variables for region that we will use later on when we summarize the data. Along with those variables, we also want to retain country_name, year and country_id for the purposes of merging these data with our World Bank data.\n\n\n\n\n\n\nNote\n\n\n\nWhile V-Dem has a variable look-up tool (find_var), it does not provide very much information on the variables that the search function returns. Therefore, if you want to use this package for your own research, I highly recommend just going to the V-Dem codebook and manually grabbing the codes for the indicators that you want to use in your analysis.\n\n\nIn addition to filtering out years and selecting variables, let‚Äôs also create a region coding to facilitate our analysis later on. We will do this by piping in a mutate() call where we use the case_match() function to change the region from a numeric variable to a string. This will come in handy when we go to visualize the data in future lessons.\nWe will store our new data as an object called democracy.\n\n# Load packages\nlibrary(vdemdata) # to download V-Dem data\n\n# Download the data\ndemocracy &lt;- vdem |&gt; # download the V-Dem dataset\n  filter(year &gt;= 1990)  |&gt; # filter out years less than 1990\n  select(                  # select (and rename) these variables\n    country = country_name,     # the name before the = sign is the new name  \n    vdem_ctry_id = country_id,  # the name after the = sign is the old name\n    year, \n    polyarchy = v2x_polyarchy, \n    gdp_pc = e_gdppc, \n    region = e_regionpol_6C\n    ) |&gt;\n  mutate(\n    region = case_match(region, # replace the values in region with country names\n                     1 ~ \"Eastern Europe\", \n                     2 ~ \"Latin America\",  \n                     3 ~ \"Middle East\",   \n                     4 ~ \"Africa\", \n                     5 ~ \"The West\", \n                     6 ~ \"Asia\")\n                    # number on the left of the ~ is the V-Dem region code\n                    # we are changing the number to the country name on the right\n                    # of the equals sign\n  )\n\n# View the data\nglimpse(democracy)\n\nRows: 5,667\nColumns: 6\n$ country      &lt;chr&gt; \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico‚Ä¶\n$ vdem_ctry_id &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ year         &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199‚Ä¶\n$ polyarchy    &lt;dbl&gt; 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0‚Ä¶\n$ gdp_pc       &lt;dbl&gt; 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1‚Ä¶\n$ region       &lt;chr&gt; \"Latin America\", \"Latin America\", \"Latin America\", \"Latin‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#add-country-codes-to-a-data-frame",
    "href": "modules/module-1.2.html#add-country-codes-to-a-data-frame",
    "title": "Module 1.2",
    "section": "Add country codes to a data frame",
    "text": "Add country codes to a data frame\n\nOne common problem scholars face when they want to analyze country-level data is the fact that datasets use different country codes. This can make it challenging to combine datasets, thus limiting the potential scope of our analysis. Lucikly, there is a wonderful package called countrycode that can help to solve this problem.\nThe countrycode() function creates a new country code variable in our dataset that matches the country code variable of the second dataset that we are trying to merge it to. countrycode() takes three arguments: sourcevar; origin; and destination. sourcevar identifies the name of the column that you want to transform, origin is the coding system that you want to translate from, and destination is the coding system that you want to translate to.\nIn this next step of our analysis, we are going to join the World Bank and V-Dem data that we wrangled into a single dataset. To do that we need a common country code. The way we are going to do this is to create a new country code variable in the democracy dataset that matches the one in the women‚Äôs empowerment dataset.\nLet‚Äôs create a new version of our democracy dataset where we add a variable called iso3c. We will call mutate() to create the variable and wrap the countrycode() call inside of that. The sourcevar that we want to transform is the vdem_ctry_id, the origin code is ‚Äúvdem‚Äù, and the destination code is ‚Äúwb‚Äù.\nWe are also going to pipe in a relocate() call which simply moves the new iso3c column from the end of the data frame (where R automically drops it) so that it sits right next to vdem_ctry_cd. This is not essential but it is always good to keep our data frames looking nice and neat!.\n\n# Load countrycode\nlibrary(countrycode)\n\n# Create new iso3c variable\ndemocracy &lt;- democracy |&gt;    \n  mutate(iso3c = countrycode(sourcevar = vdem_ctry_id, # what we are converting\n        origin = \"vdem\",         # we are converting from vdem\n        destination = \"wb\"))  |&gt; # and converting to the WB iso3c code \n  relocate(iso3c, .after = vdem_ctry_id) # move iso3c \n\n# View the data\nglimpse(democracy)\n\nRows: 5,667\nColumns: 7\n$ country      &lt;chr&gt; \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico‚Ä¶\n$ vdem_ctry_id &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ iso3c        &lt;chr&gt; \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"‚Ä¶\n$ year         &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199‚Ä¶\n$ polyarchy    &lt;dbl&gt; 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0‚Ä¶\n$ gdp_pc       &lt;dbl&gt; 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1‚Ä¶\n$ region       &lt;chr&gt; \"Latin America\", \"Latin America\", \"Latin America\", \"Latin‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#merge-two-datasets",
    "href": "modules/module-1.2.html#merge-two-datasets",
    "title": "Module 1.2",
    "section": "Merge two datasets",
    "text": "Merge two datasets\n\nNow that we have a common country code, we can join the two data sets. There are many different types of joins. First there is a distinction between mutating joins, which add observations from one dataset to another, and filtering joins, which filter out observations based on their presence or absence in another dataset. Here we are going to be focused on mutating joins.\nThere are four kinds of mutating joins we can do in dplyr. An inner_join() keeps only the observations that are common in both datasets that you want to merge. A full_join() does the opposite. It keeps all of the observations present in both datasets regardless of whether or not they have a match. A left_join() keeps all of the observations in dataset \\(x\\) and only the matching observations in dataset \\(y\\). A right_join() does the same thing, but instead keeps all of the observations from dataset \\(y\\) and only matching observations from dataset \\(x\\).\nWe are going to use left_join() to merge our two datasets. left_join() takes three essential arguments: \\(x\\); \\(y\\); and \\(by\\) which identifies the column that we want to join on. For this exercise, the \\(x\\) dataset is going to be the democracy dataset, the \\(y\\) dataset is the women empowerment dataset, and we want to join on both the ‚Äúiso3c‚Äù and ‚Äúyear‚Äù columns.\nWhen dplyr does a join, it renames any duplicate columns with suffixes like .x or .y. In our data, country is a duplicate column across the democracy and women‚Äôs empowerment datasets. So dplyr renames these country.x and country.y. It doesn‚Äôt really matter which one we keep, so let‚Äôs just rename country.x to country and filter out country.y using select().\nWe can can pipe all of these functions together and store the resulting data frame in a new object called dem_women. Let‚Äôs also save these data as a .csv file for future use with write_csv(). The first argument for write_csv() is the name of the data frame or tibble that we want to save. The second argument is the path and name of the file that we want to save it to.\n\n# Load readr\nlibrary(readr)\n\n# Perform left join using common iso3c variable and year\ndem_women &lt;- left_join(democracy, women_emp, by = c(\"iso3c\", \"year\")) |&gt; \n  rename(country = country.x) |&gt; # rename country.x\n  select(!country.y)             # crop country.y\n\n# Save as .csv for future use\nwrite_csv(dem_women, \"data/dem_women.csv\")\n\n# View the data\nglimpse(dem_women)  \n\nRows: 5,667\nColumns: 9\n$ country      &lt;chr&gt; \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico‚Ä¶\n$ vdem_ctry_id &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ iso3c        &lt;chr&gt; \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"‚Ä¶\n$ year         &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199‚Ä¶\n$ polyarchy    &lt;dbl&gt; 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0‚Ä¶\n$ gdp_pc       &lt;dbl&gt; 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1‚Ä¶\n$ region       &lt;chr&gt; \"Latin America\", \"Latin America\", \"Latin America\", \"Latin‚Ä¶\n$ women_rep    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 14.20, 17.40, 18.20, 16.00, 1‚Ä¶\n$ flfp         &lt;dbl&gt; 33.94, 34.24, 35.01, 35.85, 36.38, 37.62, 37.69, 39.65, 3‚Ä¶"
  },
  {
    "objectID": "modules/module-1.2.html#group-summarize-and-arrange",
    "href": "modules/module-1.2.html#group-summarize-and-arrange",
    "title": "Module 1.2",
    "section": "Group, summarize and arrange",
    "text": "Group, summarize and arrange\n\nNow that we have completed all of the wrangling, let‚Äôs do something with it. A common sequence in data science is group by(), summarize() and arrange(). First, we group the data by certain value or category. Then we summarize it by applying a function like min(), max(), mean(), median() or sd(). Finally, we order the data according to column values.\nLet‚Äôs go ahead and apply our three new verbs to the dem_women data frame and store the resulting new data frame in an object called dem_summary. We will group the data by region, take the mean of each variable, and sort the data in descending order based on the regions‚Äô polyarchy scores. Then we will print the object to view its contents. Along the way, we let‚Äôs also export the data to a .csv file for future use.\n\n\n\n\n\n\nNote\n\n\n\nTo print an object in R, we can either use the print() function or just execute the name of the object. Oftentimes it is simpler to just execute the name of the object.\n\n\n\n# group_by(), summarize() and arrange()\ndem_summary &lt;- dem_women |&gt; # save result as new object\n  group_by(region)  |&gt; # group dem_women data by region\n  summarize(           # summarize following vars (by region)\n    polyarchy = mean(polyarchy, na.rm = TRUE), # calculate mean, remove NAs\n    gdp_pc = mean(gdp_pc, na.rm = TRUE), \n    flfp = mean(flfp, na.rm = TRUE), \n    women_rep = mean(women_rep, na.rm = TRUE)\n  ) |&gt; \n  arrange(desc(polyarchy)) # arrange in descending order by polyarchy score\n\n# Save as .csv for future use\nwrite_csv(dem_summary, \"data/dem_summary.csv\")\n\n# View the data\nglimpse(dem_summary)\n\nRows: 6\nColumns: 5\n$ region    &lt;chr&gt; \"The West\", \"Latin America\", \"Eastern Europe\", \"Asia\", \"Afri‚Ä¶\n$ polyarchy &lt;dbl&gt; 0.8725938, 0.6405013, 0.5383947, 0.4077176, 0.3929385, 0.248‚Ä¶\n$ gdp_pc    &lt;dbl&gt; 37.913051, 9.610281, 12.177422, 9.746389, 4.410481, 21.134312\n$ flfp      &lt;dbl&gt; 52.84760, 48.02866, 51.40721, 50.28034, 56.71850, 26.48931\n$ women_rep &lt;dbl&gt; 27.783519, 20.864359, 17.608873, 14.296118, 17.152801, 9.945‚Ä¶"
  },
  {
    "objectID": "modules/module-2.1.html",
    "href": "modules/module-2.1.html",
    "title": "Module 2.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall the scales package (install.packages(\"scales\"))\nHave a look at the documentation for ggplot2\nFamiliarize yourself with the ggplot2 cheatseet\nGenerate a quarto document named ‚Äúmodule-2.1.qmd‚Äù in youe modules project folder so that you can code along with me\n\nIf you have installed the Tidyverse, then you should already have the packages for this model, including ggplot2. You can go ahead and load ggplot2 along with readr and dplyr.\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nNote that you could also load these three packages by running library(tidyverse). However, it is good to be intentional about which packages we are loading as we are learning them."
  },
  {
    "objectID": "modules/module-2.1.html#overview",
    "href": "modules/module-2.1.html#overview",
    "title": "Module 2.1",
    "section": "Overview",
    "text": "Overview\nLast week we learned how to gather and wrangle data. This week we are going to start visualizing it with the ggplot2. We will learn how to make bar charts, histograms, line charts and scatter plots.\nAlong the way we are going to be talking about the ‚Äúgrammar of graphics‚Äù that ggplot2 is based on. The ‚Äúgg‚Äù in ggplot stands for ‚Äúgrammar of graphics.‚Äù The grammar of graphics is a layered approach to constructing graphs based on a book by Leland Wilkinson.\nThe idea is that each visualization you make is going to contain cerain elements. You will start with some data. Then you will incorporate some ‚Äúaesthetics‚Äù which you can think of as the dimensions of the visualization (x-axis, y-axis and color, size or shapes for additional dimensions). Next you identify a geometric obejct that you want to use such as a bar, a line or a point. From there you can customize various elements of the plot like the title and axis scales and labels."
  },
  {
    "objectID": "modules/module-2.1.html#bar-charts",
    "href": "modules/module-2.1.html#bar-charts",
    "title": "Module 2.1",
    "section": "Bar charts",
    "text": "Bar charts\n\nLet‚Äôs get started with our first visualization‚Äìa basic bar chart. Bar charts are good for comparing data across cases. Our aim here is going to be to summarize levels of democracy across different regions like we did in the last lesson, but this time we will illustrate the differences with a chart.\nWe will start by loading in the dem_summary.csv file that we made in the last lesson. Next we will do our first ggplot() call. The ggplot() function takes two arguments: data and mapping. data refers to the data frame that includes the variables we want to visualize and mapping refers to the aesthetics mappings for the visualization. The aesthetics mappings are themselves presented in a quoting function aes() that defines the x and y values of the plot along with other aesthetic values like fill, color and linetype. We will focus on x and y values here and return to these additional aesthetic values later.\nAfter our ggplot() call, we can add a series of additional functions to define our visualization following a + sign. The most important group are the geoms which will define the basic type of plot we want to make. In this case, we are calling geom_col() for our histogram and specifying that the fill color should be ‚Äústeelblue.‚Äù\nFrom there we will further customize our visualization with the labs() function to provide a title, axis labels and a caption.\n\ndem_summary &lt;- read_csv(\"data/dem_summary.csv\")\n\nggplot(dem_summary, aes(x = region, y = polyarchy)) + # ggplot call\n  geom_col(fill = \"steelblue\") + # we use geom_col() for a a bar chart\n  labs(\n    x = \"Region\", \n    y = \"Avg. Polyarchy Score\", \n    title = \"Democracy by region, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )\n\n\n\n\nThis looks pretty good but frequently we would want the bars of our bar chart to be sorted in order of the values being displayed. Let‚Äôs go ahead and add the reorder() function to our aes() call so that we are reordering the bars based on descending values of the average polyarchy score.\n\nggplot(dem_summary, aes(x = reorder(region, -polyarchy), y = polyarchy)) +\n  geom_col(fill = \"steelblue\") + \n  labs(\n    x = \"Region\", \n    y = \"Avg. Polyarchy Score\", \n    title = \"Democracy by region, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )"
  },
  {
    "objectID": "modules/module-2.1.html#histograms",
    "href": "modules/module-2.1.html#histograms",
    "title": "Module 2.1",
    "section": "Histograms",
    "text": "Histograms\n\nNow let‚Äôs do another ggplot() call to make a histogram. We use histograms when we want to show how our data are distributed.\nWe‚Äôll start by reading in the dem_women.csv file from our previous lesson. From there, we call ggplot(), specifying the polyarchy score on x-axis. But this time we change the geom to geom_histogram(). We also change the title and axis labels to reflect the fact that we are plotting the number of cases falling in each bin.\n\n\n\n\n\n\nNote\n\n\n\nNote that we leave the y-axis blank for the histogram because ggplot will automatically know to plot the number of units in each bin on the y-axis.\n\n\n\ndem_women_2015 &lt;- read_csv(\"data/dem_women.csv\") |&gt; \n  filter(year == 2015) \n\nggplot(dem_women_2015, aes(x = polyarchy)) + # only specify x for histogram\n  geom_histogram(fill = \"steelblue\") + # geom is a histogram\n  labs(\n    x = \"Polyarchy Score, 2015\", \n    y = \"Count\",\n    title = \"Distribution of democracy, 2015\", \n    caption = \"Source: V-Dem Institute\"\n    )"
  },
  {
    "objectID": "modules/module-2.1.html#line-charts",
    "href": "modules/module-2.1.html#line-charts",
    "title": "Module 2.1",
    "section": "Line charts",
    "text": "Line charts\n\nNow let‚Äôs create a line chart. Line charts are usually the best option when we want to illustrate trends in our data. For this visualization, we will try to illustrate Samuel Huntington‚Äôs waves of democracy by showing how countries representing each of the three waves. The U.S. represents the first wave, Japan the second wave starting with the allied victory in WWII, and Portugal represents the first country to transition in the third wave.\nFirst, let‚Äôs grab the relevant data using vdemdata and dplyr. We are going to be downloading the polyarchy measure for the U.S., Japan and Portugal as far back as the data are available. So first we will select country name, year and the polyarchy schore and then we will filter the data based on the three country names. We are saving these data in an object called dem_waves_ctrs.\n\nlibrary(vdemdata)\n\ndem_waves_ctrs &lt;- vdem |&gt;\n  select(\n    country = country_name,     \n    year, \n    polyarchy = v2x_polyarchy, \n  ) |&gt;\n  filter( \n    country %in% c(\"United States of America\", # select countries in this list\n                   \"Japan\", \n                   \"Portugal\")\n    )\n\nwrite_csv(dem_waves_ctrs, \"data/dem_waves_ctrs.csv\")\n\nNext, we are going to do our ggplot() call. The data will be the dem_waves_ctrs object that we just created. For the aesthetics mapping, we will put the year on the x-axis and the polyarchy score on the y-axis. We will also specify color in the aes() call so that we can color the lines by region.\nTo get a line chart, we have to specify geom_line(). Then within the geom_line() function we will set the linewidth equal to ` so that the lines are a bit more visible.\nFinally, we will add a labs() call as with the previous visualizations. But in addition to title, axis labels and a caption, we will also add color = \"Country\" to change the label of the legend to ‚ÄúColor‚Äù with a capital ‚ÄúC.‚Äù\n\n# in this ggplot() call, we add a third dimension for line color\nggplot(dem_waves_ctrs, aes(x = year, y = polyarchy, color = country)) +\n  geom_line(linewidth = 1) + # our geom is a line with a width of 1\n  labs(\n    x = \"Year\", \n    y = \"Polyarchy Score\", \n    title = 'Democracy in countries representing three different \"waves\"', \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\" # make title of legend to upper case\n  )"
  },
  {
    "objectID": "modules/module-2.1.html#scatter-plots",
    "href": "modules/module-2.1.html#scatter-plots",
    "title": "Module 2.1",
    "section": "Scatter plots",
    "text": "Scatter plots\n\nThe last thing we are going to do in this lesson is to create a scatter plot. We use scatter plots in order to illustrate how two variables relate to each other (or not). In this example, we are going to illustrating modernization theory, which predicts a positive relationship between wealth and democracy, while also incorporating levels of women‚Äôs representation into our analysis.\nWe are going to start with the dem_women.csv file we created in Module 1.2. We will then group the data by country and calculate the mean for each variable. Note that in the group_by() call we also include region because we will want to keep it so that we can color our points by region.\n\ndem_summary_ctry &lt;- read_csv(\"data/dem_women.csv\") |&gt;\n  group_by(country, region) |&gt; # group by country, keep region\n  summarize(\n    polyarchy = mean(polyarchy, na.rm = TRUE),\n    gdp_pc = mean(gdp_pc, na.rm = TRUE), \n    flfp = mean(flfp, na.rm = TRUE), \n    women_rep = mean(women_rep, na.rm = TRUE)\n  )\n\nNow let‚Äôs create our first scatter plot. Our ggplot() call looks similar to previous ones except for a few things. First we are calling geom_point() for our geom. But also notice that our aesthetics mapping includes four dimenstions: x, y, color and size. So here we are telling ggplot2 that we want wealth on the x-axis, the polyarchy score on the y-axis, to color the points based on region, and to vary the size of the points in relation to the level of women‚Äôs representation.\nOne last thing we want to do is to put our x-axis on a log scale and change the labels to reflect their dollar values. For the log scale, we can use the scale_x_log10() function and for the labels we can use the label_number() function from the scales package. We set the prefix to ‚Äú$‚Äù and the suffix to ‚Äúk‚Äù so that each number on the x-axis starts with a dollar sign and ends with ‚Äúk‚Äù denoting ‚Äúthousands.‚Äù\n\n\n\n\n\n\nNote\n\n\n\nWe will encounter other useful scales functions including label_dollar() and label_percent() in future lessons.\nNotice that in this example we introduce the scales package by including it as a prefix to the label_number() function, e.g.¬†scales::label_number(prefix = \"$\", suffix = \"k\"). This allows us to use the package without having to load it, e.g.¬†library(scales). It also has the benefit of generating a list of auto-complete suggestions for the many available functions in the scales package.\n\n\n\n# in this ggplot() call we have four dimensions\n# x, y, color, and size\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy, color = region, size = women_rep)) + \n  geom_point() + # use geom_point() for scatter plots\n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Region\",\n    size = \"Women Reps\"\n    )\n\n\n\n\nThe plot does a good job of illustrating the basic point of modernization theory in that we do see the positive correlation between wealth and democracy. But we also see that there are some outliers and that a lot of the outlier countries are concentrated in the Middle East.\nWe also see that the distribution of women‚Äôs representation is somewhat orthogonal to wealth and democracy. Most wealthy western countries have high levels of women‚Äôs representation, but so do a lot of low- and middle-income countries in Africa, Asia and Latin America.\n\nAdding a trend line\nWe can definitely see a relationship between wealth and democracy in the scatter plot, but how strong is it? One way to find out is to add a trend line. Let‚Äôs do this by adding another geom, geom_smooth(), and specifying a linear model with the argument method = \"lm\" We acn also set the linewidth of the trend line to 1 so that the line is more visible.\nIf we want to add a single trend while also maintaining the coloring by region, then we have to reconfigure the ggplot() call a bit. Specifically, we will want to move color = region to a separate aes() call in the geom_point() function, e.g.¬†geom_point(aes(color = region)). If we don‚Äôt do this we will get separate trend lines for each region (try it and see!).\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy)) + \n  geom_point(aes(color = region)) + \n  geom_smooth(method = \"lm\", linewidth = 1) + \n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Region\"\n    )\n\n\n\n\n\n\nFacet wrapping\nNow let‚Äôs imagine that we really interested in drilling down into the ‚Äúheterogeneous effects‚Äù of wealth on democracy by region. In other words, we want to see more clearly how wealth is related to democracy in some regions but not others. For this, we can use facet_wrap() to get a separate chart for each region rather than just shading the points by region. Inside of facet_wrap() we identify region as the variable that we want to use to separate the plots, e.g.¬†facet_wrap(~region). Notice how we have to include a tilde (~) here.\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", linewidth = 1) + \n  facet_wrap(~ region) +\n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )\n\n\n\n\nHere we can clearly see a relationship between wealth and democracy in all of the countries except for the Middle East and Africa. We could speculate that the lack of a relationship in the Middle East could be evidence of an oil curse dynamic whereas perhaps the lack of a relationship in Africa is due to weak institutions.\nThe relationship between wealth and democracy in the West would be apparent, but it is obscured by the fact that western countries because the high wealth and polyarchy values result in extreme bunching in the northwest quadrant of the graph. To deal with this issue, we could add the scales = \"free\" argument to our plot.\n\nggplot(dem_summary_ctry, aes(x = gdp_pc, y = polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", linewidth = 1) + \n  facet_wrap(~ region, scales = \"free\") +\n  scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n  labs(\n    x= \"GDP per Capita\", \n    y = \"Polyarchy Score\",\n    title = \"Wealth and democracy, 1990 - present\", \n    caption = \"Source: V-Dem Institute\"\n    )\n\n\n\n\nBut notice there is a bit of a tradeoff here. With the scales = free option set, we now have separate axes for each of the plots. This is less of a clean look than having common x and y axes.\n\n\nLabeling points\nNow let‚Äôs try drilling down into one of the regions to get a better sense of what countries are driving the relationship. To do this, we can filter our data set for a region that we are interested in and then add country labels to the points in the scatter plot. Here we are going to filter for ‚ÄúAsia‚Äù and we will ad a geom_text() call to add country labels. In the geom_text() call we include arguments for size and vjust to adjust the size and vertical location of the labels relative to the points.\n\ndem_summary_ctry |&gt; \n  filter(region == \"Asia\") |&gt;\n  ggplot(aes(x = gdp_pc, y = polyarchy)) + \n    geom_point() + \n    geom_text(aes(label = country), size = 2, vjust = 2) +\n    geom_smooth(method = \"lm\", linewidth = 1) +\n    scale_x_log10(labels = scales::label_number(prefix = \"$\", suffix = \"k\")) +\n      labs(\n        x= \"GDP Per Capita\", \n        y = \"Polyarchy Score\",\n        title = \"Wealth and democracy in Asia, 1990 - present\", \n        caption = \"Source: V-Dem Institute\"\n        )"
  },
  {
    "objectID": "modules/module-2.2.html",
    "href": "modules/module-2.2.html",
    "title": "Module 2.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall plotly (install.packages(\"plotly\")) and have a look at the documentation\nInstall colorBlindness (install.packages(\"colorBlindness\")) and read this vignette\nInstall ggthemes (install.packages(\"ggthemes\"))\nGenerate a quarto document named ‚Äúmodule-2.2.qmd‚Äù in your ‚Äúmodules‚Äù project folder so that you can code along with me\nIn your quarto document, run these code chunks and familiarize yourself the data frames that they generate\n\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(wbstats)\nlibrary(countrycode)\n\nindicators = c(flfp = \"SL.TLF.CACT.FE.ZS\", gdp_pc = \"NY.GDP.PCAP.KD\") # define indicators\n\n## Regional levels of FLFP for column chart \n\nflfp_gdp_regions &lt;- \n  wb_data(\"SL.TLF.CACT.FE.ZS\", country = \"regions_only\", mrnev = 1) |&gt; \n  rename(\n    region = country,\n    year = date,\n    flfp = SL.TLF.CACT.FE.ZS\n  ) |&gt; \n  select(region, iso3c, year, flfp)\n  \nflfp_gdp_regions\n\n# A tibble: 7 √ó 4\n  region                     iso3c  year  flfp\n  &lt;chr&gt;                      &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 East Asia & Pacific        EAS    2021  58.9\n2 Europe & Central Asia      ECS    2021  51.6\n3 Latin America & Caribbean  LCN    2021  49.8\n4 Middle East & North Africa MEA    2021  18.2\n5 North America              NAC    2021  56.1\n6 South Asia                 SAS    2021  24.8\n7 Sub-Saharan Africa         SSF    2021  60.4\n\n## Cross-section of data on FLFP and GDP per capita for scatter plot\n\nflfp_gdp &lt;- wb_data(indicators, mrnev = 1) |&gt; # download most recent non-missing value of indicators\n    left_join(select(wb_countries(), c(iso3c, region)), by = \"iso3c\")  # add regions from countrycode()\n\nglimpse(flfp_gdp)\n\nRows: 224\nColumns: 7\n$ iso2c   &lt;chr&gt; \"AW\", \"AF\", \"AF\", \"AO\", \"AL\", \"AD\", \"AE\", \"AR\", \"AM\", \"AS\", \"A‚Ä¶\n$ iso3c   &lt;chr&gt; \"ABW\", \"AFG\", \"AFG\", \"AGO\", \"ALB\", \"AND\", \"ARE\", \"ARG\", \"ARM\",‚Ä¶\n$ country &lt;chr&gt; \"Aruba\", \"Afghanistan\", \"Afghanistan\", \"Angola\", \"Albania\", \"A‚Ä¶\n$ date    &lt;dbl&gt; 2021, 2020, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 20‚Ä¶\n$ gdp_pc  &lt;dbl&gt; 30271.8335, NA, 426.0300, 2299.6406, 4830.5963, 36839.8762, 42‚Ä¶\n$ flfp    &lt;dbl&gt; NA, 16.463, NA, 74.464, 51.653, NA, 52.789, 50.283, 57.779, NA‚Ä¶\n$ region  &lt;chr&gt; \"Latin America & Caribbean\", \"South Asia\", \"South Asia\", \"Sub-‚Ä¶\n\n## Time series data on regional trends in FLFP for line chart\n\nflfp_ts &lt;- wb_data(\"SL.TLF.CACT.FE.ZS\", country = \"regions_only\", start_date = 1990, end_date = 2022) |&gt; \n  rename(\n    region = country,\n    year = date,\n    flfp = SL.TLF.CACT.FE.ZS\n  ) |&gt; \n  select(region, iso3c, year, flfp)\n  \nglimpse(flfp_ts)\n\nRows: 224\nColumns: 4\n$ region &lt;chr&gt; \"East Asia & Pacific\", \"East Asia & Pacific\", \"East Asia & Paci‚Ä¶\n$ iso3c  &lt;chr&gt; \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", \"EAS\", ‚Ä¶\n$ year   &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 200‚Ä¶\n$ flfp   &lt;dbl&gt; 66.32925, 66.12070, 66.00342, 65.68375, 65.65046, 65.50232, 65.‚Ä¶"
  },
  {
    "objectID": "modules/module-2.2.html#overview",
    "href": "modules/module-2.2.html#overview",
    "title": "Module 2.2",
    "section": "Overview",
    "text": "Overview\nIn this module we are going to take our visualizations from Module 2.1 and improve them. In the first part of the lesson we are going to focused on how to make your visualizations accessible to a color-blind audience. Then we will discuss how to improve the look of your visualizations with themes and to provide additional information and context with annotations. Finally, we will spend some time talking about how to make your graphs interactive so that users can explore them in a more dynamic and flexible way."
  },
  {
    "objectID": "modules/module-2.2.html#color-schemes",
    "href": "modules/module-2.2.html#color-schemes",
    "title": "Module 2.2",
    "section": "Color schemes",
    "text": "Color schemes\n\nThere are a number of different types of color blindness, but the most common type is red-green color blindness. Making your visualizations colorblind-accessible can be important for convincing certain audiences. Most notably, approximately 8% of men are affected by color blindness.\nLet‚Äôs start off by looking at the line chart that we did in the last module pertaining to Huntington‚Äôs three waves of democratization:\n\ndem_waves_ctrs &lt;- read_csv(\"data/dem_waves_ctrs.csv\")\n\ndem_waves_chart &lt;- ggplot(dem_waves_ctrs, aes(x = year, y = polyarchy, color = country)) +\n  geom_line(linewidth = 1) + \n  labs(\n    x = \"Year\", \n    y = \"Polyarchy Score\", \n    title = 'Democracy in countries representing three different \"waves\"', \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\"\n  )\n\ndem_waves_chart\n\n\n\n\nThe problem with this plot is that people with red-green color blindness will not be able to distinguish between the lines for Japan and Portungal. There are many tools that we could use to see how this is true, but here we are going to focus on the color vision deficiency (CVD) simulator from the colorBlindness package. To use it, all we have to do is load colorBlindness and call cvdPlot() on the stored plot.\n\nlibrary(colorBlindness)\n\ncvdPlot(dem_waves_chart)\n\n\n\n\nIn this output, we can see how deuteranopia and protonopia (red-green color blindness) would experience our plot. Notice how hard it is to distinguish between Japan and Portugal here. We can also see how someone with monochromatic vision would see the plot by looking at the ‚Äúdesaturated (BW)‚Äù plot. While monochromatic vision is very rare, we can use this plot to make adjustments for a worst-case scenario.\nSo once you determine that your color scheme is not colorblind friendly, what should you do? There are two basic solutions available to you: making your own colorblind friendly color scheme or use a package that produces colorblind-friendly schemes for you.\n\nCreate your own colorblind-friendly color scheme\nThe first way to make your plot more accessible is to create your own discrete scale using scale_fill_manual() or scale_color_manual() (depending on what type of plot you are trying to draw).\nLet‚Äôs try using an example color scheme from the R Cookbook to fill in the bars of a column chart. Here we will make use of the regional levels of female labor force participation data that we prepped in the prework section of this module. First we create a vector of colors called cb_palette. Then we build our bar chart and save it as an object called flfp_region. Crucially, when we perform our ggplot call, we include fill = region as a third dimension in our aes() function. This is in addition to including the region code iso3c on the x-axis. Finally, we use our palette to shade our bars using scale_fill_manual().\n\ncb_palette &lt;- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nflfp_region &lt;- ggplot(flfp_gdp_regions, aes(x = reorder(iso3c, -flfp), y = flfp, fill = region)) +\n  geom_col() + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(\n    x = \"Region\", \n    y = \"Avg. Female Labor Force Participation\", \n    title = \"Levels of female labor force participation by region\", \n    fill = \"Region\",\n    caption = \"Source: World Bank\"\n    ) \n\nflfp_region + scale_fill_manual(values = cb_palette)\n\n\n\n\nNow we can check our visualization using the cvdPlot() function from the colorBlindness package.\n\nflfp_region &lt;- flfp_region + scale_fill_manual(values = cb_palette)\n\ncvdPlot(flfp_region)\n\n\n\n\nAlthough it would still be difficult for a person with red-green color blindness to see some of the colors in the chart (like the pink of SSF or the bright green of LAC), it would still be possible for them to distinguish the colors of the bars based on what would appear to them as shades of grey.\n\n\nUse viridis\nAnother option is to use a package designed with accessibility issues in mind. One of the more popular ones is the viridis() package. To use it just load viridis and add a viridis color scheme to the plot. You have the option of choosing continuous, discrete or binned color schemes but here we use the discrete option scale_fill_viridis_d() because our regions constitute a discrete variable. You can also try different viridis color maps by inserting the various available schemes in the function. For example you can get the ‚Äúplasma‚Äù map with `scale_fill_viridis_d(option = ‚Äúplasma‚Äù). The default map is ‚Äúviridis.‚Äù\n\nflfp_region + scale_fill_viridis_d()\n\n\n\n\nNow let‚Äôs run our bar chart with the viridis color mapping through cvdPlot:\n\nflfp_region &lt;- flfp_region + scale_fill_viridis_d()\n\ncvdPlot(flfp_region)\n\n\n\n\nThis is pretty good. In fact it looks fairly close to the original. It is even to easy to see the differences in colors when looking at the desaturated output. Of course the first column for the black and white plot is difficult to distinguish from the plot‚Äôs background, but we will learn how to change this up later in this module.\n\n\nUse ColorBrewer\nAnother package available to us is the RColorBrewer package. Technically, RColorBrewer is a separate package but its color mappings come available as part of ggplot2, so we don‚Äôt have to load RColorBrewer in order to use it with ggplot2. We can also use the color brewer palette selector tool to help select palettes that are ‚Äúcolorblind safe.‚Äù\nLet‚Äôs try updating our column chart with a ColorBrewer color scheme:\n\nflfp_region + scale_fill_brewer(palette = \"YlGn\") \n\n\n\n\nAnd now lets run it through the cvdPlot() function.\n\nflfp_region &lt;- flfp_region + scale_fill_brewer(palette = \"YlGn\")\n\ncvdPlot(flfp_region)\n\n\n\n\n\n\nScaling for scatter plots and line charts\nOne thing to note is that when we want to adjust the color scheme for a scatter plot or line chart, we should use ‚Äúscale_color‚Äù instead of ‚Äúscale_fill‚Äù, e.g.¬†scale_color_manual(), scale_color_viridis_d(), scale_color_brewer. Let‚Äôs try a couple of examples. First, let‚Äôs add a viridis color map to a scatter plot. We will use the flfp_gdp data we prepped in the prework section to generate our scatter plot.\n\nwealth_flfp &lt;- ggplot(flfp_gdp, aes(x = gdp_pc, y = flfp)) + \n  geom_point(aes(color = region)) + # color points by region\n  geom_smooth(method = \"loess\", linewidth = 1) +  # make the line a loess curve\n  scale_x_log10(labels = scales::label_dollar()) + # stretch axis, add '$' format\n  scale_y_continuous(labels = scales::label_percent(scale = 1)) + # add % label\n  labs(\n    x= \"GDP per Capita\", # x-axis title\n    y = \"Female Labor Force Participation\", # y-axis title\n    title = \"Wealth and female labor force participation\", # plot title\n    caption = \"Source: World Bank Development Indicators\", # caption\n    color = \"Region\" # legend title\n    )\n\nwealth_flfp + scale_color_viridis_d(option = \"plasma\")\n\n\n\n\nNow let‚Äôs try adding a ColorBrewer scheme to a line chart. Here we will use the flfp_ts data frame that we prepped in our prework routine.\n\nflfp_line &lt;- ggplot(flfp_ts, aes(x = year, y = flfp, color = region)) +\n  geom_line(linewidth = 1) + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(\n    x = \"Year\", \n    y = \"Female Labor Force Participation\", \n    title = \"Regional trends in female labor force participation\", \n    caption = \"Source: V-Dem Institute\", \n    color = \"Country\"\n  )\n\nflfp_line + scale_color_brewer(palette = \"YlOrRd\")"
  },
  {
    "objectID": "modules/module-2.2.html#themes",
    "href": "modules/module-2.2.html#themes",
    "title": "Module 2.2",
    "section": "Themes",
    "text": "Themes\n\nAnother thing that we can do to improve the overall look of our plots is to change the theme. Here is a list of themes that are available with ggplot2.\nThere are also many extension packages that you can use to apply even more themes, some of which we may encounter later in the course.\nFor now, let‚Äôs take a couple of plots that we developed earlier in the lesson and apply some ggplot2 themes to them. We can do this by simply adding the name of the theme to our code.\n\nwealth_flfp + scale_color_viridis_d(option = \"plasma\") + theme_dark()\n\n\n\n\n\nflfp_region + scale_fill_brewer(palette = \"YlGn\") + theme_minimal()"
  },
  {
    "objectID": "modules/module-2.2.html#annotations",
    "href": "modules/module-2.2.html#annotations",
    "title": "Module 2.2",
    "section": "Annotations",
    "text": "Annotations\n\nSometimes it makes sense to include annotations in our charts. We can achieve this by applying the annotate() function. To add a text annotation, we include ‚Äútext‚Äù for the first argument, then the value of x and y at which we want our annotation to appear, and finally the text of the annotation that we want to display. Let‚Äôs try adding text to our indicating where high-, middle- and low-income countries are concentraed on the wealth_flfp scatter plot that we developed earlier.\n\nwealth_flfp &lt;- wealth_flfp + scale_color_viridis_d(option = \"plasma\") + theme_minimal()\n\nwealth_flfp + annotate(\"text\", x = 90000, y = 75, label = \"Wealthy\") + \n  annotate(\"text\", x = 1000, y = 80, label = \"Low income\") +\n  annotate(\"text\", x = 10000, y = 20, label = \"Middle income\")\n\n\n\n\nAnother common annotation involves combining text with a horizontal or vertical reference line. For a horizontal intercept line we include an additional geom called geom_hline. The first argument is the value yintercept where we want the reference line to cross. Then we can add additional arguments to define the style, color and size of the line.\n\nflfp_line &lt;- flfp_line + scale_color_viridis_d() \n\nflfp_line + geom_hline(yintercept=52, linetype=\"dashed\", color = \"red\", size = 1) +\n  annotate(\"text\", x = 1995, y = 55, label = \"Global average\")\n\n\n\n\nThe same logic applies for a vertical reference line, except this time the geom is called geom_vline and the first argument, xintercept, is the point at which we want the line to cross the x-axis.\n\nflfp_line &lt;- flfp_line + scale_color_viridis_d() \n\nflfp_line + geom_vline(xintercept=2020, linetype = \"dashed\", size = 1) +\n  annotate(\"text\", x = 2017, y = 35, label = \"Pandemic\")"
  },
  {
    "objectID": "modules/module-2.2.html#interactivity",
    "href": "modules/module-2.2.html#interactivity",
    "title": "Module 2.2",
    "section": "Interactivity",
    "text": "Interactivity\n\nOne final thing we can do, which is really fun, is to add interactivity to our plots with plotly. We can do this by simply calling ggplotly() on our plot object.\n\nlibrary(plotly)\n\nggplotly(flfp_line)\n\n\n\n\n\nIn a lot of cases, we may want to control the tool tip of the plot. The tool tip is what appears when the user hovers over information on the chart. In this next example, the chart does not look that great unless we add the tooltip argument. But it is fairly simple to do. We just add the elements that we want to appear in a combine function, e.g.¬†c(). In this case we will include region and female labor force participation in the tool tip.\n\nflfp_region &lt;- flfp_region + scale_fill_brewer(palette = \"YlGn\") + theme_minimal()\n\nggplotly(flfp_region, tooltip = c(\"region\", \"flfp\")) # controlling the tooltip output\n\n\n\n\n\nAnother thing we may want to do is to include some additional annotations. We might also notice that some of the things we include in the labs argument in ggplot2 do not get picked up by plotly and that we have to add them back with a layout(annotations = ) call. One additional idiosyncrasy is that any item that we want to include in the plotly chart has to be passed as an argument in the ggplot code. For example, we need to include aes(label = country) to view country in tool tip. But plotly does support the R native pipe operator and that makes it a little easier to layer on multiple annotations.\n\nlibrary(plotly)\n\nwealth_flfp_plotly &lt;- wealth_flfp  + \n  scale_color_viridis_d(option = \"plasma\") +\n  theme_minimal() +\n  aes(label = country)  # need so ggplot retains label for plotly\n\nggplotly(wealth_flfp_plotly, tooltip = c(\"country\", \"flfp\", \"gdp_pc\")) |&gt; \n  \n  layout(annotations = list(text = \"Source: World Bank Development Indicators\",  \n                            font = list(size = 10), showarrow = FALSE,\n                            xref = 'paper', x = 1.1, xanchor = 'right', xshift = 0,\n                            yref = 'paper', y = -.1, yanchor = 'auto', yshift = 0)) |&gt; \n  # add web address\n  layout(annotations = list(text = \"www.dataviz-gwu.rocks\", \n                            font = list(size = 10, color = 'grey'), showarrow = FALSE,\n                            xref = 'paper', x = .5, xanchor = 'center', xshift = 0,\n                            yref = 'paper', y = 1, yanchor = 'top', yshift = 0))\n\n\n\n\n\nNotice that plotly has some fairly unique syntax for the layout() function. It helps to read the documentation but also to search around on google and Stack Overflow. Each annotation needs to be inputted in a list format. The first time in the list is the text you want to include in the annotation. From there you can include multiple arguments to specify the font size and location of the annotation."
  },
  {
    "objectID": "modules/module-3.1.html",
    "href": "modules/module-3.1.html",
    "title": "Module 3.1",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall rnaturalearth (install.packages(\"rnaturalearth\")) and have a look at the documentation\nInstall ggthemes (install.packages(\"ggthemes\"))and have a look at this post) for a brief explanation of how it works\nCreate a Quarto document called ‚Äúmodule-3.1.qmd‚Äù in your modules folder for the code-along\nInstall magick and underlying file system to remove whitespace around maps\nThen insert this code chunk somewhere in your module 3.1 Quarto document:\n\n\n# create a hook to crop maps as recommended by pmassicotte\n# must have `magick` and its dependencies installed\n\nknitr::knit_hooks$set(crop = knitr::hook_pdfcrop)"
  },
  {
    "objectID": "modules/module-3.1.html#overview",
    "href": "modules/module-3.1.html#overview",
    "title": "Module 3.1",
    "section": "Overview",
    "text": "Overview\nThe focus of this module is going to be on how to make choropleth maps. A choropleth map is a type of data visualization used to show a geographical distribution of data where areas or regions are shaded based on quantities or levels represented in each area or region.\nOne important concept in mapping that we are going to come across this week: simple features. Simple features is a formal international standard for representing objects in the real world in digital space.\nA ‚Äúfeature‚Äù is basically any object in the real world that can be represented in two or three-dimensional space. A tree or a house can be a feature as can a forest or a body of water. But in politics we are usually focused on mapping the political boundaries of different administrative units like countries, states or provinces, counties and cities.\nSimple features allow us to work with such boundaries easily in a data frame in R. We can take all of the points associated with a geometry and store it in a special data frame column (usually labeled ‚Äògeom‚Äô or ‚Äògeometry‚Äô). This ability to store all of the geographic information in one column differs from how spatial data are organized under the traditional spatial objects standard and makes it much easier to work with geographic data in R."
  },
  {
    "objectID": "modules/module-3.1.html#using-rnaturalearth",
    "href": "modules/module-3.1.html#using-rnaturalearth",
    "title": "Module 3.1",
    "section": "Using rnaturalearth",
    "text": "Using rnaturalearth\n\nIn this module we are going to be with the rnaturalearth package, which facilitates working with Natural Earth map data in R. Natural Earth is a public domain map dataset based on Tom Patterson‚Äôs Natural Earth projection that provides data suitable for making small-scale world, regional and country maps. Natural Earth contains country boundaries, first-order admin boundaries like provinces and states, urban polygons and more. rnaturalearth supports both simple features (sf) and spatial objects (sp) formats, but we are going to be focused on using simple features for the reasons stated earlier.\n\nGrabbing country shapes with ne_countries()\nLet‚Äôs start by loading country shapes using the ne_countries() function from rnaturalearth. We will start by loading rnaturalearth and dplyr. Next we will load the country boundaries into an object called world_map_df while filtering out Antarctica. Then, let‚Äôs glimpse() the data and have a closure look at the geometry column.\n\nlibrary(rnaturalearth)\nlibrary(dplyr)\n\nworld_map_df &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\") |&gt;\n    filter(name != \"Antarctica\") # remove Antarctica\n\n#world_map_df |&gt;\n#glimpse()\n\n# view contents of geometry column\nworld_map_df |&gt;\n  select(geometry) \n\nSimple feature collection with 241 features and 0 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -58.49229 xmax: 180 ymax: 83.59961\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                         geometry\n1  MULTIPOLYGON (((31.28789 -2...\n2  MULTIPOLYGON (((30.39609 -1...\n3  MULTIPOLYGON (((53.08564 16...\n4  MULTIPOLYGON (((104.064 10....\n5  MULTIPOLYGON (((-60.82119 9...\n6  MULTIPOLYGON (((12.43916 41...\n7  MULTIPOLYGON (((166.7458 -1...\n8  MULTIPOLYGON (((70.94678 42...\n9  MULTIPOLYGON (((-53.37061 -...\n10 MULTIPOLYGON (((162.9832 5....\n\n\n\n\nMake a map with geom_sf()\nNow, let‚Äôs make our first choropleth map with the data. Let‚Äôs map World Bank income groups. Here we will use the special features geom_sf() from ggplot2 and for our aesthetics mapping we will specify fill = income_grp.\n\nlibrary(ggplot2)\n\nggplot(data = world_map_df) +\n  geom_sf(aes(fill = income_grp)) + \n  labs(title = \"World Bank country income categories\")\n\n\n\n\n\n\nBeautify your map\nThe default ggplot settings are pretty good for a preview, but we could make it look a lot better. Let‚Äôs add some labels, a ggtheme map theme and the default viridis color mapping.\n\nlibrary(ggthemes)\n\nggplot(data = world_map_df) +\n  geom_sf(aes(fill = income_grp)) + \n  labs(\n    title = \"World Bank country income categories\",\n    fill = \"Category\"\n    ) +\n    scale_fill_viridis_d() +\n    theme_map()"
  },
  {
    "objectID": "modules/module-3.1.html#using-rnaturalearth-to-map-other-data",
    "href": "modules/module-3.1.html#using-rnaturalearth-to-map-other-data",
    "title": "Module 3.1",
    "section": "Using rnaturalearth to map other data",
    "text": "Using rnaturalearth to map other data\n\nNow that we know how to make a map with Natural Earth shapes and geom_sf(), we can merge in data and map data from other sources. Let‚Äôs go ahead and merge some data on oil rents from the World Bank. We will do a left_join() based on iso3c country codes. In the World Bank data the iso3c codes are simply called ‚Äúiso3c.‚Äù In rnaturalearth there are a number of options, but the best is ‚Äúiso3_a3_eh‚Äù because at the time this lesson was written the codes for some of the others are missing.\n\nlibrary(wbstats)\n\noil_rents_df &lt;- wb_data(c(oil_rents_gdp = \"NY.GDP.PETR.RT.ZS\"), mrnev = 1) \n\nrents_map_df &lt;- left_join(world_map_df, oil_rents_df, join_by(iso_a3_eh == iso3c))\n\nrents_map_df |&gt;\n  select(last_col(5):last_col()) |&gt; #select last 5 columns of df\n  glimpse() \n\nRows: 241\nColumns: 6\n$ date          &lt;dbl&gt; 2021, 2021, 2018, 2021, 2014, NA, 2021, 2021, 2021, NA, ‚Ä¶\n$ oil_rents_gdp &lt;dbl&gt; 0.047768809, 0.000000000, 4.823561531, 0.669314215, 11.3‚Ä¶\n$ obs_status    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ footnote      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ last_updated  &lt;date&gt; 2023-03-30, 2023-03-30, 2023-03-30, 2023-03-30, 2023-03‚Ä¶\n$ geometry      &lt;MULTIPOLYGON [¬∞]&gt; MULTIPOLYGON (((31.28789 -2..., MULTIPOLYGO‚Ä¶\n\n\nNow we can map these data. Everything here is pretty much the same as before, except we change the fill to oil_rents_gdp. We will also add a subtitle and make a few other cosmetic changes like shifting the position of the legend title, bolding the plot title and changing the viridis color scale from discrete to continuous.\n\nggplot(data = rents_map_df) +\n  geom_sf(aes(fill = oil_rents_gdp)) + # shade based on oil rents\n  labs(\n    title = \"Oil rents (% of GDP)\",\n    subtitle = \"(Most recent available data)\", # add subtitle\n    fill = \"Percent\", \n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(\n    legend.position = \"right\", \n    #legend.title = element_text(size = 8),\n    #legend.text = element_text(size = 6)\n    plot.title = element_text(face = \"bold\"), # move legend\n    ) +\n  scale_fill_viridis_c( # chg from discrete (_d) to continuous (_c)\n      option = \"magma\", #  chg to magma theme\n      labels = scales::label_percent(scale = 1) # add % label for legend\n      )"
  },
  {
    "objectID": "modules/module-3.1.html#turn-your-map-into-a-function",
    "href": "modules/module-3.1.html#turn-your-map-into-a-function",
    "title": "Module 3.1",
    "section": "Turn your map into a function",
    "text": "Turn your map into a function\n\nSometimes you may want to map more than one variable in a paper or display variables with a map in an app. For these situations, it can help to create your own function that allows you to change various components of the map code without having to type out all of the code every time you want to create a map.\n\nCreate the map function\nThe first thing that you want to do is to write out the script for your function. That should include any packages that you need to run that may not already be loaded.\nFrom there, you can build your function. The code for your function contains three elements: 1) a name; 2) the arguments you will include in your function; and 3) a code block of code that will execute when you call the function.\nIn this example, we are going to call our function create_map(). It is going to include five arguments: var_id, title, legend_title, theme and direction. var_id refers to the World Bank variable id, title and legend_title refer to the title of the plot and the title of the legend respectively. theme will allow the user to adjust the viridis theme. And direction refers to whether the color scale is light to dark or dark to light.\nThe code block will first join the country shapes to the selected World Bank data and then map those data by piping them into a ggplot() call. Everything is pretty similar to our previous use of ggplot() and geom_sf(), but one tricky part here is that we have to use eval(parse(text=var_id)))) to remove the quotes surrounding the variable code entered by the user.\n\nlibrary(rnaturalearth)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(wbstats)\n\ncreate_map &lt;- function(var_id, title, legend_title, theme, direction){\n\nne_countries(scale = \"medium\", returnclass = \"sf\") |&gt; \n  left_join(\n    wb_data(var_id, mrnev = 1), # change variable id\n    join_by(iso_a3_eh == iso3c)\n  ) |&gt; \n  filter(name != \"Antarctica\") |&gt;  \n  ggplot() + \n  geom_sf(aes(fill = eval(parse(text=var_id)))) + # remove quotes\n  labs(\n    title =  title, # change title\n    fill = legend_title, # change legend title\n    caption = \"Source: World Bank Development Indicators\"\n    ) +\n  theme_map() +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n  ) +\n  scale_fill_viridis_c( \n    option = \"magma\", #  chg theme\n    direction = direction # change direction of scale\n    )\n}\n\n\n\nDeploy the function in another document\nTo deploy the function in a Quarto or R Markdown dackument, we need to source it as an external R script. First we will save the previous code as a source document. Let‚Äôs name our file web-maps.R and save it in a subdirectory called functions. From there, we can use the source() function so that we can call our create_map() function in subsequent code chunks in our document.\n\nsource(\"functions/wb-maps.R\", local = knitr::knit_global())\n\nNow let‚Äôs call our create_map() function that we just made using female labor force particpation.\n\ncreate_map(var_id = \"SL.TLF.CACT.FE.ZS\", \n           title= \"Female Labor Force Participation\", \n           legend_title = \"FLFP %\", \n           theme = \"inferno\", \n           direction = -1)\n\n\n\n\nNow search for an indicator we want to use. We will look for something related to GDP per capita.\n\nwb_search(\"GDP per capita\") \n\n# A tibble: 24 √ó 3\n   indicator_id       indicator                                          indic‚Ä¶¬π\n   &lt;chr&gt;              &lt;chr&gt;                                              &lt;chr&gt;  \n 1 5.51.01.10.gdp     Per capita GDP growth                              GDP pe‚Ä¶\n 2 6.0.GDPpc_constant GDP per capita, PPP (constant 2011 international ‚Ä¶ GDP pe‚Ä¶\n 3 NV.AGR.PCAP.KD.ZG  Real agricultural GDP per capita growth rate (%)   The gr‚Ä¶\n 4 NY.GDP.PCAP.CD     GDP per capita (current US$)                       GDP pe‚Ä¶\n 5 NY.GDP.PCAP.CN     GDP per capita (current LCU)                       GDP pe‚Ä¶\n 6 NY.GDP.PCAP.KD     GDP per capita (constant 2010 US$)                 GDP pe‚Ä¶\n 7 NY.GDP.PCAP.KD.ZG  GDP per capita growth (annual %)                   Annual‚Ä¶\n 8 NY.GDP.PCAP.KN     GDP per capita (constant LCU)                      GDP pe‚Ä¶\n 9 NY.GDP.PCAP.PP.CD  GDP per capita, PPP (current international $)      This i‚Ä¶\n10 NY.GDP.PCAP.PP.KD  GDP per capita, PPP (constant 2017 international ‚Ä¶ GDP pe‚Ä¶\n# ‚Ä¶ with 14 more rows, and abbreviated variable name ¬π‚Äãindicator_desc\n\n\nNow let‚Äôs take that info. and use it to make a plot of GDP per capita.\n\ncreate_map(var_id = \"NY.GDP.PCAP.PP.KD\", \n           title= \"GDP per capita (constant 2017 internatioal $)\", \n           legend_title = \"Geary-Khamis $\", \n           theme = \"mako\", \n           direction = -1)\n\n\n\n\nThere you go! That‚Äôs how we can build and use a map function to easily map different indicators in our document or web app."
  },
  {
    "objectID": "modules/module-3.2.html",
    "href": "modules/module-3.2.html",
    "title": "Module 3.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall states, leaflet, simple features and html tools and have a look at the documentation for each.\n\ninstall.packages(c(\"states\", \"leaflet\", \"sf\", \"htmltools))"
  },
  {
    "objectID": "modules/module-3.2.html#overview",
    "href": "modules/module-3.2.html#overview",
    "title": "Module 3.2",
    "section": "Overview",
    "text": "Overview\nThis module is going to introduce you to how to make maps with markers and pop-ups using leaflet. Markers are icons or symbols that show where something is located. Pop-ups are fields that display information about a location on a map. Together, pop-ups and markers allow you to show information related to a particular point or feature on a map without having to navigate away from the current view.\nMarkers and pop-ups can be used to display information such as an address or the name of a city or town. You can customize how pop-ups look, choose what data to display in them. As you get more advanced, you can do even more cool things like link them to other pages or external websites."
  },
  {
    "objectID": "modules/module-3.2.html#working-with-ucdp-data",
    "href": "modules/module-3.2.html#working-with-ucdp-data",
    "title": "Module 3.2",
    "section": "Working with UCDP data",
    "text": "Working with UCDP data\n\nOur running example in this module is going to involve mapping conflict events for Yemen from the Uppsala Conflict Data Program UCDP. So while we will be building on some of our earlier knowledge, this module is going to depart a bit from previous ones in that we are using an entirely new dataset. Specifically, we will be using the UCDP georeferenced event dataset, which you can download from here.\nAfter you have downloaded the data and saved it in your modules folder, go ahead and, read it in and have a look at its contents with gplimpse().\n\n\n\n\n\n\nNote\n\n\n\nI am working with a truncated version of the UCDP GED data so that I can upload everything to GitHub. Consequently, my glimpse() output may look slightly different from yours if you are using the full data.\n\n\n\nlibrary(readr)\nlibrary(dplyr)\n\nged_data &lt;- read_csv(\"data/GEDEvent_v22_1.csv\")\n\nglimpse(ged_data)\n\nRows: 16,609\nColumns: 49\n$ id                &lt;dbl&gt; 412700, 413023, 412909, 374227, 374229, 374396, 3749‚Ä¶\n$ relid             &lt;chr&gt; \"IRQ-2021-1-524-145\", \"IRQ-2021-1-524-143\", \"IRQ-202‚Ä¶\n$ year              &lt;dbl&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021‚Ä¶\n$ active_year       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ code_status       &lt;chr&gt; \"Clear\", \"Clear\", \"Clear\", \"Clear\", \"Clear\", \"Clear\"‚Ä¶\n$ type_of_violence  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ conflict_dset_id  &lt;dbl&gt; 259, 259, 259, 333, 333, 333, 333, 333, 333, 333, 33‚Ä¶\n$ conflict_new_id   &lt;dbl&gt; 259, 259, 259, 333, 333, 333, 333, 333, 333, 333, 33‚Ä¶\n$ conflict_name     &lt;chr&gt; \"Iraq: Government\", \"Iraq: Government\", \"Iraq: Gover‚Ä¶\n$ dyad_dset_id      &lt;dbl&gt; 524, 524, 524, 735, 735, 735, 735, 735, 735, 735, 73‚Ä¶\n$ dyad_new_id       &lt;dbl&gt; 524, 524, 524, 735, 735, 735, 735, 735, 735, 735, 73‚Ä¶\n$ dyad_name         &lt;chr&gt; \"Government of Iraq - IS\", \"Government of Iraq - IS\"‚Ä¶\n$ side_a_dset_id    &lt;dbl&gt; 116, 116, 116, 130, 130, 130, 130, 130, 130, 130, 13‚Ä¶\n$ side_a_new_id     &lt;dbl&gt; 116, 116, 116, 130, 130, 130, 130, 130, 130, 130, 13‚Ä¶\n$ side_a            &lt;chr&gt; \"Government of Iraq\", \"Government of Iraq\", \"Governm‚Ä¶\n$ side_b_dset_id    &lt;dbl&gt; 234, 234, 234, 303, 303, 303, 303, 303, 303, 303, 30‚Ä¶\n$ side_b_new_id     &lt;dbl&gt; 234, 234, 234, 303, 303, 303, 303, 303, 303, 303, 30‚Ä¶\n$ side_b            &lt;chr&gt; \"IS\", \"IS\", \"IS\", \"Taleban\", \"Taleban\", \"Taleban\", \"‚Ä¶\n$ number_of_sources &lt;dbl&gt; 15, 5, 8, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, ‚Ä¶\n$ source_article    &lt;chr&gt; \"\\\"BBC News,2021-08-26,Explosion at Kabul airport\\\";‚Ä¶\n$ source_office     &lt;chr&gt; \"BBC News;ShamshadNews on Twitter;Reuters News;Assoc‚Ä¶\n$ source_date       &lt;chr&gt; \"2021-08-26;2021-08-26;2021-08-27;2021-08-27;2021-08‚Ä¶\n$ source_headline   &lt;chr&gt; \"Explosion at Kabul airport;At least 11 people kille‚Ä¶\n$ source_original   &lt;chr&gt; \"US officials; Taliban spokesman Zabihullah Mujahid;‚Ä¶\n$ where_prec        &lt;dbl&gt; 1, 1, 1, 1, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2‚Ä¶\n$ where_coordinates &lt;chr&gt; \"Kabul international airport\", \"Jalalabad town\", \"Ka‚Ä¶\n$ where_description &lt;chr&gt; \"Kabul airport (Abbey gate entrance)\", \"Police Distr‚Ä¶\n$ adm_1             &lt;chr&gt; \"Kabul province\", \"Nangarhar province\", \"Kabul provi‚Ä¶\n$ adm_2             &lt;chr&gt; \"Kabul district\", \"Jalalabad district\", \"Kabul distr‚Ä¶\n$ latitude          &lt;dbl&gt; 34.56444, 34.42884, 34.53109, 31.61180, 31.64045, 31‚Ä¶\n$ longitude         &lt;dbl&gt; 69.21722, 70.45575, 69.16280, 65.70579, 65.39759, 64‚Ä¶\n$ geom_wkt          &lt;chr&gt; \"POINT (69.2172222 34.5644444)\", \"POINT (70.45575 34‚Ä¶\n$ priogrid_gid      &lt;dbl&gt; 179779, 179061, 179779, 175452, 175451, 175449, 1790‚Ä¶\n$ country           &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghan‚Ä¶\n$ country_id        &lt;dbl&gt; 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 70‚Ä¶\n$ region            &lt;chr&gt; \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"Asi‚Ä¶\n$ event_clarity     &lt;dbl&gt; 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ date_prec         &lt;dbl&gt; 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ date_start        &lt;dttm&gt; 2021-08-26, 2021-08-28, 2021-08-29, 2021-01-01, 202‚Ä¶\n$ date_end          &lt;dttm&gt; 2021-08-26, 2021-08-28, 2021-08-29, 2021-01-01, 202‚Ä¶\n$ deaths_a          &lt;dbl&gt; 13, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ deaths_b          &lt;dbl&gt; 1, 2, 0, 0, 7, 13, 0, 7, 6, 18, 13, 12, 12, 14, 14, ‚Ä¶\n$ deaths_civilians  &lt;dbl&gt; 141, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ deaths_unknown    &lt;dbl&gt; 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ best              &lt;dbl&gt; 183, 2, 10, 1, 7, 13, 4, 7, 6, 18, 13, 12, 12, 14, 1‚Ä¶\n$ high              &lt;dbl&gt; 184, 3, 10, 1, 16, 12, 4, 16, 16, 18, 12, 13, 13, 14‚Ä¶\n$ low               &lt;dbl&gt; 171, 0, 9, 1, 7, 13, 4, 6, 7, 18, 13, 12, 12, 14, 14‚Ä¶\n$ gwnoa             &lt;dbl&gt; 645, 645, 645, 700, 700, 700, 700, 700, 700, 700, 70‚Ä¶\n$ gwnob             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n\n\nOne thing we have to manage right away is the specific country codes used in these data. There is a whole art to managing international standards organization (ISO) codes which we have already touched on in our discussion of the countrycodes package. For the pruposes of this course, it is enough to be aware of the fact that country-level data sets use different coding systems and that this poses a small hurdle to the visualization and analysis of country-level data.\nFor this analysis, we are going to want to filter by country and specifically we want conflict data for Yemen. According to the UCDP codebook, this dataset uses Gleditsch-Ward (GW) country identifiers. One option could be to simply look up the GW country code for Yemen. But there is also a nice package developed called states. It has a function called sfind() that we can use to find the relevant country code.\n\nlibrary(states)\n\nsfind(\"Yemen\")[1:6]\n\n    list ccode code3c                   country_name      start        end\n169   GW   678    YEM Yemen (Arab Republic of Yemen) 1918-10-30 9999-12-31\n170   GW   680    YPR    Yemen, People's Republic of 1967-11-30 1990-05-21\n428  COW   678    YAR            Yemen Arab Republic 1926-09-02 1990-05-21\n429  COW   679    YEM                          Yemen 1990-05-22 9999-12-31\n430  COW   680    YPR        Yemen People's Republic 1967-11-30 1990-05-21\n\n\nHere we see that the GW code for Yemen is 678. Although there are many listings for Yemen, we know that it is the right code because the Arab Republic of Yemen (our other option for a GW Yemen code) ceased to exist in 1990 following its unification with the People‚Äôs Democratic Republic of Yemen.\nLet‚Äôs go ahead and use our newly discovered country code to wrangle some data for Yemen. We will filter for Yemen‚Äôs country ID and events from 2021 and, to keep things manageable, we will only include events that started before March 1 2021.\nLooking again at the codebook, we see there are codings for how certain the coders were regarding where an event occurred and that they also coded for the quality of the reporting. We will keep events with a location precision score less than 3 and an event clarity score equal to 1.\nFrom there we will create a new variable deaths that sums the different categories of deaths (side a, side b, civilian and unknown). Then we will select all of these variables and the location coordinates and use the st_as_sf() function from the sf package to conver the coordinates into simple features objects.\n\nged_yemen &lt;- ged_data |&gt; \n  filter(\n    country_id == 678, #gw country code\n    year == 2021,\n    date_start &lt; \"2021-03-01\", \n    where_prec &lt; 3, # keep if certain where event occurred\n    event_clarity == 1, # keep if event reporting is clear\n      ) |&gt; \n  mutate(deaths = deaths_a + deaths_b + deaths_civilians + deaths_unknown) |&gt;\n  select(event_id = id,\n         country_id,\n         date = date_start,\n         gov_deaths = deaths_a, \n         rebel_deaths = deaths_b, \n         civilian_deaths = deaths_civilians, \n         deaths, \n         place = where_coordinates,\n         latitude, \n         longitude) |&gt;\n  sf::st_as_sf(coords = c(\"longitude\", \"latitude\")) \n\nglimpse(ged_yemen)\n\nRows: 83\nColumns: 9\n$ event_id        &lt;dbl&gt; 378022, 378424, 378425, 378904, 378908, 378942, 386614‚Ä¶\n$ country_id      &lt;dbl&gt; 678, 678, 678, 678, 678, 678, 678, 678, 678, 678, 678,‚Ä¶\n$ date            &lt;dttm&gt; 2021-01-06, 2021-01-14, 2021-01-20, 2021-01-22, 2021-‚Ä¶\n$ gov_deaths      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ‚Ä¶\n$ rebel_deaths    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ civilian_deaths &lt;dbl&gt; 6, 1, 1, 1, 1, 1, 1, 1, 5, 1, 7, 1, 1, 1, 3, 1, 1, 0, ‚Ä¶\n$ deaths          &lt;dbl&gt; 6, 1, 1, 1, 1, 1, 1, 1, 5, 1, 7, 1, 1, 1, 3, 1, 1, 2, ‚Ä¶\n$ place           &lt;chr&gt; \"Al ·∏®aymah as Sufl√° area\", \"WƒÅdƒ´ al ·∏®ƒÅjib village\", \"A‚Ä¶\n$ geometry        &lt;POINT&gt; POINT (44.06 13.70564), POINT (44.04394 13.74153), P‚Ä¶"
  },
  {
    "objectID": "modules/module-3.2.html#make-a-leaflet-map",
    "href": "modules/module-3.2.html#make-a-leaflet-map",
    "title": "Module 3.2",
    "section": "Make a leaflet map",
    "text": "Make a leaflet map\n\nNow that we have our data, let‚Äôs make our first pop-up map. To do this we are going to be using the leaflet package. Leaflet is a really popular JavaScript library for interactive maps. To get started with leaflet, we‚Äôll make a really simple map with one marker that says ‚ÄúFirst conflict event.‚Äù\n\nPlot a single marker\nLet‚Äôs start with a really simple hypothetical example. Let‚Äôs say we want to plot one conflict event that we have the coordinates for and label it ‚ÄúFirst conflict event.‚Äù To do this, we would first call the leaflet()function. From there will add default street map tiles with addTiles() and then our single pop-up marker with addMarkers().\n\nlibrary(leaflet)\n\nleaflet() |&gt;\n  addTiles() |&gt;  # Add default OpenStreetMap map tiles\n  addMarkers(lng = 45.46916, lat = 14.14912, label = \"First conflict event\")\n\n\n\n\n\n\n\nPlot some conflict events from Yemen\nNow that you have the hang of it, we can move on to plotting some conflict events from our data frame. Again we will call leaflet() but this time we will add data = ged_yemen as an argument. We will also use setView() to center the map on Yemen‚Äôs capital Sana‚Äôa. We include two arguments for addMarkers. popup = ~as.character(deaths) displays the number of deaths when the user clicks on the marker and label = ~place displays the name of the town that the coordinates correspond to.\n\n\n\n\n\n\nNote\n\n\n\nNote that arguments for the popup = argument take the form of a one-sided formula, meaning that they require a tilde (~) as a prefix. Scroll to the bottom of this page for a more detailed explanation of the ~ notation in this context.\n\n\n\nleaflet(data = ged_yemen) |&gt; # map points in ged_yemen data frame\n  addTiles() |&gt; # add default tile\n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |&gt; # Sana'a coordinates\n  addMarkers(\n    popup = ~as.character(deaths), # when user clicks, show deaths\n    label = ~place # when user hovers, show town\n    )"
  },
  {
    "objectID": "modules/module-3.2.html#customize-your-leaflet-map",
    "href": "modules/module-3.2.html#customize-your-leaflet-map",
    "title": "Module 3.2",
    "section": "Customize your leaflet map",
    "text": "Customize your leaflet map\n\nNext, let‚Äôs do some customization to make our map look amazing. We will talk about changing the icon style, customized the information displayed in the icon and adding base maps.\n\nUse an awesome icon\nWe can dress our leaflet map up a little bit with the addAwesomeMarkers() function which allows us to use the glyphicons, font awesome and ionicons libraries.\nFirst we will use awesomeIcons() to store the icon we want to use. Here we choose ‚Äúios-close‚Äù from the ionic library. We will say that we want the icon colorto be black and the surrounding marker color to be red. Then we call addAwesomeMarkers() and specify icon = icon to call the red and black ionic marker.\n\n# save icon\nicon &lt;- awesomeIcons(\n  icon = \"ios-close\",\n  iconColor = \"black\",\n  markerColor = \"red\", \n  library = \"ion\" \n)\n\n# Build map\nleaflet(data = ged_yemen) |&gt;   \n  addTiles() |&gt; \n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |&gt; # Sana'a coordinates\n  addAwesomeMarkers(\n    icon = icon, \n    popup = ~as.character(deaths), \n    label = ~place\n    )\n\n\n\n\n\n\n\nChange content of the popup\nLet‚Äôs say we want to add more information to our pop-up when the user clicks on it. Instead of just showing the total number of deaths, we also want to show the date of the event and the breakdown of government deaths, rebel deaths and civilian deaths.\nThe easiest way to do this is going to be to add a column to our data frame with a label associated with each event. We will use the base R sprintf() function combined with htmltools to create these labels. sprintf() returns a formatted string using values in a list. The first parameter in sprintf is the format and the second is the values that go into the format.\nIn this example, we are separating the lines of our label with html () and we are passing in a string (%s) for the date and numeric values (%.0f) for the number of deaths.\nThen we call HMTL from htmltools and use lapply() to apply the function to every line in the data frame.\n\nged_yemen$popup_text &lt;- sprintf(\n      \"Date: %s &lt;br&gt; \n       Total Deaths: %.0f &lt;br&gt; \n       Govt. Deaths: %.0f &lt;br&gt; \n       Rebel Deaths: %.0f &lt;br&gt; \n       Civilian Death: %.0f &lt;br&gt;\",\n      ged_yemen$date, \n      ged_yemen$deaths, \n      ged_yemen$gov_deaths, \n      ged_yemen$rebel_deaths,\n      ged_yemen$civilian_deaths\n    ) |&gt; lapply(htmltools::HTML)\n\nNow we can use the new labels to enhance the markers by specifying popup = ~popup_text in the addAwesomeMarkers() function.\n\nleaflet(data = ged_yemen) |&gt;  \n  addTiles() |&gt; \n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |&gt; # Sana'a coordinates\n  addAwesomeMarkers(\n    icon = icon, \n    popup = ~popup_text, \n    label = ~place\n    )\n\n\n\n\n\nNow let‚Äôs spot check the labels.\n\nged_yemen |&gt;\n  filter(place == \"Marib Dam\")\n\nSimple feature collection with 1 feature and 9 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 45.24417 ymin: 15.39639 xmax: 45.24417 ymax: 15.39639\nCRS:           NA\n# A tibble: 1 √ó 10\n  event_id country_id date                gov_dea‚Ä¶¬π rebel‚Ä¶¬≤ civil‚Ä¶¬≥ deaths place\n*    &lt;dbl&gt;      &lt;dbl&gt; &lt;dttm&gt;                  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;\n1   385602        678 2021-02-26 00:00:00        34      27       0     61 Mari‚Ä¶\n# ‚Ä¶ with 2 more variables: geometry &lt;POINT&gt;, popup_text &lt;list&gt;, and abbreviated\n#   variable names ¬π‚Äãgov_deaths, ¬≤‚Äãrebel_deaths, ¬≥‚Äãcivilian_deaths\n\n\n\n\nUsing basemaps\nAs a last step, let‚Äôs change the basemap. We can do this by specifying addProviderTiles() instead of addTiles() and specifying the basemap that we want to use. Here is a list of available basemaps. For this example, we are going to use ‚ÄúOpenTopoMap.‚Äù\n\nleaflet(data = ged_yemen) |&gt; # Jan and Feb  \n  addProviderTiles(\"OpenTopoMap\") |&gt; # include name of provider here\n  setView(lng = 44.1910, lat = 15.3694, zoom = 6) |&gt; # Sana'a coordinates\n  addAwesomeMarkers(\n    icon = icon, \n    popup = ~popup_text, \n    label = ~place\n    )\n\n\n\n\n\nNow we can see a bit more about the topography, which could be super-useful for conflict analysis."
  },
  {
    "objectID": "modules/module-4.1.html",
    "href": "modules/module-4.1.html",
    "title": "Module 4.1",
    "section": "",
    "text": "Prework\n\n\n\n\nGet a U.S. Census api key\nInstall tidycensus, kableExtra and gt\n\ninstall.packages(c(\"tidycensus\", \"kableExtra\", \"gt\"))\n\nWe will be using the stringr package, which is part of the Tidyverse, so you probably already have it installed. But spend some time reading about its usage and features."
  },
  {
    "objectID": "modules/module-4.1.html#overview",
    "href": "modules/module-4.1.html#overview",
    "title": "Module 4.1",
    "section": "Overview",
    "text": "Overview\nThis week we are going to be talking about making tables in R. Tables can be a great way to summarize data for your audience. While there are no hard and fast rules about when to use a table versus a plot, typically we use tables when we want to present summary statistics that we want to compare across groups or when we want to show the precise values for individual data points. This can be true when we have a small number of cases that we want to discuss.\nIn this module we are going to be working with the tidycensus package to download income data from the [American Community Survey (ACS)]((https://www.census.gov/programs-surveys/acs/data/data-tables.html) and the kableExtra and gt packages to visualize it. Along the way, we discuss ‚Äúthe grammar of tables‚Äù and some situations where a table would be less appropriate than other methods of visualizing our data."
  },
  {
    "objectID": "modules/module-4.1.html#working-with-tidycensus",
    "href": "modules/module-4.1.html#working-with-tidycensus",
    "title": "Module 4.1",
    "section": "Working with tidycensus",
    "text": "Working with tidycensus\n\nWe are going to start by using tidycensus to download some income data. To use tidycensus you need a Census API key, which you can get here: http://api.census.gov/data/key_signup.html.\n\nlibrary(tidycensus)\ncensus_api_key(\"YOUR API KEY\") # enter your census api key here in quotes\n\nUse the load_variables() function to import data from the census or ACS for a particular year. There is a cache = TRUE option if you want to cache the data for faster retrieval in the future. We can save our data in an object called v21 and then click on it or use View() and the search function in the data frame viewer to see what data are available.\n\nv21 &lt;- load_variables(2021, \"acs5\", cache = TRUE)\n\n#View(v21)\n\nWe want data on income quintiles, so let‚Äôs search for ‚Äúquintile‚Äù in the search field. From there we use get_acs() to retrieve the data based on the codes for the five quintiles and the top five percent of earners.\nIn our call, we specify ‚Äústate‚Äù as the geography and ‚Äú2021‚Äù as the year. This will ensure that data from the 2017-2021 ACS is retrieved. Note that by default, tidycensus returns data such that rows represent a unit-variable combination. To get the data with census variables in the columns, we have to specify wide form with output = \"wide\". We will select all of the variables except for the margin of error and GEOID. Let‚Äôs rename NAME so it is in lower case. And for some reason, tidycensus puts an ‚ÄúE‚Äù suffix at the end of all of our variables when we specify wide format, so let‚Äôs use rename_with() and str_remove from the [stringr] package to get rid of that suffix. We will save the data frame in an object called quintiles.\n\nlibrary(stringr)\nlibrary(dplyr)\n\nquintiles &lt;- get_acs(geography = \"state\", \n                      variables = c(q1 = \"B19081_001\",\n                                    q2 = \"B19081_002\",\n                                    q3 = \"B19081_003\",\n                                    q4 = \"B19081_004\",\n                                    q5 = \"B19081_005\",\n                                    top5 = \"B19081_006\"),\n                      year = 2021,\n                      output = \"wide\") |&gt;\n                      select(\n                        !ends_with(\"m\"), # eliminate margin of error\n                        -GEOID) |&gt; # eliminate geo id\n                      rename(name = NAME) |&gt;\n                      rename_with(~str_remove(., 'E'))\n    \n\nglimpse(quintiles)\n\nRows: 52\nColumns: 7\n$ name &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colora‚Ä¶\n$ q1   &lt;dbl&gt; 11602, 19344, 15486, 12076, 17433, 18963, 17417, 17052, 12971, 14‚Ä¶\n$ q2   &lt;dbl&gt; 31928, 51030, 40774, 31051, 49234, 49711, 48870, 44638, 51060, 37‚Ä¶\n$ q3   &lt;dbl&gt; 55270, 81169, 66384, 52280, 84658, 80679, 84042, 73187, 94478, 62‚Ä¶\n$ q4   &lt;dbl&gt; 88640, 122652, 102299, 82811, 134560, 123359, 133488, 111915, 157‚Ä¶\n$ q5   &lt;dbl&gt; 193311, 242097, 223521, 188510, 309857, 264516, 319533, 238612, 3‚Ä¶\n$ top5 &lt;dbl&gt; 336788, 394694, 395620, 344470, 555007, 466181, 602707, 420859, 6‚Ä¶"
  },
  {
    "objectID": "modules/module-4.1.html#explore-the-data-with-kableextra",
    "href": "modules/module-4.1.html#explore-the-data-with-kableextra",
    "title": "Module 4.1",
    "section": "Explore the data with kableExtra",
    "text": "Explore the data with kableExtra\n\nNow let‚Äôs use some dplyr slice functions and kableExtra to subset and explore the data. First let‚Äôs see which are the wealthiest states. To do this, we can apply slice_max() to identify the states with the highest incomes among the top 5 percent of wage earners. We will save that list as an object called top_10 and then call kable() to view it.\n\nlibrary(kableExtra)\n\ntop_10 &lt;- quintiles |&gt;\n  slice_max(top5, n = 10)\n\nkable(top_10)\n\n\n\n\nname\nq1\nq2\nq3\nq4\nq5\ntop5\n\n\n\n\nDistrict of Columbia\n12971\n51060\n94478\n157803\n375792\n670768\n\n\nConnecticut\n17417\n48870\n84042\n133488\n319533\n602707\n\n\nNew York\n14054\n42220\n75647\n123318\n302676\n574063\n\n\nNew Jersey\n18458\n52339\n90337\n142858\n319140\n562886\n\n\nMassachusetts\n16812\n50519\n89602\n142491\n316447\n558616\n\n\nCalifornia\n17433\n49234\n84658\n134560\n309857\n555007\n\n\nMaryland\n19946\n55165\n91725\n140353\n293979\n503597\n\n\nWashington\n19367\n50803\n82817\n127003\n277165\n487950\n\n\nVirginia\n17922\n48359\n81072\n127411\n280299\n486006\n\n\nIllinois\n15102\n42688\n72900\n114531\n258373\n466713\n\n\n\n\n\n\n\nNow let‚Äôs do the same thing but searching for the poorest states instead. We will use the slice_min() function to identify the states with the lowest incomes in the first quintile of earners.\n\nlibrary(kableExtra)\n\nbottom_10 &lt;- quintiles |&gt;\n  slice_min(q1, n = 10)\n\nkable(bottom_10)\n\n\n\n\nname\nq1\nq2\nq3\nq4\nq5\ntop5\n\n\n\n\nPuerto Rico\n2906\n12144\n22163\n38397\n99043\n187234\n\n\nMississippi\n10096\n27963\n49418\n80125\n175581\n308523\n\n\nLouisiana\n10371\n29781\n53925\n89536\n201514\n357026\n\n\nNew Mexico\n11058\n31274\n54295\n86905\n188282\n323568\n\n\nWest Virginia\n11120\n29606\n51038\n81393\n174019\n299882\n\n\nAlabama\n11602\n31928\n55270\n88640\n193311\n336788\n\n\nKentucky\n11846\n32616\n55838\n88089\n194168\n350411\n\n\nArkansas\n12076\n31051\n52280\n82811\n188510\n344470\n\n\nSouth Carolina\n12680\n34881\n58665\n92118\n207367\n374427\n\n\nDistrict of Columbia\n12971\n51060\n94478\n157803\n375792\n670768\n\n\n\n\n\n\n\nOK now let‚Äôs make a table with a selection of states that reflects the full range of household incomes. So first, we will use slice_min() and slice_max() without arguments to select the state with the poorest households in q1 and the state with the wealthiest households in top5. The we will use slice_sample() to take a random sample of five additional states.\nWe will store these selections in three objects and then combine them into a single data frame called states using the dplyr function bind_rows. bind_rows() appends data frames with different observations for the same set of columns. You can think of its a kind of ‚Äúverticle merging‚Äù of data frames.\nAfter we have done the append, we can view the new data by calling kable(states).\n\nlibrary(dplyr)\n\n# lowest \nstate_min = quintiles |&gt; \n  slice_min(q1) \n\n# highest\nstate_max = quintiles |&gt; \n  slice_max(top5) \n\n# randomly select five more\nfive_more = quintiles |&gt;\n   slice_sample(n = 5) \n\nstates &lt;- bind_rows(state_min, state_max, five_more) |&gt;\n  arrange(desc(top5))\n\nkable(states)\n\n\n\n\nname\nq1\nq2\nq3\nq4\nq5\ntop5\n\n\n\n\nDistrict of Columbia\n12971\n51060\n94478\n157803\n375792\n670768\n\n\nMinnesota\n18936\n48127\n78073\n117959\n250361\n441274\n\n\nNew Hampshire\n20203\n51363\n83876\n126230\n258632\n440829\n\n\nFlorida\n14307\n37662\n62092\n97166\n230107\n431870\n\n\nLouisiana\n10371\n29781\n53925\n89536\n201514\n357026\n\n\nOklahoma\n13348\n34646\n57485\n89451\n195269\n348180\n\n\nPuerto Rico\n2906\n12144\n22163\n38397\n99043\n187234"
  },
  {
    "objectID": "modules/module-4.1.html#display-the-data-with-a-gt-table",
    "href": "modules/module-4.1.html#display-the-data-with-a-gt-table",
    "title": "Module 4.1",
    "section": "Display the data with a gt table",
    "text": "Display the data with a gt table\n\nNow that we have some good data for a table, let‚Äôs make a really beautiful table with the gt package. ‚Äúgt‚Äù stands for ‚Äúgrammar of tables.‚Äù So just as we talked about a ‚Äúgrammar of graphics‚Äù when we were studying plots, we can talk about the ‚Äúgrammar of tables‚Äù and break a table down into its component parts.\ngt envisions six main parts of a table that can be customized in various ways. The table header includes the title and possibly a subtitle. Next, we have the stub section that contains our row labels and, above that, a stubhead label, which we could use to provide more information about what is in the rows. Then, we have column labels that tell us about what is in each column and the table body which contains the actual data that we want to present. Finally, we have the table footer, which would contain any notes that we have about information contained in the table as well as information about sources. Check out the gt function reference to get a sense of all the customizations available.\nLet‚Äôs go ahead and start out by making a basic gt table with a title, subtitle, column labels, source note and format the numbers as dollar figures.\n\nMake a good gt table\n\nlibrary(gt)\n\ngoodtable &lt;- gt(states) |&gt; \n  tab_header(\n    title = \"Mean Household Income of Quintiles, 2021\",\n    subtitle = \"Seven Representative U.S. States\"\n  ) |&gt; \n  cols_label(\n    name = \"\",\n    q1 = \"lowest\",\n    q2 = \"second\",\n    q3 = \"third\",\n    q4 = \"fourth\",\n    q5 = \"fifth\",\n    top5 = \"top 5%\"\n  ) |&gt; \n  fmt_currency(\n    columns = c(q1, q2, q3, q4, q5, top5),\n    currency = \"USD\", \n    use_subunits = FALSE\n  ) |&gt;\n  # note that you can use markdown (md) to format the source note for html documents\n  tab_source_note(source_note = md(\"**Source**: US Census Bureau, American Community Survey\"))\n\ngoodtable\n\n\n\n\n\nMean Household Income of Quintiles, 2021\nSeven Representative U.S. States\nlowest\nsecond\nthird\nfourth\nfifth\ntop 5%\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\nMinnesota\n$18,936\n$48,127\n$78,073\n$117,959\n$250,361\n$441,274\nNew Hampshire\n$20,203\n$51,363\n$83,876\n$126,230\n$258,632\n$440,829\nFlorida\n$14,307\n$37,662\n$62,092\n$97,166\n$230,107\n$431,870\nLouisiana\n$10,371\n$29,781\n$53,925\n$89,536\n$201,514\n$357,026\nOklahoma\n$13,348\n$34,646\n$57,485\n$89,451\n$195,269\n$348,180\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\nSource: US Census Bureau, American Community Survey\n\n\n\n\n\n\nChange column width\nNow let‚Äôs add some further customization. One thing to pay attention to is the column width. Too narrow of columns can make it difficult to read the information, while too wide of columns can cause the table not to fit on the page. We can adjust the column width of our table with the cols_width() function.\n\nvgoodtable &lt;- goodtable |&gt;\n  cols_width(c(q1:top5) ~ px(90))\n\nvgoodtable\n\n\n\n\n\nMean Household Income of Quintiles, 2021\nSeven Representative U.S. States\nlowest\nsecond\nthird\nfourth\nfifth\ntop 5%\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\nMinnesota\n$18,936\n$48,127\n$78,073\n$117,959\n$250,361\n$441,274\nNew Hampshire\n$20,203\n$51,363\n$83,876\n$126,230\n$258,632\n$440,829\nFlorida\n$14,307\n$37,662\n$62,092\n$97,166\n$230,107\n$431,870\nLouisiana\n$10,371\n$29,781\n$53,925\n$89,536\n$201,514\n$357,026\nOklahoma\n$13,348\n$34,646\n$57,485\n$89,451\n$195,269\n$348,180\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\nSource: US Census Bureau, American Community Survey\n\n\n\n\n\n\nChange font\nNext we want to make sure that the fonts that we use are legible and accessible, just like we did for our charts. We can do this with opt_table_font().\n\ngreattable &lt;- vgoodtable |&gt;\n  opt_table_font(font = \"verdana\")\n\ngreattable\n\n\n\n\n\nMean Household Income of Quintiles, 2021\nSeven Representative U.S. States\nlowest\nsecond\nthird\nfourth\nfifth\ntop 5%\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\nMinnesota\n$18,936\n$48,127\n$78,073\n$117,959\n$250,361\n$441,274\nNew Hampshire\n$20,203\n$51,363\n$83,876\n$126,230\n$258,632\n$440,829\nFlorida\n$14,307\n$37,662\n$62,092\n$97,166\n$230,107\n$431,870\nLouisiana\n$10,371\n$29,781\n$53,925\n$89,536\n$201,514\n$357,026\nOklahoma\n$13,348\n$34,646\n$57,485\n$89,451\n$195,269\n$348,180\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\nSource: US Census Bureau, American Community Survey\n\n\n\n\n\n\nCenter\nThen we want to check to make sure that information is aligned properly in the table. We can use right, left or center justify our text, depending on its purpose, by calling cols_align().\n\nvgreattable &lt;- greattable |&gt;\n  cols_align(\n  align = \"center\",\n  columns = q1:top5\n)\n\nvgreattable\n\n\n\n\n\nMean Household Income of Quintiles, 2021\nSeven Representative U.S. States\nlowest\nsecond\nthird\nfourth\nfifth\ntop 5%\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\nMinnesota\n$18,936\n$48,127\n$78,073\n$117,959\n$250,361\n$441,274\nNew Hampshire\n$20,203\n$51,363\n$83,876\n$126,230\n$258,632\n$440,829\nFlorida\n$14,307\n$37,662\n$62,092\n$97,166\n$230,107\n$431,870\nLouisiana\n$10,371\n$29,781\n$53,925\n$89,536\n$201,514\n$357,026\nOklahoma\n$13,348\n$34,646\n$57,485\n$89,451\n$195,269\n$348,180\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\nSource: US Census Bureau, American Community Survey\n\n\n\ngtsave(vgreattable, \"vgreattable.png\")\n\n\n\nAdd borders and lines\nFinally, we want to think about how to use borders and lines to separate and identify different elements of the table using tab_options() like this.\n\nawesometable &lt;- vgreattable |&gt;\n  tab_options(\n    table.border.top.color = \"black\", \n    table.border.bottom.color = \"black\",\n    heading.border.bottom.color = \"black\", \n    column_labels.border.bottom.color = \"black\", \n    table_body.border.bottom.color = \"black\"\n  )\n\nawesometable\n\n\n\n\n\nMean Household Income of Quintiles, 2021\nSeven Representative U.S. States\nlowest\nsecond\nthird\nfourth\nfifth\ntop 5%\nDistrict of Columbia\n$12,971\n$51,060\n$94,478\n$157,803\n$375,792\n$670,768\nMinnesota\n$18,936\n$48,127\n$78,073\n$117,959\n$250,361\n$441,274\nNew Hampshire\n$20,203\n$51,363\n$83,876\n$126,230\n$258,632\n$440,829\nFlorida\n$14,307\n$37,662\n$62,092\n$97,166\n$230,107\n$431,870\nLouisiana\n$10,371\n$29,781\n$53,925\n$89,536\n$201,514\n$357,026\nOklahoma\n$13,348\n$34,646\n$57,485\n$89,451\n$195,269\n$348,180\nPuerto Rico\n$2,906\n$12,144\n$22,163\n$38,397\n$99,043\n$187,234\nSource: US Census Bureau, American Community Survey"
  },
  {
    "objectID": "modules/module-4.1.html#when-a-plot-is-better-than-a-table",
    "href": "modules/module-4.1.html#when-a-plot-is-better-than-a-table",
    "title": "Module 4.1",
    "section": "When a plot is better than a table",
    "text": "When a plot is better than a table\n\nBe judicious with your use of tables. You would not want to use tables where a plot is more appropriate. For example you would not want to use a table to show a trend over time (a line chart would be more appropriate) or to display the relationship between two variables (where a scatter plot would be more appropriate).\nAnother case where a table would be less effective than a plot is in showing estimates, margins of error and confidence intervals. Let‚Äôs do an example with median income estimates. We can start by searching for ‚Äúmedian income‚Äù and discover that the code for median income is B06011_001. Let‚Äôs use that to extract the median income for counties in the state of Massachusetts.\n\nlibrary(janitor)\n\nmass_med_inc &lt;- get_acs(\n  geography = \"county\", \n  variables = c(mediancome = \"B06011_001\"), \n  state = \"MA\", \n  year = 2021\n  ) |&gt;\n  mutate(\n    lower_90 = estimate - moe,\n    upper_90 = estimate + moe \n  ) |&gt;\n  clean_names() |&gt;\n  mutate(name = str_replace_all(name, \" County, Massachusetts\", \"\")) |&gt;\n  select(name, estimate, lower_90, upper_90)\n\nglimpse(mass_med_inc)\n\nRows: 14\nColumns: 4\n$ name     &lt;chr&gt; \"Barnstable\", \"Berkshire\", \"Bristol\", \"Dukes\", \"Essex\", \"Fran‚Ä¶\n$ estimate &lt;dbl&gt; 40442, 33040, 36910, 40119, 39756, 34775, 32262, 30795, 51808‚Ä¶\n$ lower_90 &lt;dbl&gt; 39554, 32074, 36347, 34791, 39174, 33712, 31707, 29868, 51337‚Ä¶\n$ upper_90 &lt;dbl&gt; 41330, 34006, 37473, 45447, 40338, 35838, 32817, 31722, 52279‚Ä¶\n\n\nWe can select the county name, median income estimate and the upper and lower confidence intervals and put those in a table.\n\nkable(mass_med_inc)\n\n\n\n\nname\nestimate\nlower_90\nupper_90\n\n\n\n\nBarnstable\n40442\n39554\n41330\n\n\nBerkshire\n33040\n32074\n34006\n\n\nBristol\n36910\n36347\n37473\n\n\nDukes\n40119\n34791\n45447\n\n\nEssex\n39756\n39174\n40338\n\n\nFranklin\n34775\n33712\n35838\n\n\nHampden\n32262\n31707\n32817\n\n\nHampshire\n30795\n29868\n31722\n\n\nMiddlesex\n51808\n51337\n52279\n\n\nNantucket\n45717\n38260\n53174\n\n\nNorfolk\n52591\n51991\n53191\n\n\nPlymouth\n43684\n43014\n44354\n\n\nSuffolk\n39200\n38624\n39776\n\n\nWorcester\n39009\n38454\n39564\n\n\n\n\n\n\n\nBut this is not very compelling. So instead, we can plot confidence intervals with ggplot using a combination of geom_errorbar() and geom_point().\n\nlibrary(ggplot2)\n\nmass_med_inc |&gt;\n  ggplot(aes(x = estimate, y = reorder(name, estimate))) +\n  geom_errorbar(aes(xmin = lower_90, xmax = upper_90)) +\n  geom_point(color = \"red\", size = 2) +\n  labs(title = \"Household income by county in Massachusetts\",\n       subtitle = \"2017-2021 American Community Survey\",\n       y = \"\",\n       x = \"Median Income\", \n       caption = \"ACS estimate (bars represent 90% confidence intervals)\") +\n  theme_minimal()\n\n\n\n\nThis conveys a lot more information relative to a table."
  },
  {
    "objectID": "modules/module-4.2.html",
    "href": "modules/module-4.2.html",
    "title": "Module 4.2",
    "section": "",
    "text": "Prework\n\n\n\n\nInstall peacesciencer, broom and modelsummary. Familiarize yourself with the basic purpose and usage of these packages, `\n\ninstall.packages(c(\"peacesciencer\", \"broom\", \"modelsummary\"))"
  },
  {
    "objectID": "modules/module-4.2.html#when-a-coefficient-plot-is-better",
    "href": "modules/module-4.2.html#when-a-coefficient-plot-is-better",
    "title": "Module 4.2",
    "section": "When a coefficient plot is better",
    "text": "When a coefficient plot is better\n\nA regression table is great when we have many models that we want to display. But what happens when we have just one model? We could present something like our earlier tidy() output which has the beta coefficient, the standard error, t-statistic and p-values in separate columns, but this would be unconvetional and would take up a lot of space. Another option is just to present a table with one column like this:\n\nmodelsummary(conflict_model, \n             stars = TRUE,  \n             gof_map = c(\"nobs\"),\n             coef_map = coef_map,\n             title = caption, \n             notes = reference)\n\n\nTable 1: Predictors of Conflict Onset\n\n\n\n¬†(1)\n\n\n\n\nEthnic Frac\n0.800*\n\n\n\n(0.381)\n\n\nReligions Frac\n‚àí0.391\n\n\n\n(0.417)\n\n\nPolyarchy\n‚àí0.602\n\n\n\n(0.509)\n\n\nTerrain\n0.064\n\n\n\n(0.076)\n\n\nPer capita GDP\n‚àí0.372**\n\n\n\n(0.121)\n\n\nPopulation\n0.293***\n\n\n\n(0.067)\n\n\nIntercept\n‚àí5.693***\n\n\n\n(1.408)\n\n\nNum.Obs.\n6151\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n See appendix for data sources.\n\n\n\n\n\n\n\n\n\nBut this is also somewhat unconventional and makes our regression output look a little bit lonely. A better option could be to display a coefficient plot that shows point estimates and confidence intervals. This is often preferable with one model because it makes our results so much easier to interpret.\nLet‚Äôs try making a coefficient plot with modelplot() from the modelsummary package. The syntax for modelplot() is very similar to that of modelsummary() but there are a few small differences.\nFirst, it puts maps the coefficients from the bottom up, so if you to maintain the order of the coefficients you need to reverse the mapping. We do this with the rev() function.\nSecond, we want to omit the intercept with coef_omit = \"Intercept\" because the emphasis in a coefficient plot is less on the exact regression equation and more on the magnitude and significance of the coefficients.\nThird we can customize various things. We can specify the color of the points and confidence intervals and we can load ggplot2 for furthercustomization. Now we can add geoms and labels just like any other ggplot object. Here we add a red vertical intercept line at zero to make it clearer which variables are significant (e.g.¬†the confidence interval does not overlap with zero). And we add a title and a caption using the labs() function.\n\nlibrary(ggplot2)\n\n\nmodelplot(conflict_model, \n          coef_map = rev(coef_map), # rev() reverses list order\n          coef_omit = \"Intercept\", \n          color = \"blue\") + # use plus to add customizations like any ggplot object\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\", linewidth = .75) + # red 0 line\n  labs(\n    title = \"Figure 1: Predictors of Conflict Onset\",\n    caption = \"Note: Coefficients and 95% confidence intervals.\"\n  )"
  },
  {
    "objectID": "modules/module-5.1.html#setup",
    "href": "modules/module-5.1.html#setup",
    "title": "Module 5.1",
    "section": "Setup",
    "text": "Setup\n\n# load packages\nlibrary(shiny)\nlibrary(readr)\nlibrary(ggplot2)\n\n# read in data, create a vector of variable names\ndem_data &lt;- read_csv(\"dem_data.csv\")\n\n# create list of named values for the input selection\nvars &lt;- c(\"Democracy\" = \"polyarchy\",\n          \"Clientelism\" = \"clientelism\",\n          \"Corruption\" = \"corruption\",\n          \"Women's Empowerment\" = \"womens_emp\",\n          \"Wealth\" = \"gdp_pc\",\n          \"Infant Mortality\" = \"inf_mort\",\n          \"Life Expectancy\" = \"life_exp\", \n          \"Education\" = \"education\")"
  },
  {
    "objectID": "modules/module-5.1.html#ui",
    "href": "modules/module-5.1.html#ui",
    "title": "Module 5.1",
    "section": "ui",
    "text": "ui\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n\n    # Application title\n    titlePanel(\"Democracy and Development\"),\n\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n      sidebarPanel(\n        selectInput('xcol', 'X Variable', vars),\n        selectInput('ycol', 'Y Variable', vars, selected = vars[[6]])\n      ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"scatterplot\")\n        )\n    )\n)"
  },
  {
    "objectID": "modules/module-5.1.html#server",
    "href": "modules/module-5.1.html#server",
    "title": "Module 5.1",
    "section": "Server",
    "text": "Server\n\n# Define server logic required to draw a scatter plot\nserver &lt;- function(input, output, session) {\n  \n  # Render the plot\n  output$scatterplot &lt;- renderPlot({\n    \n    # Combine the selected variables into a new data frame\n    selectedData &lt;- dem_data[, c(input$xcol, input$ycol, \"region\")]\n    \n    # ggplot call\n    ggplot(selectedData(), aes_string(x = input$xcol, y = input$ycol)) +\n      geom_point(aes(color = region)) +\n      geom_smooth(method = \"loess\") +\n      scale_color_viridis_d(option = \"plasma\") +\n      theme_minimal() +\n      labs(\n        x =  names(vars[which(vars == input$xcol)]),\n        y =  names(vars[which(vars == input$ycol)]),\n        caption = \"Source: V-Dem Institute\", # caption\n        color = \"Region\" # legend title\n      )\n  })\n}"
  },
  {
    "objectID": "modules/module-5.1.html#call-to-shiny-app",
    "href": "modules/module-5.1.html#call-to-shiny-app",
    "title": "Module 5.1",
    "section": "Call to Shiny app",
    "text": "Call to Shiny app\n\n# See above for the definitions of ui and server\nui &lt;- ...\n\nserver &lt;- ...\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "project/project-datasets.html",
    "href": "project/project-datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "Here are some datasets that you might consider using for your final project:\n\nILOSTAT is the statistical database of the International Labour Organisation. It has data pertaining to labor, working conditions, industrial relations, poverty and inequality.\nGoogle Public Data Explorer contains information about dozens of databases related to governance and the economy. You cannot download the raw data from Google, but you can use the site to visualize the data and then follow the link to the original source.\nOECD DATA provides data related to the performance of high income countries.\nOur World in Data is a good general resource for political economy data. The site is centered around blog posts but you can also search for a topic, view a visualization related to that topic and then download the data used to create it.\nStatista is a good place to look for data on more niche topics.\nUNCTADstat is the United Nations Conference on Trade and Development statistical database. It provides harmonized data on a range of topics related to economic performance, trade and statistics.\nThe UN Human Development Reports include a number of important indicators related to human development, gender and sustainable development goals (SDGs).\nVarieties of Democracy (V-DEM) provides original measures of the quality of democracy for every country dating back to the 18th century.\nWorld Bank Development Indicators (WDI) is the primary World Bank database for development data from officially-recognized international sources.\nThe World Bank DataBank provides access to dozens of additional World Bank databases on topics such as regional development, governance, education, gender and the environment.\n\nFor information on more specific resources available, see this page on the Gelman Library website."
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "üìñ Review the course syllabus and support resources\nüìñ r4ds - [8.1 & 8.2] - [6.1 - 6.3] - [20.3] - [4.5]\nüìñ Norris, The Impact of Electoral Reform on Women‚Äôs Representation"
  },
  {
    "objectID": "weeks/week-1.html#readings",
    "href": "weeks/week-1.html#readings",
    "title": "Week 1",
    "section": "",
    "text": "üìñ Review the course syllabus and support resources\nüìñ r4ds - [8.1 & 8.2] - [6.1 - 6.3] - [20.3] - [4.5]\nüìñ Norris, The Impact of Electoral Reform on Women‚Äôs Representation"
  },
  {
    "objectID": "weeks/week-1.html#assignments",
    "href": "weeks/week-1.html#assignments",
    "title": "Week 1",
    "section": "Assignments",
    "text": "Assignments\nüìò Quiz 1 üìò Quiz 2 üßÆ Coding Assignment 1"
  },
  {
    "objectID": "modules/module-4.2.html#overview",
    "href": "modules/module-4.2.html#overview",
    "title": "Module 4.2",
    "section": "Overview",
    "text": "Overview\nA very common use of tables in the social sciences is to present regression results. There are numerous packages available for presenting regression output. In this lesson, we are going to focus on one of them that I think is particularly good for both pdf and html output: modelsummary. modelsummary also includes a function (modelplot()) for plotting point estimates and confidence intervals. So part of the objective of this lesson is going to be to learn when you should use a table to present your regression results versus when you should use a plot.\nWe will be taking our example from the peace studies literature. We are going to download data using the peacesciencer package and use it to partially reproduce a famous analysis of conflict onset by Fearon and Laitin."
  },
  {
    "objectID": "modules/module-4.2.html#run-a-regression-model-and-display-results-with-broom",
    "href": "modules/module-4.2.html#run-a-regression-model-and-display-results-with-broom",
    "title": "Module 4.2",
    "section": "Run a regression model and display results with broom",
    "text": "Run a regression model and display results with broom\n\nWe will start off by building a data frame for our analysis with the peacesciencer package. peacesciencer is designed to make standard analysis for conflict studies more convenient and includes many of the control variables that you would use to estimate the likelihood of conflict onset or duration.\nTo start, we call create_stateyears(s) to create a time-series data set for all available countries. We will specify system = 'gw' to denote the Gleditsch-Ward country coding system. Then we will filter for roughly the same years of Fearon and Laitin‚Äôs original analysis (1945-99) with the caveat that peacesciencer only has conflict data starting in 1946.\nThen we add a bunch of data to the data frame using the various add_X functions available in the package. Here we add UCDP conflict data which includes our dependent variable for this analysis‚Äìconflict onset. Then we add measures of democracy, ethno-religious fractionalization, GDP and terrain.\n\nlibrary(peacesciencer)\nlibrary(dplyr)\n\nconflict_df &lt;- create_stateyears(system = 'gw') |&gt;\n  filter(year %in% c(1946:1999)) |&gt;\n  add_ucdp_acd(type=c(\"intrastate\"), only_wars = FALSE) |&gt;\n  add_democracy() |&gt;\n  add_creg_fractionalization() |&gt;\n  add_sdp_gdp() |&gt;\n  add_rugged_terrain()\n\nglimpse(conflict_df)\n\nRows: 7,036\nColumns: 20\n$ gwcode         &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2‚Ä¶\n$ statename      &lt;chr&gt; \"United States of America\", \"United States of America\",‚Ä¶\n$ year           &lt;dbl&gt; 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1‚Ä¶\n$ ucdpongoing    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ ucdponset      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ maxintensity   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ conflict_ids   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ v2x_polyarchy  &lt;dbl&gt; 0.605, 0.587, 0.599, 0.599, 0.587, 0.602, 0.601, 0.594,‚Ä¶\n$ polity2        &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,‚Ä¶\n$ xm_qudsest     &lt;dbl&gt; 1.259180, 1.259180, 1.252190, 1.252190, 1.270106, 1.259‚Ä¶\n$ ethfrac        &lt;dbl&gt; 0.2226323, 0.2248701, 0.2271561, 0.2294918, 0.2318781, ‚Ä¶\n$ ethpol         &lt;dbl&gt; 0.4152487, 0.4186156, 0.4220368, 0.4255134, 0.4290458, ‚Ä¶\n$ relfrac        &lt;dbl&gt; 0.4980802, 0.5009111, 0.5037278, 0.5065309, 0.5093204, ‚Ä¶\n$ relpol         &lt;dbl&gt; 0.7769888, 0.7770017, 0.7770303, 0.7770729, 0.7771274, ‚Ä¶\n$ wbgdp2011est   &lt;dbl&gt; 28.539, 28.519, 28.545, 28.534, 28.572, 28.635, 28.669,‚Ä¶\n$ wbpopest       &lt;dbl&gt; 18.744, 18.756, 18.781, 18.804, 18.821, 18.832, 18.848,‚Ä¶\n$ sdpest         &lt;dbl&gt; 28.478, 28.456, 28.483, 28.469, 28.510, 28.576, 28.611,‚Ä¶\n$ wbgdppc2011est &lt;dbl&gt; 9.794, 9.762, 9.764, 9.730, 9.752, 9.803, 9.821, 9.857,‚Ä¶\n$ rugged         &lt;dbl&gt; 1.073, 1.073, 1.073, 1.073, 1.073, 1.073, 1.073, 1.073,‚Ä¶\n$ newlmtnest     &lt;dbl&gt; 3.214868, 3.214868, 3.214868, 3.214868, 3.214868, 3.214‚Ä¶\n\n\nNow let‚Äôs go ahead and run the analysis. We will specify a logit model using the glm() function and specifying family = binomial(link = \"logit\"). We will store our model in an object called conflict_model. And from there we can use the tidy() function from the broom package to view the results.\nWe notice that by default tidy() returns figures with large numbers of digits following the decimal point, making hard to tell whether the variables are significant. To fix this, let‚Äôs pipe our tidy() output inot a mutate_if() call and specificy that we want numeric output to round to five decimal places.\n\nlibrary(broom)\n\nconflict_model &lt;- glm(ucdponset ~ ethfrac + relfrac + v2x_polyarchy + \n                        rugged + wbgdppc2011est + wbpopest,\n                  data= conflict_df,\n                  family = binomial(link=\"logit\"))\n\n#tidy(conflict_model)\n\nconflict_model |&gt;\n  tidy() |&gt;\n  mutate_if(is.numeric, round, 5)\n\n# A tibble: 7 √ó 5\n  term           estimate std.error statistic p.value\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)     -5.69      1.41      -4.04  0.00005\n2 ethfrac          0.800     0.381      2.10  0.0356 \n3 relfrac         -0.391     0.417     -0.939 0.348  \n4 v2x_polyarchy   -0.602     0.509     -1.18  0.237  \n5 rugged           0.0641    0.0760     0.843 0.399  \n6 wbgdppc2011est  -0.372     0.121     -3.08  0.00204\n7 wbpopest         0.293     0.0673     4.35  0.00001\n\n\nHow did we do relative to Fearon and Latin‚Äôs original analysis. Well, one thing that F&L were pretty certain about is that ethnic and religiou fractionalization do not matter for conflict onset. But here we find a statistically significan relationship between these variables and conflict onset. But one thing we do find in common with their analysis is the importance of wealth and population. Both of these variables are significant in the expected direction. Wealthier countries experience less risk of conflict onset while more populous ones have a higher risk."
  },
  {
    "objectID": "modules/module-4.2.html#run-many-regressions-and-display-with-modelsummary",
    "href": "modules/module-4.2.html#run-many-regressions-and-display-with-modelsummary",
    "title": "Module 4.2",
    "section": "Run many regressions and display with modelsummary",
    "text": "Run many regressions and display with modelsummary\n\nbroom is really great if we want to just run one regression and see the results in the context of a working document. But what if we want to display our results to other researchers? For this, we need to use a different package. One package that is really good at producing professional-looking tabels is modelsummary and one of its strongest features is the ability to combine multiple models into the same table while still allowing for substantial customization.\nLet‚Äôs go ahead and store four models. In the first three, we will feature sets of predictors (ethnicity, democracy and terrain) and then a final model that includes all of our predictors. In each model, we will include wealth (GDP) and population as controls because we have a feeling that these are robust predictors of conflict onset.\n\nethnicity &lt;- glm(ucdponset ~ ethfrac + relfrac + wbgdppc2011est + wbpopest, # store each model in an object\n                  data=subset(conflict_df),\n                  family = binomial(link=\"logit\"))\n\ndemocracy &lt;- glm(ucdponset ~ v2x_polyarchy + wbgdppc2011est +  wbpopest,\n                  data=subset(conflict_df),\n                  family = binomial(link=\"logit\"))\n\nterrain &lt;- glm(ucdponset ~ rugged + wbgdppc2011est + wbpopest ,\n                  data=subset(conflict_df),\n                  family = binomial(link=\"logit\"))\n\nfull_model &lt;- glm(ucdponset ~ ethfrac + relfrac + v2x_polyarchy + rugged +\n                        wbgdppc2011est + wbpopest,\n                  data=subset(conflict_df),\n                  family = binomial(link=\"logit\"))\n\nNext we will store our models as a list with intuitive names that we can display as column headers in our regression table. Then we will store a new coefficient mapping where we rename our variables and change the order that they will appear in the table. We will also store a title and a reference.\n\nmodels &lt;- list(\"Ethnicity\" = ethnicity,  # store list of models in an object\n               \"Democracy\" = democracy, \n               \"Terrain\" = terrain, \n               \"Full Model\" = full_model)\n\ncoef_map &lt;- c(\"ethfrac\" = \"Ethnic Frac\",  # map coefficients\n        \"relfrac\" = \"Religions Frac\",     #(change names and order)\n        \"v2x_polyarchy\" = \"Polyarchy\",\n        \"rugged\" = \"Terrain\",\n        \"wbgdppc2011est\" = \"Per capita GDP\",\n        \"wbpopest\" = \"Population\",\n        \"(Intercept)\" = \"Intercept\")\n\ncaption = \"Table 1: Predictors of Conflict Onset\" # store caption\nreference = \"See appendix for data sources.\"      # store reference notes\n\nNow we can call modelsummary(). The first argument is the list of models we want to display. Next we tell modelsummary that we want it to show stars for statitiscal significance (stars = TRUE). And in gof_map(), we say that, of the many goodness of fit statistics available to us, we only want to include the number of observations. Finally we plug our title into title = and a source note into notes =.\n\nlibrary(modelsummary)\n\nmodelsummary(models,                      # display the table\n             stars = TRUE,                # include stars for significance\n             gof_map = c(\"nobs\"),         # goodness of fit stats to include   \n             coef_map = coef_map,         # coefficient mapping\n             title = caption,             # title\n             notes = reference)           # source note\n\n\nTable 1: Predictors of Conflict Onset\n\n\n\nEthnicity\nDemocracy\nTerrain\nFull Model\n\n\n\n\nEthnic Frac\n0.744*\n\n\n0.800*\n\n\n\n(0.367)\n\n\n(0.381)\n\n\nReligions Frac\n‚àí0.481\n\n\n‚àí0.391\n\n\n\n(0.411)\n\n\n(0.417)\n\n\nPolyarchy\n\n‚àí0.228\n\n‚àí0.602\n\n\n\n\n(0.436)\n\n(0.509)\n\n\nTerrain\n\n\n0.031\n0.064\n\n\n\n\n\n(0.076)\n(0.076)\n\n\nPer capita GDP\n‚àí0.474***\n‚àí0.512***\n‚àí0.543***\n‚àí0.372**\n\n\n\n(0.104)\n(0.108)\n(0.092)\n(0.121)\n\n\nPopulation\n0.282***\n0.297***\n0.299***\n0.293***\n\n\n\n(0.067)\n(0.051)\n(0.050)\n(0.067)\n\n\nIntercept\n‚àí4.703***\n‚àí4.407***\n‚àí4.296***\n‚àí5.693***\n\n\n\n(1.327)\n(1.205)\n(1.143)\n(1.408)\n\n\nNum.Obs.\n6364\n6772\n6840\n6151\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n See appendix for data sources."
  }
]