{
  "hash": "1d5f100fe1495c7719e51bed6b7c65f6",
  "result": {
    "markdown": "---\ntitle: \"Module 1.2\"\nsubtitle: \"Working With APIs\"\nformat: html\nhighlight-style: atom-one\nexecute:\n  echo: true\n  message: false\n  warning: false\n---\n\n\n::: {.callout-tip}\n## Prework\n\n- Install the `devtools` package. Type `install.packages(\"devtools\")` in your console. You will need this to install the `vdemdata` package becaue it is not on the CRAN Network. \n- Install the `vdemdata` package from GitHub. Type `devtools::install_github(\"vdeminstitute/vdemdata\")` in your console. \n- Install the `wbstats` and `countrycode` packages:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npkg_list <- c(\"wbstats\", \"countrycode\") # create a list of packages\ninstall.packages(pkg_list) # install the packages\n```\n:::\n\n- Have a look at the vignettes for [wbstats](https://cran.r-project.org/web/packages/wbstats/vignettes/wbstats.html) and the [countrycode](https://vincentarelbundock.github.io/countrycode/) documentation\n- Generate a quarto document named \"module-1.2.qmd\" in your modules project folder so that you can code along with me\n:::\n\n\n## Overview \n\nIn this module working, we are going to be working with data from [APIs](https://en.wikipedia.org/wiki/API) instead of flat files. As we saw in the last lesson, importing and wrangling data from flat files can be a messy process. So when clean data are available for download, we want to be able to take advantage of that. Luckily there are some pretty good R packages that allow us to extract data from open source APIs. We are going to be working with two of those in this module (`wbstats` and `vdemdata`) and some others later in the course. \n\nAlong the way, we are going to continue to extend our data wrangling skills. We will learn some new functions in `dplyr` and `janitor` that will help us get our data into a usable form for analysis. We are also going to cover in depth some common data science workflows, including filtering observations, selecting variables, merging two data sets, summarizing data for different groups, and sorting data based on column values. \n\nThe end goal is to have a nice dataset with a combination of World Bank and [V-Dem Institute](https://www.v-dem.net/) data that we can use to illustrate the relationship between the economy, democracy and women's empowerment.   \n\n\n## Downloading data from an API\n\n\n{{< video https://youtu.be/cBRTP2imt_o title='Downloading Data from the World Bank' >}}\n\n\n\nYou will no doubt remember the messy data that we downloaded from the World Bank's website in [module 1.1](/modules/module-1.1.htmll#step-1-download-data-from-the-world-bank). Usually it is much easier to download data from an API as opposed to wrangling it from a .csv file. In this example, I want to illustrate that for you by having you download the same data that we worked with in the last module using the [wbstats](https://cran.r-project.org/web/packages/wbstats/vignettes/wbstats.html) package.\n\nFirst we are going to load `wbstats` along with `dplyr` and `janitor`. The `wb_data()` function is the one we need to download the data from the World Bank's API. `wb_data()` requires to main sets of arguments: a list of indicators that we want to use and the period for which we want to download data. The period can can be entered as two separate arguments (e.g. `start_date` and `end_date`). But for this exercise we will specify the number of years we want to download using `mrv` which stands for \"most recent value.\" \n\nIn addition to female labor force participation, let's also grab the percentage of seats in parliament held by women. We will store that list of objects in a vector called `women_emp` to signify that these indicators are related to women's empowerment. We will try to download 50 years of data for these two variables.  \n\n::: {.callout-note}\nIf you want to search World Bank data for additional indicators, you can use the `wb_search()` function. For example, if we wanted to find all of the indicators associated with female labor force participation, we could run: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nflfp_indicators <- wb_search(\"female labor force\") # store the list of indicators\n\nprint(flfp_indicators, n=26) # view the indicators\n```\n:::\n\n\nTry searching for some indicators related to a topic you are interested in and see what you get!\n:::\n\nWhile we are calling `wb_data` we will go ahead and pipe some additional functions from `dplyr` and `janitor` to clean it up. First, we will use `select()` to eliminate the iso2c variable, which we won't be needing. Then, we will rename `date` to `year`. Then we will use a combination of `mutate` and `round_to_fraction()` to round the data to the nearest hundredth. \n\nWe will pipe all of these functions together and store the resulting data frame in a new object called `women_emp`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(wbstats) # for downloading WB data\nlibrary(dplyr) # for selecting, renaming and mutating\nlibrary(janitor) # for rounding\n\n# Store the list of indicators in an object\nindicators <- c(\"flfp\" = \"SL.TLF.CACT.FE.ZS\", \"women_rep\" = \"SG.GEN.PARL.ZS\") \n\n# Download the data  \nwomen_emp <- wb_data(indicators, mrv = 50) |> # download data for last 50 yrs\n  select(!iso2c) |> # drop the iso2c code which we won't be using\n  rename(year = date) |> # rename date to year \n  mutate(\n    flfp = round_to_fraction(flfp, denominator = 100), # round to nearest 100th\n    women_rep = round_to_fraction(women_rep, denominator = 100) \n  )\n\n# View the data\nglimpse(women_emp) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6,944\nColumns: 5\n$ iso3c     <chr> \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW…\n$ country   <chr> \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba…\n$ year      <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, …\n$ women_rep <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ flfp      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n```\n:::\n:::\n\n\nNow we have some pretty tidy World Bank data related to women's empowerment without having to do too much work. I am sure you would agree that this is a much more straightforward process than downloading the data and then importing the data as a flat file! \n\nOne thing that becomes very clear here is that `wb_data()` did not download any data before 1990. It automatically filtered out the years for which all countries had no data. The fact there were no data before 1990 for any of the countries is easily missed when we were simply importing it from a .csv file. \n\n## Filter observations, select and create new variables \n\n\n{{< video https://youtu.be/7CvYTeMP_PU title='Downloading Data Using wbstats' >}}\n\n\n\nThe next thing we want to talk about is how to filter observations and to select new variables. We also delve more into the topic of how to create new variables. To illustrate these concepts, we are going to be working with the [V-Dem Dataset](https://www.v-dem.net/data/the-v-dem-dataset/). The V-Dem offers an R package for downloading its data called [vdemdata](https://github.com/vdeminstitute/vdemdata). \n\n`vdemdata` is perfect for illustrating the `filter()` and `select()` verbs because its main function for downloading the data (`vdem`) does not take any arguments (it simply downloads the whole dataset). So you have to use R functions to narrow down the variables and years you want to work with. \n\nWhile V-Dem has wealth of indicators related to democracy, we are going to focus on the most famous one called the \"polyarchy\" score. We are also going to download data on per capita GDP and create some indicator variables for region that we will use later on when we summarize the data. Along with those variables, we also want to retain `country_name`, `year` and `country_id` for the purposes of merging these data with our World Bank data. \n\n::: {.callout-note}\nWhile V-Dem has a variable look-up tool (`find_var`), it does not provide very much information on the variables that the search function returns. Therefore, if you want to use this package for your own research, I highly recommend just going to the [V-Dem codebook](https://www.v-dem.net/documents/24/codebook_v13.pdf) and manually grabbing the codes for the indicators that you want to use in your analysis. \n:::\n\nIn addition to filtering out years and selecting variables, let's also create a `region` coding to facilitate our analysis later on. We will do this by piping in a `mutate()` call where we use the [case_match()](https://dplyr.tidyverse.org/reference/case_match.html) function to change the `region` from a numeric variable to a string. This will come in handy when we go to visualize the data in future lessons.  \n\nWe will store our new data as an object called `democracy`.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(vdemdata) # to download V-Dem data\n\n# Download the data\ndemocracy <- vdem |> # download the V-Dem dataset\n  filter(year >= 1990)  |> # filter out years less than 1990\n  select(                  # select (and rename) these variables\n    country = country_name,     # the name before the = sign is the new name  \n    vdem_ctry_id = country_id,  # the name after the = sign is the old name\n    year, \n    polyarchy = v2x_polyarchy, \n    gdp_pc = e_gdppc, \n    region = e_regionpol_6C\n    ) |>\n  mutate(\n    region = case_match(region, # replace the values in region with country names\n                     1 ~ \"Eastern Europe\", \n                     2 ~ \"Latin America\",  \n                     3 ~ \"Middle East\",   \n                     4 ~ \"Africa\", \n                     5 ~ \"The West\", \n                     6 ~ \"Asia\")\n                    # number on the left of the ~ is the V-Dem region code\n                    # we are changing the number to the country name on the right\n                    # of the equals sign\n  )\n\n# View the data\nglimpse(democracy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 5,667\nColumns: 6\n$ country      <chr> \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico…\n$ vdem_ctry_id <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n$ year         <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199…\n$ polyarchy    <dbl> 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0…\n$ gdp_pc       <dbl> 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1…\n$ region       <chr> \"Latin America\", \"Latin America\", \"Latin America\", \"Latin…\n```\n:::\n:::\n\n\n## Add country codes to a data frame\n\n\n{{< video https://www.youtube.com/embed/wo9vZccmqwc title='Add Country Codes to a Data Frame' >}}\n\n\n\nOne common problem scholars face when they want to analyze country-level data is the fact that datasets use different country codes. This can make it challenging to combine datasets, thus limiting the potential scope of our analysis. Lucikly, there is a wonderful package called [countrycode](https://vincentarelbundock.github.io/countrycode/) that can help to solve this problem.\n\nThe `countrycode()` function creates a new country code variable in our dataset that matches the country code variable of the second dataset that we are trying to merge it to. `countrycode()` takes three arguments: `sourcevar`; `origin`; and `destination`. `sourcevar` identifies  the name of the column that you want to transform, `origin` is the coding system that you want to translate from, and `destination` is the coding system that you want to translate to.  \n\nIn this next step of our analysis, we are going to join the World Bank and V-Dem data that we wrangled into a single dataset. To do that we need a common country code. The way we are going to do this is to create a new country code variable in the democracy dataset that matches the one in the women's empowerment dataset.\n\nLet's create a new version of our democracy dataset where we add a variable called `iso3c`. We will call `mutate()` to create the variable and wrap the `countrycode()` call inside of that. The `sourcevar` that we want to transform is the `vdem_ctry_id`, the origin code is \"vdem\", and the destination code is \"wb\". \n\nWe are also going to pipe in a [relocate()](https://dplyr.tidyverse.org/reference/relocate.html) call which simply moves the new `iso3c` column from the end of the data frame (where R automically drops it) so that it sits right next to `vdem_ctry_cd`. This is not essential but it is always good to keep our data frames looking nice and neat!. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load countrycode\nlibrary(countrycode)\n\n# Create new iso3c variable\ndemocracy <- democracy |>    \n  mutate(iso3c = countrycode(sourcevar = vdem_ctry_id, # what we are converting\n        origin = \"vdem\",         # we are converting from vdem\n        destination = \"wb\"))  |> # and converting to the WB iso3c code \n  relocate(iso3c, .after = vdem_ctry_id) # move iso3c \n\n#filter(democracy, is.na(iso3c)) STILL NEED THIS?\n\n# View the data\nglimpse(democracy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 5,667\nColumns: 7\n$ country      <chr> \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico…\n$ vdem_ctry_id <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n$ iso3c        <chr> \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"…\n$ year         <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199…\n$ polyarchy    <dbl> 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0…\n$ gdp_pc       <dbl> 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1…\n$ region       <chr> \"Latin America\", \"Latin America\", \"Latin America\", \"Latin…\n```\n:::\n:::\n\n\n## Merge two datasets \n\n\n{{< video https://www.youtube.com/embed/wo9vZccmqwc title='Merge Two Datasets' >}}\n\n\n\nNow that we have a common country code, we can join the two data sets. There are many different types of joins. First there is a distinction between [mutating joins](https://dplyr.tidyverse.org/reference/mutate-joins.html), which add observations from one dataset to another, and [filtering joins](https://dplyr.tidyverse.org/reference/filter-joins.html), which filter out variables based on their presence or absence in another dataset. Here we are going to be focused on mutating joins. \n\nThere are four kinds of mutating joins we can do in `dplyr`. An `inner_join()` keeps only the observations that are common in both datasets that you want to merge. A `full_join()` does the opposite. It keeps all of the observations present in both datasets regardless of whether or not they have a match. A `left_join()` keeps all of the observations in dataset $x$ and only the matching observations in dataset $y$. A `right_join()` does the same thing, but instead keeps all of the observations from dataset $y$ and only matching observations from dataset $x$. \n\nWe are going to use `left_join()` to merge our two datasets. `left_join()` takes three essential arguments: $x$; $y$; and $by$ which identifies the column that we want to join on. For this exercise, the $x$ dataset is going to be the democracy dataset, the $y$ dataset is the women empowerment dataset, and we want to join on both the \"iso3c\" and \"year\" columns. \n\nWhen `dplyr` does a join, it renames any duplicate columns with suffixes like `.x` or `.y`. In our data, country is a duplicate column across the democracy and women's empowerment datasets. So `dplyr` renames these `country.x` and `country.y`. It doesn't really matter which one we keep, so let's just rename `country.x` to `country` and filter out `country.y` using `select()`.\n\nWe can can pipe all of these functions together and store the resulting data frame in a new object called `dem_women`. Let's also save these data as a .csv file for future use with `write_csv()`. The first argument for `write_csv()` is the name of the data frame or tibble that we want to save. The second argument is the path and name of the file that we want to save it to. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load readr\nlibrary(readr)\n\n# Perform left join using common iso3c variable and year\ndem_women <- left_join(democracy, women_emp, by = c(\"iso3c\", \"year\")) |> \n  rename(country = country.x) |> # rename country.x\n  select(!country.y)             # crop country.y\n\n# Save as .csv for future use\nwrite_csv(dem_women, \"data/dem_women.csv\")\n\n# View the data\nglimpse(dem_women)  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 5,667\nColumns: 9\n$ country      <chr> \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico\", \"Mexico…\n$ vdem_ctry_id <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n$ iso3c        <chr> \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"…\n$ year         <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 199…\n$ polyarchy    <dbl> 0.396, 0.416, 0.439, 0.456, 0.473, 0.485, 0.513, 0.548, 0…\n$ gdp_pc       <dbl> 11.389, 11.635, 11.883, 11.983, 12.043, 11.742, 12.059, 1…\n$ region       <chr> \"Latin America\", \"Latin America\", \"Latin America\", \"Latin…\n$ women_rep    <dbl> NA, NA, NA, NA, NA, NA, NA, 14.20, 17.40, 18.20, 16.00, 1…\n$ flfp         <dbl> 33.94, 34.24, 35.01, 35.85, 36.38, 37.62, 37.69, 39.65, 3…\n```\n:::\n:::\n\n\n\n## Group, summarize and arrange \n\n\n{{< video https://www.youtube.com/embed/wo9vZccmqwc title='Group, Summarize and Arrange' >}}\n\n\n\nNow that we have completed all of the wrangling, let's do something with it. A common sequence in data science is [group by()](https://dplyr.tidyverse.org/reference/group_by.html), [summarize()](https://dplyr.tidyverse.org/reference/summarise.html) and [arrange()](https://dplyr.tidyverse.org/reference/arrange.html). First, we group the data by certain value or category. Then we summarize it by applying a function like `min()`, `max()`, `mean()`, `median()` or `sd()`. Finally, we order the data according to column values. \n\nLet's go ahead and apply our three new verbs to the `dem_women` data frame and store the resulting new data frame in an object called `dem_summary`. We will group the data by region, take the mean of each variable, and sort the data in descending order based on the regions' polyarchy scores. Then we will print the object to view its contents. Along the way, we let's also export the data to a .csv file for future use. \n\n::: {.callout-note}\nTo print an object in R, we can either use the `print()` function or just execute the name of the object. Oftentimes it is simpler to just execute the name of the object. \n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# group_by(), summarize() and arrange()\ndem_summary <- dem_women |> # save result as new object\n  group_by(region)  |> # group dem_women data by region\n  summarize(           # summarize following vars (by region)\n    polyarchy = mean(polyarchy, na.rm = TRUE), # calculate mean, remove NAs\n    gdp_pc = mean(gdp_pc, na.rm = TRUE), \n    flfp = mean(flfp, na.rm = TRUE), \n    women_rep = mean(women_rep, na.rm = TRUE)\n  ) |> \n  arrange(desc(polyarchy)) # arrange in descending order by polyarchy score\n\n# Save as .csv for future use\nwrite_csv(dem_summary, \"data/dem_summary.csv\")\n\n# View the data\nglimpse(dem_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6\nColumns: 5\n$ region    <chr> \"The West\", \"Latin America\", \"Eastern Europe\", \"Asia\", \"Afri…\n$ polyarchy <dbl> 0.8725938, 0.6405013, 0.5383947, 0.4077176, 0.3929385, 0.248…\n$ gdp_pc    <dbl> 37.913051, 9.610281, 12.177422, 9.746389, 4.410481, 21.134312\n$ flfp      <dbl> 52.84760, 48.02866, 51.40721, 50.28034, 56.71850, 26.48931\n$ women_rep <dbl> 27.783519, 20.864359, 17.608873, 14.296118, 17.152801, 9.945…\n```\n:::\n:::\n",
    "supporting": [
      "module-1.2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}